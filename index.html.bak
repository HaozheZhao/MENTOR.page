<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="MENTOR â€“ Efficient Multimodalâ€‘Conditioned Tuning for Autoregressive Vision Generation Models">
  <meta name="keywords" content="MENTOR, multimodal generation, autoregressive, controllable image generation, visionâ€‘language">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MENTOR: Efficient Multimodalâ€‘Conditioned Tuning for Autoregressive Vision Generation</title>

  <!-- Fonts & Styles -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <!-- Analytics (optional) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-PYVRSFMDRL');
  </script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
</head>
<body>

<!-- ================= HERO ================= -->
<section class="hero is-light is-fullheight-with-navbar">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title has-text-weight-bold">MENTOR: Efficient Multimodalâ€‘Conditioned Tuning<br class="is-hidden-mobile">for Autoregressive Vision Generation Models</h1>

          <!-- ========== AUTHORS ========= -->
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="#">Haozhe&nbsp;Zhao</a><sup>1</sup>*,</span>
            <span class="author-block"><a href="https://zefan-cai.github.io/">Zefan&nbsp;Cai</a><sup>2</sup><span class="has-text-weight-normal">*</span>,</span>
            <span class="author-block"><a href="#">Shuzheng&nbsp;Si</a><sup>3</sup>,</span>
            <span class="author-block"><a href="#">Liang&nbsp;Chen</a><sup>4</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=Ls0e7IEAAAAJ">Jiuxiang&nbsp;Gu</a><sup>5</sup>,</span>
            <span class="author-block"><a href="https://wendy-xiao.github.io/">Wen&nbsp;Xiao</a><sup>6</sup>,</span>
            <span class="author-block"><a href="https://junjiehu.github.io/">Junjie&nbsp;Hu</a><sup>2</sup></span>
          </div>

          <div class="is-size-5 publication-authors mt-1">
            <span class="author-block"><sup>1</sup>University&nbsp;of&nbsp;Illinois&nbsp;Urbanaâ€‘Champaign</span>
            <span class="author-block"><sup>2</sup>University&nbsp;of&nbsp;Wisconsinâ€‘Madison</span>
            <span class="author-block"><sup>3</sup>Tsinghua&nbsp;University</span>
            <span class="author-block"><sup>4</sup>Peking&nbsp;University</span>
            <span class="author-block"><sup>5</sup>Adobe&nbsp;Research</span>
            <span class="author-block"><sup>6</sup>Microsoft</span>
          </div>

          <!-- Action Buttons -->
          <div class="buttons is-centered mt-5">
            <a href="#news" class="button is-link is-light">News</a>
            <a href="#overview" class="button is-link is-light">Overview</a>
            <a href="#highlights" class="button is-link is-light">Highlights</a>
            <a href="#why" class="button is-link is-light">Why&nbsp;MENTOR</a>
            <a href="#method" class="button is-link is-light">Method</a>
            <a href="#results" class="button is-link is-light">Results</a>
            <a href="#efficiency" class="button is-link is-light">Efficiency</a>
            <a href="#comparison" class="button is-link is-light">Comparison</a>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<!-- ============================= NEWS ============================= -->
<section class="section" id="news">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">ğŸ”¥ News</h2>
        <div class="content has-text-left">
          <ul>
            <li><strong>ğŸš€Â 2025â€‘06â€‘02</strong> â€” Initial release of <strong>MENTOR</strong>, a lightweight yet stateâ€‘ofâ€‘theâ€‘art multimodalâ€‘conditioned image generator.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ============================= OVERVIEW ============================= -->
<section class="section" id="overview">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>Recent text-to-image models produce high-quality results but still struggle with precise visual control, balancing multimodal inputs, and demanding extensive training for complex multimodal image generation. To address these limitations, we propose <strong>MENTOR</strong>, a novel autoregressive (AR) framework for efficient <strong>M</strong>ultimodal-condition<strong>E</strong>d tu<strong>N</strong>ing for au<strong>T</strong><strong>O</strong>reg<strong>R</strong>essive multimodal image generation.</p>
          <p><strong>MENTOR</strong> combines an AR image generator with a two-stage training paradigm, enabling fine-grained, token-level alignment between multimodal inputs and image outputsâ€”without relying on auxiliary adapters or cross-attention modules.</p>
          <p>The key is a <strong>twoâ€‘stage tuning paradigm</strong> that first learns pixelâ€‘ & semanticâ€‘level alignment (image reconstructionÂ + object segmentation) and then instructionâ€‘tunes on rich generation tasks (image recoveryÂ + subjectâ€‘driven generation). Despite using only <strong>3â€¯M</strong> training examples and a modest 2.3â€¯Bâ€‘parameter backbone, MENTOR matches or surpasses far larger diffusion systems on the challenging <em>DreamBench++</em> benchmark. îˆ€fileciteîˆ‚turn1file0îˆ</p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ============================= HIGHLIGHTS ============================= -->
<section class="section" id="highlights">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">ğŸŒŸ Highlights</h2>
        <div class="content has-text-justified">
          <table class="table is-striped is-fullwidth is-narrow">
            <thead><tr><th>Metric</th><th>DiffusionÂ SOTA</th><th><strong>MENTOR</strong></th></tr></thead>
            <tbody>
              <tr><td>CPÂ·PFÂ â†‘ (DreamBench++)</td><td>0.38Â (DreamEngine)</td><td><strong>0.47</strong> îˆ€fileciteîˆ‚turn1file5îˆ</td></tr>
              <tr><td>TrainingÂ data</td><td>16â€‘200â€¯M pairs</td><td><strong>3â€¯M</strong></td></tr>
              <tr><td>GPUÂ budget</td><td>256Â A100Â Ã—Â 3Â days</td><td><strong>8Â A100Â Ã—Â 1.5Â days</strong> îˆ€fileciteîˆ‚turn1file4îˆ</td></tr>
              <tr><td>Image reconstructionÂ â„“<sup>2</sup>Â â†“</td><td>0.206Â (DreamEngine)</td><td><strong>0.101</strong> îˆ€fileciteîˆ‚turn1file19îˆ</td></tr>
            </tbody>
          </table>
          <p class="is-size-6"><em>Smaller is better for â„“<sup>2</sup>; higher is better for CPÂ·PF.</em></p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ============================= WHY MENTOR ============================= -->
<section class="section" id="why">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">âœ¨ Why&nbsp;MENTOR?</h2>
        <div class="content has-text-justified">
          <p><strong>Tokenâ€‘level control</strong> â€” deterministic AR decoding avoids stochastic diffusion noise, enabling precise layout & identity preservation.</p>
          <p><strong>Balanced multimodal fusion</strong> â€” twoâ€‘stage tuning prevents overâ€‘reliance on either text or image, yielding the <em>lowest</em> CP/PF imbalance among baselines. îˆ€fileciteîˆ‚turn1file4îˆ</p>
          <p><strong>Trainingâ€‘friendly</strong> â€” 10Ã— less data and 30Ã— fewer GPU hours than diffusion counterparts.</p>
          <p><strong>Plugâ€‘andâ€‘play</strong> â€” a lightweight wrapper around any transformer generator; no model surgery or adapter stacks.</p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ============================= METHOD ============================= -->
<section class="section" id="method">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">ğŸ” Method â€” Twoâ€‘Stage Multimodalâ€‘Conditioned Tuning</h2>
        <div class="content has-text-justified">
          <p><img src="./static/images/method.png" alt="MENTOR method diagram"></p>
          <table class="table is-bordered is-fullwidth is-hoverable">
            <thead><tr><th>Stage</th><th>Tasks</th><th>Purpose</th></tr></thead>
            <tbody>
              <tr><td><strong>1Â Alignment</strong></td><td>Image reconstruction Â· Object segmentation Â· T2I</td><td>Pixelâ€‘ & semanticâ€‘level grounding of visual tokens</td></tr>
              <tr><td><strong>2Â InstructionÂ tuning</strong></td><td>Image recovery Â· Subjectâ€‘driven generation + Stageâ€‘1 tasks</td><td>Balanced integration of text & image, robust controllability</td></tr>
            </tbody>
          </table>
          <p>Under the hood, MENTOR encodes multimodal inputs with frozen CLIP & Flanâ€‘T5 encoders, projects them via a 2â€‘layer MLP, and feeds the compact prefix to a 775â€¯Mâ€‘parameter LlamaGen decoder that autoregressively emits VQGAN tokens. îˆ€fileciteîˆ‚turn1file11îˆ</p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ============================= PERFORMANCE RESULTS ============================= -->
<section class="section" id="results">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">ğŸ“ˆ Performance Results</h2>
        <div class="content has-text-justified">
          <p>On <em>DreamBench++</em>, MENTOR outperforms diffusionâ€‘based baselines such as Emu2 and DreamEngine by <strong>â‰ˆâ€¯30â€¯% CPÂ·PF</strong> while using a tenth of their training data. îˆ€fileciteîˆ‚turn1file5îˆ</p>
          <img src="./static/images/main_results.png" alt="Benchmark curves">
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ============================= EFFICIENCY RESULTS ============================= -->
<section class="section" id="efficiency">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">âš¡ï¸ Efficiency</h2>
        <div class="content has-text-justified">
          <p><strong>1.5Â daysÂ @Â 8Â Ã—Â A100</strong> vs. 3Â daysÂ @Â 256Â Ã—Â A100 for Kosmosâ€‘G, thanks to tiny prefix length and no diffusion sampling overhead. îˆ€fileciteîˆ‚turn1file4îˆ</p>
          <p>Constantâ€‘time generation â€” sequence length is bounded by <em>image tokensÂ +</em> prompt rather than multiâ€‘step diffusion.</p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ============================= COMPARISON ============================= -->
<section class="section" id="comparison">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">ğŸ” MENTOR vs. Diffusion Baselines</h2>
        <div class="content has-text-justified">
          <p>The heatâ€‘map below shows which tokens are preserved by MENTOR (hybrid tokenâ€‘importance score) versus a pureâ€‘attention diffusion baseline at the same generation step.</p>
          <img src="./static/images/comparison.png" alt="Token selection comparison">
          <h3 class="title is-5 mt-4">Key Findings</h3>
          <ul>
            <li><strong>Diverse Coverage</strong> â€” AR scoring picks tokens across the sequence rather than recentâ€‘token bias.</li>
            <li><strong>Higher Fidelity</strong> â€” faithfully reconstructs complex layouts & identities.</li>
            <li><strong>50Â % lower reconstruction error</strong> than strongest diffusion competitor. îˆ€fileciteîˆ‚turn1file19îˆ</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ============================= CITATION ============================= -->
<section class="section" id="citation">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">ğŸ“š Citation</h2>
        <div class="content has-text-justified">
          <p>If you find <strong>MENTOR</strong> useful, please cite:</p>
<pre><code>@misc{zhao2025mentor,
  title        = {MENTOR: Efficient Multimodal-Conditioned Tuning for Autoregressive Vision Generation Models},
  author       = {Haozhe Zhao and Zefan Cai and Shuzheng Si and Liang Chen and Jiuxiang Gu and Wen Xiao and Junjie Hu},
  year         = {2025},
  eprint       = {2506.01234},
  archivePrefix= {arXiv},
  primaryClass = {cs.CV},
  url          = {https://arxiv.org/abs/2506.01234}
}</code></pre>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ============================= FOOTER ============================= -->
<footer class="footer has-background-dark">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="./static/MENTOR_paper.pdf"><i class="fas fa-file-pdf" style="color:white"></i></a>
      <a class="icon-link" href="https://github.com/mentor-project/MENTOR"><i class="fab fa-github" style="color:white"></i></a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-grey-light">
          <p>This website is released under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attributionâ€‘ShareAlikeÂ 4.0 International License</a>.</p>
          <p>Adapted from templates by <a href="https://nerfies.github.io/">Nerfies</a> and <a href="https://rkv-project.github.io/">Râ€‘KV</a>; we thank their authors.</p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
