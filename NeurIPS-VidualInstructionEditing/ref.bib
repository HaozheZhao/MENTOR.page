@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@article{zhao2024bridging,
  title={Bridging Different Language Models and Generative Vision Models for Text-to-Image Generation},
  author={Zhao, Shihao and Hao, Shaozhe and Zi, Bojia and Xu, Huaizhe and Wong, Kwan-Yee~K.},
  journal={ECCV},
  year={2024}
}

@misc{controlnet,
  title={Adding Conditional Control to Text-to-Image Diffusion Models}, 
  author={Lvmin Zhang and Anyi Rao and Maneesh Agrawala},
  booktitle={IEEE International Conference on Computer Vision (ICCV)},
  year={2023},
}

@article{ye2023ip-adapter,
  title={IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models},
  author={Ye, Hu and Zhang, Jun and Liu, Sibo and Han, Xiao and Yang, Wei},
  booktitle={arXiv preprint arxiv:2308.06721},
  year={2023}
}


@misc{chen2024tokenpredictionmultimodalintelligence,title={Next Token Prediction Towards Multimodal Intelligence: A Comprehensive Survey}, 
      author={Liang Chen and Zekun Wang and Shuhuai Ren and Lei Li and Haozhe Zhao and Yunshui Li and Zefan Cai and Hongcheng Guo and Lei Zhang and Yizhe Xiong and Yichi Zhang and Ruoyu Wu and Qingxiu Dong and Ge Zhang and Jian Yang and Lingwei Meng and Shujie Hu and Yulong Chen and Junyang Lin and Shuai Bai and Andreas Vlachos and Xu Tan and Minjia Zhang and Wen Xiao and Aaron Yee and Tianyu Liu and Baobao Chang},
      year={2024},
      eprint={2412.18619},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.18619}, 
}

@misc{chen2024tokenpredictionmultimodalintelligence,
      title={Next Token Prediction Towards Multimodal Intelligence: A Comprehensive Survey}, 
      author={Liang Chen and Zekun Wang and Shuhuai Ren and Lei Li and Haozhe Zhao and Yunshui Li and Zefan Cai and Hongcheng Guo and Lei Zhang and Yizhe Xiong and Yichi Zhang and Ruoyu Wu and Qingxiu Dong and Ge Zhang and Jian Yang and Lingwei Meng and Shujie Hu and Yulong Chen and Junyang Lin and Shuai Bai and Andreas Vlachos and Xu Tan and Minjia Zhang and Wen Xiao and Aaron Yee and Tianyu Liu and Baobao Chang},
      year={2024},
      eprint={2412.18619},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.18619}, 
}

@misc{karras2022elucidatingdesignspacediffusionbased,
      title={Elucidating the Design Space of Diffusion-Based Generative Models}, 
      author={Tero Karras and Miika Aittala and Timo Aila and Samuli Laine},
      year={2022},
      eprint={2206.00364},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2206.00364}, 
}

@misc{liu2022flowstraightfastlearning,
      title={Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow}, 
      author={Xingchao Liu and Chengyue Gong and Qiang Liu},
      year={2022},
      eprint={2209.03003},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2209.03003}, 
}


@misc{huang2023languageneedaligningperception,
      title={Language Is Not All You Need: Aligning Perception with Language Models}, 
      author={Shaohan Huang and Li Dong and Wenhui Wang and Yaru Hao and Saksham Singhal and Shuming Ma and Tengchao Lv and Lei Cui and Owais Khan Mohammed and Barun Patra and Qiang Liu and Kriti Aggarwal and Zewen Chi and Johan Bjorck and Vishrav Chaudhary and Subhojit Som and Xia Song and Furu Wei},
      year={2023},
      eprint={2302.14045},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.14045}, 
}

@misc{peng2023kosmos2groundingmultimodallarge,
      title={Kosmos-2: Grounding Multimodal Large Language Models to the World}, 
      author={Zhiliang Peng and Wenhui Wang and Li Dong and Yaru Hao and Shaohan Huang and Shuming Ma and Furu Wei},
      year={2023},
      eprint={2306.14824},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.14824}, 
}

@misc{lv2024kosmos25multimodalliteratemodel,
      title={KOSMOS-2.5: A Multimodal Literate Model}, 
      author={Tengchao Lv and Yupan Huang and Jingye Chen and Yuzhong Zhao and Yilin Jia and Lei Cui and Shuming Ma and Yaoyao Chang and Shaohan Huang and Wenhui Wang and Li Dong and Weiyao Luo and Shaoxiang Wu and Guoxin Wang and Cha Zhang and Furu Wei},
      year={2024},
      eprint={2309.11419},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.11419}, 
}

@misc{sun2024multimodallatentlanguagemodeling,
      title={Multimodal Latent Language Modeling with Next-Token Diffusion}, 
      author={Yutao Sun and Hangbo Bao and Wenhui Wang and Zhiliang Peng and Li Dong and Shaohan Huang and Jianyong Wang and Furu Wei},
      year={2024},
      eprint={2412.08635},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.08635}, 
}

@article{
peng2023a,
title={A Unified View of Masked Image Modeling},
author={Zhiliang Peng and Li Dong and Hangbo Bao and Furu Wei and Qixiang Ye},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=wmGlMhaBe0},
note={}
}

@misc{peng2022beitv2maskedimage,
      title={BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers}, 
      author={Zhiliang Peng and Li Dong and Hangbo Bao and Qixiang Ye and Furu Wei},
      year={2022},
      eprint={2208.06366},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2208.06366}, 
}

@inproceedings{
huang2024proteinligand,
title={Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models},
author={Zhilin Huang and Ling Yang and Xiangxin Zhou and Zhilong Zhang and Wentao Zhang and Xiawu Zheng and Jie Chen and Yu Wang and Bin CUI and Wenming Yang},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=qH9nrMNTIW}
}

@misc{chi2024diffusionpolicyvisuomotorpolicy,
      title={Diffusion Policy: Visuomotor Policy Learning via Action Diffusion}, 
      author={Cheng Chi and Zhenjia Xu and Siyuan Feng and Eric Cousineau and Yilun Du and Benjamin Burchfiel and Russ Tedrake and Shuran Song},
      year={2024},
      eprint={2303.04137},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2303.04137}, 
}

@misc{li2022diffusionlmimprovescontrollabletext,
      title={Diffusion-LM Improves Controllable Text Generation}, 
      author={Xiang Lisa Li and John Thickstun and Ishaan Gulrajani and Percy Liang and Tatsunori B. Hashimoto},
      year={2022},
      eprint={2205.14217},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2205.14217}, 
}

@misc{yang2024diffusionmodelscomprehensivesurvey,
      title={Diffusion Models: A Comprehensive Survey of Methods and Applications}, 
      author={Ling Yang and Zhilong Zhang and Yang Song and Shenda Hong and Runsheng Xu and Yue Zhao and Wentao Zhang and Bin Cui and Ming-Hsuan Yang},
      year={2024},
      eprint={2209.00796},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2209.00796}, 
}

@inproceedings{
anonymous2024next,
title={Next Block Prediction: Video Generation via Semi-Auto-Regressive Modeling},
author={Anonymous},
booktitle={Submitted to The Thirteenth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=JUYBEmwSJK},
note={under review}
}

@article{Bradley1952RankAO,
  title={Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons},
  author={Ralph Allan Bradley and Milton E. Terry},
  journal={Biometrika},
  year={1952},
  volume={39},
  pages={324},
  url={https://api.semanticscholar.org/CorpusID:125209808}
}

@misc{soldaini2024dolmaopencorpustrillion,
      title={Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research}, 
      author={Luca Soldaini and Rodney Kinney and Akshita Bhagia and Dustin Schwenk and David Atkinson and Russell Authur and Ben Bogin and Khyathi Chandu and Jennifer Dumas and Yanai Elazar and Valentin Hofmann and Ananya Harsh Jha and Sachin Kumar and Li Lucy and Xinxi Lyu and Nathan Lambert and Ian Magnusson and Jacob Morrison and Niklas Muennighoff and Aakanksha Naik and Crystal Nam and Matthew E. Peters and Abhilasha Ravichander and Kyle Richardson and Zejiang Shen and Emma Strubell and Nishant Subramani and Oyvind Tafjord and Pete Walsh and Luke Zettlemoyer and Noah A. Smith and Hannaneh Hajishirzi and Iz Beltagy and Dirk Groeneveld and Jesse Dodge and Kyle Lo},
      year={2024},
      eprint={2402.00159},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.00159}, 
}

@misc{han2024infinityscalingbitwiseautoregressive,
      title={Infinity: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis}, 
      author={Jian Han and Jinlai Liu and Yi Jiang and Bin Yan and Yuqi Zhang and Zehuan Yuan and Bingyue Peng and Xiaobing Liu},
      year={2024},
      eprint={2412.04431},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.04431}, 
}
@misc{midjourney-niji-1m-llavanext,
  author = { Caption Emporium },
  title = { midjourney-niji-1m-llavanext },
  year = { 2024 },
  publisher = { Huggingface },
  journal = { Huggingface repository },
  howpublished = {\url{https://huggingface.co/datasets/CaptionEmporium/conceptual-captions-cc12m-llavanext}},
}
@inproceedings{unimo,
    title = "{UNIMO}-{G}: Unified Image Generation through Multimodal Conditional Diffusion",
    author = "Li, Wei  and
      Xu, Xue  and
      Liu, Jiachen  and
      Xiao, Xinyan",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.335/",
    doi = "10.18653/v1/2024.acl-long.335",
    pages = "6173--6188",
    abstract = "Existing text-to-image diffusion models primarily generate images from text prompts. However, the inherent conciseness of textual descriptions poses challenges in faithfully synthesizing images with intricate details, such as specific entities or scenes. This paper presents UNIMO-G, a simple multimodal conditional diffusion framework that operates on multimodal prompts with interleaved textual and visual inputs, which demonstrates a unified ability for both text-driven and subject-driven image generation. UNIMO-G comprises two core components: a Multimodal Large Language Model (MLLM) for encoding multimodal prompts, and a conditional denoising diffusion network for generating images based on the encoded multimodal input. We leverage a two-stage training strategy to effectively train the framework: firstly pre-training on large-scale text-image pairs to develop conditional image generation capabilities, and then instruction tuning with multimodal prompts to achieve unified image generation proficiency. A well-designed data processing pipeline involving language grounding and image segmentation is employed to construct multi-modal prompts. UNIMO-G excels in both text-to-image generation and zero-shot subject-driven synthesis, and is notably effective in generating high-fidelity images from complex multimodal prompts involving multiple image entities."
}
@misc{yang2025multipartycollaborativeattentioncontrol,
      title={Multi-party Collaborative Attention Control for Image Customization}, 
      author={Han Yang and Chuanguang Yang and Qiuli Wang and Zhulin An and Weilun Feng and Libo Huang and Yongjun Xu},
      year={2025},
      eprint={2505.01428},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2505.01428}, 
}
@misc{RealCustom++,
      title={RealCustom++: Representing Images as Real-Word for Real-Time Customization}, 
      author={Zhendong Mao and Mengqi Huang and Fei Ding and Mingcong Liu and Qian He and Yongdong Zhang},
      year={2024},
      eprint={2408.09744},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.09744}, 
}
@misc{wang2025imageeditingdiffusionmodels,
      title={Image Editing with Diffusion Models: A Survey}, 
      author={Jia Wang and Jie Hu and Xiaoqi Ma and Hanghang Ma and Xiaoming Wei and Enhua Wu},
      year={2025},
      eprint={2504.13226},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2504.13226}, 
}
@misc{OminiControl,
      title={OminiControl: Minimal and Universal Control for Diffusion Transformer}, 
      author={Zhenxiong Tan and Songhua Liu and Xingyi Yang and Qiaochu Xue and Xinchao Wang},
      year={2025},
      eprint={2411.15098},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.15098}, 
}
@misc{FLUXSynID,
      title={FLUXSynID: A Framework for Identity-Controlled Synthetic Face Generation with Document and Live Images}, 
      author={Raul Ismayilov and Dzemila Sero and Luuk Spreeuwers},
      year={2025},
      eprint={2505.07530},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2505.07530}, 
}
@misc{Mix-of-Show,
      title={Mix-of-Show: Decentralized Low-Rank Adaptation for Multi-Concept Customization of Diffusion Models}, 
      author={Yuchao Gu and Xintao Wang and Jay Zhangjie Wu and Yujun Shi and Yunpeng Chen and Zihan Fan and Wuyou Xiao and Rui Zhao and Shuning Chang and Weijia Wu and Yixiao Ge and Ying Shan and Mike Zheng Shou},
      year={2023},
      eprint={2305.18292},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2305.18292}, 
}
@misc{peng2025dreambenchpp,
      title={DreamBench++: A Human-Aligned Benchmark for Personalized Image Generation}, 
      author={Yuang Peng and Yuxin Cui and Haomiao Tang and Zekun Qi and Runpei Dong and Jing Bai and Chunrui Han and Zheng Ge and Xiangyu Zhang and Shu-Tao Xia},
      year={2025},
      eprint={2406.16855},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.16855}, 
}
@misc{flant5,
      title={Scaling Instruction-Finetuned Language Models}, 
      author={Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
      year={2022},
      eprint={2210.11416},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2210.11416}, 
}
@misc{dreamengine,
      title={Multimodal Representation Alignment for Image Generation: Text-Image Interleaved Control Is Easier Than You Think}, 
      author={Liang Chen and Shuai Bai and Wenhao Chai and Weichu Xie and Haozhe Zhao and Leon Vinci and Junyang Lin and Baobao Chang},
      year={2025},
      eprint={2502.20172},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2502.20172}, 
}
@article{Flam_Shepherd_2022,
   title={Language models can learn complex molecular distributions},
   volume={13},
   ISSN={2041-1723},
   url={http://dx.doi.org/10.1038/s41467-022-30839-x},
   DOI={10.1038/s41467-022-30839-x},
   number={1},
   journal={Nature Communications},
   publisher={Springer Science and Business Media LLC},
   author={Flam-Shepherd, Daniel and Zhu, Kevin and Aspuru-Guzik, Alán},
   year={2022},
   month=jun }
@misc{Dig2DIG,
      title={Dig2DIG: Dig into Diffusion Information Gains for Image Fusion}, 
      author={Bing Cao and Baoshuo Cai and Changqing Zhang and Qinghua Hu},
      year={2025},
      eprint={2503.18627},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.18627}, 
}
@misc{huang2023diffstylercontrollabledualdiffusion,
      title={DiffStyler: Controllable Dual Diffusion for Text-Driven Image Stylization}, 
      author={Nisha Huang and Yuxin Zhang and Fan Tang and Chongyang Ma and Haibin Huang and Yong Zhang and Weiming Dong and Changsheng Xu},
      year={2023},
      eprint={2211.10682},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2211.10682}, 
}
@article{Ruffolo2024DesigningPW,
  title={Designing proteins with language models},
  author={Jeffrey A. Ruffolo and Ali Madani},
  journal={Nature Biotechnology},
  year={2024},
  volume={42},
  pages={200-202},
  url={https://api.semanticscholar.org/CorpusID:267682839}
}

@misc{baykal2024edvaemitigatingcodebookcollapse,
      title={EdVAE: Mitigating Codebook Collapse with Evidential Discrete Variational Autoencoders}, 
      author={Gulcin Baykal and Melih Kandemir and Gozde Unal},
      year={2024},
      eprint={2310.05718},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2310.05718}, 
}

@misc{wan2024efficientlargelanguagemodels,
      title={Efficient Large Language Models: A Survey}, 
      author={Zhongwei Wan and Xin Wang and Che Liu and Samiul Alam and Yu Zheng and Jiachen Liu and Zhongnan Qu and Shen Yan and Yi Zhu and Quanlu Zhang and Mosharaf Chowdhury and Mi Zhang},
      year={2024},
      eprint={2312.03863},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.03863}, 
}

@article{Menghani_2023,
   title={Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better},
   volume={55},
   ISSN={1557-7341},
   url={http://dx.doi.org/10.1145/3578938},
   DOI={10.1145/3578938},
   number={12},
   journal={ACM Computing Surveys},
   publisher={Association for Computing Machinery (ACM)},
   author={Menghani, Gaurav},
   year={2023},
   month=mar, pages={1–37} }

@misc{jiang2024surveyvisionautoregressivemodel,
      title={A Survey on Vision Autoregressive Model}, 
      author={Kai Jiang and Jiaxing Huang},
      year={2024},
      eprint={2411.08666},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.08666}, 
}

@misc{jin2024efficientmultimodallargelanguage,
      title={Efficient Multimodal Large Language Models: A Survey}, 
      author={Yizhang Jin and Jian Li and Yexin Liu and Tianjun Gu and Kai Wu and Zhengkai Jiang and Muyang He and Bo Zhao and Xin Tan and Zhenye Gan and Yabiao Wang and Chengjie Wang and Lizhuang Ma},
      year={2024},
      eprint={2405.10739},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.10739}, 
}

@misc{huang2024surveyevaluationmultimodallarge,
      title={A Survey on Evaluation of Multimodal Large Language Models}, 
      author={Jiaxing Huang and Jingyi Zhang},
      year={2024},
      eprint={2408.15769},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.15769}, 
}

@misc{fu2024mmesurveycomprehensivesurveyevaluation,
      title={MME-Survey: A Comprehensive Survey on Evaluation of Multimodal LLMs}, 
      author={Chaoyou Fu and Yi-Fan Zhang and Shukang Yin and Bo Li and Xinyu Fang and Sirui Zhao and Haodong Duan and Xing Sun and Ziwei Liu and Liang Wang and Caifeng Shan and Ran He},
      year={2024},
      eprint={2411.15296},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.15296}, 
}

@misc{crawshaw2020multitasklearningdeepneural,
      title={Multi-Task Learning with Deep Neural Networks: A Survey}, 
      author={Michael Crawshaw},
      year={2020},
      eprint={2009.09796},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2009.09796}, 
}

@article{latif2023sparks,
  title={Sparks of Large Audio Models: A Survey and Outlook},
  author={Latif, Siddique and Shoukat, Moazzam and Shamshad, Fahad and Usama, Muhammad and Cuay{\'a}huitl, Heriberto and Schuller, Bj{\"o}rn W},
  journal={arXiv preprint arXiv:2308.12792},
  year={2023}
}

@article{luo2024deem,
  title={Deem: Diffusion models serve as the eyes of large language models for image perception},
  author={Luo, Run and Li, Yunshui and Chen, Longze and He, Wanwei and Lin, Ting-En and Liu, Ziqiang and Zhang, Lei and Song, Zikai and Xia, Xiaobo and Liu, Tongliang and others},
  journal={arXiv preprint arXiv:2405.15232},
  year={2024}
}
@article{luo2024mmevol,
  title={Mmevol: Empowering multimodal large language models with evol-instruct},
  author={Luo, Run and Zhang, Haonan and Chen, Longze and Lin, Ting-En and Liu, Xiong and Wu, Yuchuan and Yang, Min and Wang, Minzheng and Zeng, Pengpeng and Gao, Lianli and others},
  journal={arXiv preprint arXiv:2409.05840},
  year={2024}
}
@misc{song2024moviechatdensetokensparse,
      title={MovieChat: From Dense Token to Sparse Memory for Long Video Understanding}, 
      author={Enxin Song and Wenhao Chai and Guanhong Wang and Yucheng Zhang and Haoyang Zhou and Feiyang Wu and Haozhe Chi and Xun Guo and Tian Ye and Yanting Zhang and Yan Lu and Jenq-Neng Hwang and Gaoang Wang},
      year={2024},
      eprint={2307.16449},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.16449}, 
}

@misc{heusel2018ganstrainedtimescaleupdate,
      title={GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium}, 
      author={Martin Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and Sepp Hochreiter},
      year={2018},
      eprint={1706.08500},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1706.08500}, 
}

@article{10.1109/TPAMI.2018.2798607,
author = {Baltrusaitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
title = {Multimodal Machine Learning: A Survey and Taxonomy},
year = {2019},
issue_date = {February 2019},
publisher = {IEEE Computer Society},
address = {USA},
volume = {41},
number = {2},
issn = {0162-8828},
url = {https://doi.org/10.1109/TPAMI.2018.2798607},
doi = {10.1109/TPAMI.2018.2798607},
abstract = {Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = feb,
pages = {423–443},
numpages = {21}
}

@misc{hao2022languagemodelsgeneralpurposeinterfaces,
      title={Language Models are General-Purpose Interfaces}, 
      author={Yaru Hao and Haoyu Song and Li Dong and Shaohan Huang and Zewen Chi and Wenhui Wang and Shuming Ma and Furu Wei},
      year={2022},
      eprint={2206.06336},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.06336}, 
}

@misc{huang2024mmevalprocalibratingmultimodalbenchmarks,
      title={MMEvalPro: Calibrating Multimodal Benchmarks Towards Trustworthy and Efficient Evaluation}, 
      author={Jinsheng Huang and Liang Chen and Taian Guo and Fu Zeng and Yusheng Zhao and Bohan Wu and Ye Yuan and Haozhe Zhao and Zhihui Guo and Yichi Zhang and Jingyang Yuan and Wei Ju and Luchen Liu and Tianyu Liu and Baobao Chang and Ming Zhang},
      year={2024},
      eprint={2407.00468},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.00468}, 
}

@article{chen2023endtoend,
      title={Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond}, 
      author={Liang Chen and Yichi Zhang and Shuhuai Ren and Haozhe Zhao and Zefan Cai and Yuchi Wang and Peiyi Wang and Tianyu Liu and Baobao Chang},
      year={2023},
      journal={ArXiv},
}

@misc{zhang2023sirenssongaiocean,
      title={Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models}, 
      author={Yue Zhang and Yafu Li and Leyang Cui and Deng Cai and Lemao Liu and Tingchen Fu and Xinting Huang and Enbo Zhao and Yu Zhang and Yulong Chen and Longyue Wang and Anh Tuan Luu and Wei Bi and Freda Shi and Shuming Shi},
      year={2023},
      eprint={2309.01219},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.01219}, 
}

@misc{cobbe2021trainingverifierssolvemath,
      title={Training Verifiers to Solve Math Word Problems}, 
      author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
      year={2021},
      eprint={2110.14168},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.14168}, 
}

@misc{zhang2024videoincontextlearning,
      title={Video In-context Learning}, 
      author={Wentao Zhang and Junliang Guo and Tianyu He and Li Zhao and Linli Xu and Jiang Bian},
      year={2024},
      eprint={2407.07356},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.07356}, 
}

@article{zeng2024can,
  title={Can MLLMs Perform Text-to-Image In-Context Learning?},
  author={Zeng, Yuchen and Kang, Wonjun and Chen, Yicong and Koo, Hyung Il and Lee, Kangwook},
  journal={arXiv preprint arXiv:2402.01293},
  year={2024}
}

@misc{ghosh2023genevalobjectfocusedframeworkevaluating,
      title={GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment}, 
      author={Dhruba Ghosh and Hanna Hajishirzi and Ludwig Schmidt},
      year={2023},
      eprint={2310.11513},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2310.11513}, 
}

@misc{jiang2024manyshotincontextlearningmultimodal,
      title={Many-Shot In-Context Learning in Multimodal Foundation Models}, 
      author={Yixing Jiang and Jeremy Irvin and Ji Hun Wang and Muhammad Ahmed Chaudhry and Jonathan H. Chen and Andrew Y. Ng},
      year={2024},
      eprint={2405.09798},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.09798}, 
}

@article{JMLR:v25:23-0870,
  author  = {Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
  title   = {Scaling Instruction-Finetuned Language Models},
  journal = {Journal of Machine Learning Research},
  year    = {2024},
  volume  = {25},
  number  = {70},
  pages   = {1--53},
  url     = {http://jmlr.org/papers/v25/23-0870.html}
}

@misc{vatsal2024surveypromptengineeringmethods,
      title={A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks}, 
      author={Shubham Vatsal and Harsh Dubey},
      year={2024},
      eprint={2407.12994},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.12994}, 
}

@misc{zhang2024pretrainedlanguagemodelshelp,
      title={Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation}, 
      author={Yuhui Zhang and Brandon McKinzie and Zhe Gan and Vaishaal Shankar and Alexander Toshev},
      year={2024},
      eprint={2311.16201},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2311.16201}, 
}

@misc{henry2020querykeynormalizationtransformers,
      title={Query-Key Normalization for Transformers}, 
      author={Alex Henry and Prudhvi Raj Dachapally and Shubham Pawar and Yuxuan Chen},
      year={2020},
      eprint={2010.04245},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2010.04245}, 
}

@misc{RAR,
      title={Randomized Autoregressive Visual Generation}, 
      author={Qihang Yu and Ju He and Xueqing Deng and Xiaohui Shen and Liang-Chieh Chen},
      year={2024},
      eprint={2411.00776},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.00776}, 
}
@misc{zhai2023sigmoidlosslanguageimage,
      title={Sigmoid Loss for Language Image Pre-Training}, 
      author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
      year={2023},
      eprint={2303.15343},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2303.15343}, 
}
@misc{johnson2016perceptuallossesrealtimestyle,
      title={Perceptual Losses for Real-Time Style Transfer and Super-Resolution}, 
      author={Justin Johnson and Alexandre Alahi and Li Fei-Fei},
      year={2016},
      eprint={1603.08155},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1603.08155}, 
}

@misc{larsen2016autoencodingpixelsusinglearned,
      title={Autoencoding beyond pixels using a learned similarity metric}, 
      author={Anders Boesen Lindbo Larsen and Søren Kaae Sønderby and Hugo Larochelle and Ole Winther},
      year={2016},
      eprint={1512.09300},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1512.09300}, 
}

@misc{midas,
      title={Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer}, 
      author={René Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun},
      year={2020},
      eprint={1907.01341},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1907.01341}, 
}

@misc{vitdet,
      title={Exploring Plain Vision Transformer Backbones for Object Detection}, 
      author={Yanghao Li and Hanzi Mao and Ross Girshick and Kaiming He},
      year={2022},
      eprint={2203.16527},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2203.16527}, 
}

@misc{he2021maskedautoencodersscalablevision,
      title={Masked Autoencoders Are Scalable Vision Learners}, 
      author={Kaiming He and Xinlei Chen and Saining Xie and Yanghao Li and Piotr Dollár and Ross Girshick},
      year={2021},
      eprint={2111.06377},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2111.06377}, 
}

@misc{yang2024visionmodelpretraininginterleaved,
      title={Vision Model Pre-training on Interleaved Image-Text Data via Latent Compression Learning}, 
      author={Chenyu Yang and Xizhou Zhu and Jinguo Zhu and Weijie Su and Junjie Wang and Xuan Dong and Wenhai Wang and Lewei Lu and Bin Li and Jie Zhou and Yu Qiao and Jifeng Dai},
      year={2024},
      eprint={2406.07543},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.07543}, 
}

@misc{hoffmann2022trainingcomputeoptimallargelanguage,
      title={Training Compute-Optimal Large Language Models}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      eprint={2203.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.15556}, 
}

@misc{sun2024scalinglawhypothesismultimodal,
      title={Scaling Law Hypothesis for Multimodal Model}, 
      author={Qingyun Sun and Zhen Guo},
      year={2024},
      eprint={2409.06754},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.06754}, 
}

@misc{aghajanyan2023scalinglawsgenerativemixedmodal,
      title={Scaling Laws for Generative Mixed-Modal Language Models}, 
      author={Armen Aghajanyan and Lili Yu and Alexis Conneau and Wei-Ning Hsu and Karen Hambardzumyan and Susan Zhang and Stephen Roller and Naman Goyal and Omer Levy and Luke Zettlemoyer},
      year={2023},
      eprint={2301.03728},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2301.03728}, 
}

@article{luo2022clip4clip,
  title={Clip4clip: An empirical study of clip for end to end video clip retrieval and captioning},
  author={Luo, Huaishao and Ji, Lei and Zhong, Ming and Chen, Yang and Lei, Wen and Duan, Nan and Li, Tianrui},
  journal={Neurocomputing},
  volume={508},
  pages={293--304},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{ren2024timechat,
  title={Timechat: A time-sensitive multimodal large language model for long video understanding},
  author={Ren, Shuhuai and Yao, Linli and Li, Shicheng and Sun, Xu and Hou, Lu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14313--14323},
  year={2024}
}

@article{ren2023testa,
  title={TESTA: Temporal-spatial token aggregation for long-form video-language understanding},
  author={Ren, Shuhuai and Chen, Sishuo and Li, Shicheng and Sun, Xu and Hou, Lu},
  journal={arXiv preprint arXiv:2310.19060},
  year={2023}
}

@article{gong2021ast,
  title={Ast: Audio spectrogram transformer},
  author={Gong, Yuan and Chung, Yu-An and Glass, James},
  journal={arXiv preprint arXiv:2104.01778},
  year={2021}
}


@misc{vllm,
      title={Efficient Memory Management for Large Language Model Serving with PagedAttention}, 
      author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
      year={2023},
      eprint={2309.06180},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2309.06180}, 
}

@misc{flash-attention,
      title={FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness}, 
      author={Tri Dao and Daniel Y. Fu and Stefano Ermon and Atri Rudra and Christopher Ré},
      year={2022},
      eprint={2205.14135},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2205.14135}, 
}

@misc{li2023multimodalfoundationmodelsspecialists,
      title={Multimodal Foundation Models: From Specialists to General-Purpose Assistants}, 
      author={Chunyuan Li and Zhe Gan and Zhengyuan Yang and Jianwei Yang and Linjie Li and Lijuan Wang and Jianfeng Gao},
      year={2023},
      eprint={2309.10020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2309.10020}, 
}

@misc{xie2024showosingletransformerunify,
      title={Show-o: One Single Transformer to Unify Multimodal Understanding and Generation}, 
      author={Jinheng Xie and Weijia Mao and Zechen Bai and David Junhao Zhang and Weihao Wang and Kevin Qinghong Lin and Yuchao Gu and Zhijie Chen and Zhenheng Yang and Mike Zheng Shou},
      year={2024},
      eprint={2408.12528},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.12528}, 
}

@misc{chen2024sparkvisionlanguageintelligence2dimensional,
      title={A Spark of Vision-Language Intelligence: 2-Dimensional Autoregressive Transformer for Efficient Finegrained Image Generation}, 
      author={Liang Chen and Sinan Tan and Zefan Cai and Weichu Xie and Haozhe Zhao and Yichi Zhang and Junyang Lin and Jinze Bai and Tianyu Liu and Baobao Chang},
      year={2024},
      eprint={2410.01912},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.01912}, 
}

@misc{wang2024emu3nexttokenpredictionneed,
      title={Emu3: Next-Token Prediction is All You Need}, 
      author={Xinlong Wang and Xiaosong Zhang and Zhengxiong Luo and Quan Sun and Yufeng Cui and Jinsheng Wang and Fan Zhang and Yueze Wang and Zhen Li and Qiying Yu and Yingli Zhao and Yulong Ao and Xuebin Min and Tao Li and Boya Wu and Bo Zhao and Bowen Zhang and Liangdong Wang and Guang Liu and Zheqi He and Xi Yang and Jingjing Liu and Yonghua Lin and Tiejun Huang and Zhongyuan Wang},
      year={2024},
      eprint={2409.18869},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.18869}, 
}

@article{flam2022language,
  title={Language models can learn complex molecular distributions},
  author={Flam-Shepherd, Daniel and Zhu, Kevin and Aspuru-Guzik, Al{\'a}n},
  journal={Nature Communications},
  volume={13},
  number={1},
  pages={3293},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@misc{benegas2024genomiclanguagemodelsopportunities,
      title={Genomic Language Models: Opportunities and Challenges}, 
      author={Gonzalo Benegas and Chengzhong Ye and Carlos Albors and Jianan Canal Li and Yun S. Song},
      year={2024},
      eprint={2407.11435},
      archivePrefix={arXiv},
      primaryClass={q-bio.GN},
      url={https://arxiv.org/abs/2407.11435}, 
}

@misc{défossez2024moshispeechtextfoundationmodel,
      title={Moshi: a speech-text foundation model for real-time dialogue}, 
      author={Alexandre Défossez and Laurent Mazaré and Manu Orsini and Amélie Royer and Patrick Pérez and Herv\'{e} J\'{e}gou and Edouard Grave and Neil Zeghidour},
      year={2024},
      eprint={2410.00037},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2410.00037}, 
}

@inproceedings{furui1986speaker,
  title={Speaker-independent isolated word recognition based on emphasized spectral dynamics},
  author={Furui, Sadaoki},
  booktitle={ICASSP'86. IEEE International Conference on Acoustics, Speech, and Signal Processing},
  volume={11},
  pages={1991--1994},
  year={1986},
  organization={IEEE}
}

@article{duhamel1990fast,
  title={Fast Fourier transforms: a tutorial review and a state of the art},
  author={Duhamel, Pierre and Vetterli, Martin},
  journal={Signal processing},
  volume={19},
  number={4},
  pages={259--299},
  year={1990},
  publisher={Elsevier}
}

@article{griffin1984signal,
  title={Signal estimation from modified short-time Fourier transform},
  author={Griffin, Daniel and Lim, Jae},
  journal={IEEE Transactions on acoustics, speech, and signal processing},
  volume={32},
  number={2},
  pages={236--243},
  year={1984},
  publisher={IEEE}
}

@article{braun2024dac,
  title={DAC-JAX: A JAX Implementation of the Descript Audio Codec},
  author={Braun, David},
  journal={arXiv preprint arXiv:2405.11554},
  year={2024}
}

@misc{dhariwal2021diffusionmodelsbeatgans,
      title={Diffusion Models Beat GANs on Image Synthesis}, 
      author={Prafulla Dhariwal and Alex Nichol},
      year={2021},
      eprint={2105.05233},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2105.05233}, 
}

@misc{bengio2013estimatingpropagatinggradientsstochastic,
      title={Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation}, 
      author={Yoshua Bengio and Nicholas Léonard and Aaron Courville},
      year={2013},
      eprint={1308.3432},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1308.3432}, 
}

@misc{dieleman2022diffusion,
  author = {Dieleman, Sander},
  title = {Diffusion models are autoencoders},
  url = {https://benanne.github.io/2022/01/31/diffusion.html},
  year = {2022}
}

@misc{cunningham2023sparse,
      title={Sparse Autoencoders Find Highly Interpretable Features in Language Models}, 
      author={Hoagy Cunningham and Aidan Ewart and Logan Riggs and Robert Huben and Lee Sharkey},
      year={2023},
      eprint={2309.08600},
      archivePrefix={arXiv},
}

@misc{kingma2022autoencoding,
      title={Auto-Encoding Variational Bayes}, 
      author={Diederik P Kingma and Max Welling},
      year={2022},
      eprint={1312.6114},
      archivePrefix={arXiv},
}

@misc{caron2021emerging,
      title={Emerging Properties in Self-Supervised Vision Transformers}, 
      author={Mathilde Caron and Hugo Touvron and Ishan Misra and Herv\'{e} J\'{e}gou and Julien Mairal and Piotr Bojanowski and Armand Joulin},
      year={2021},
      eprint={2104.14294},
      archivePrefix={arXiv},
}

@misc{li2024autoregressive-without,
      title={Autoregressive Image Generation without Vector Quantization}, 
      author={Tianhong Li and Yonglong Tian and He Li and Mingyang Deng and Kaiming He},
      year={2024},
      eprint={2406.11838},
      archivePrefix={arXiv},
}

@article{Chameleon_Team_Chameleon_Mixed-Modal_Early-Fusion_2024,
  author = {Chameleon Team},
  doi = {10.48550/arXiv.2405.09818},
  journal = {arXiv preprint arXiv:2405.09818},
  title = {Chameleon: Mixed-Modal Early-Fusion Foundation Models},
  url = {https://github.com/facebookresearch/chameleon},
  year = {2024}
}


@inproceedings{zhu2021musicbert,
  title={MusicBERT: A self-supervised learning of music representation},
  author={Zhu, Hongyuan and Niu, Ye and Fu, Di and Wang, Hao},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={3955--3963},
  year={2021}
}

@article{li2022map,
  title={Map-music2vec: A simple and effective baseline for self-supervised music audio representation learning},
  author={Li, Yizhi and Yuan, Ruibin and Zhang, Ge and Ma, Yinghao and Lin, Chenghua and Chen, Xingran and Ragni, Anton and Yin, Hanzhi and Hu, Zhijie and He, Haoyu and others},
  journal={arXiv preprint arXiv:2212.02508},
  year={2022}
}

@article{hussain2023m,
  title={M$^{2}$ UGen: Multi-modal Music Understanding and Generation with the Power of Large Language Models},
  author={Hussain, Atin Sakkeer and Liu, Shansong and Sun, Chenshuo and Shan, Ying},
  journal={arXiv preprint arXiv:2311.11255},
  year={2023}
}
@misc{phi3_5,
      title={Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone}, 
      author={Marah Abdin and Jyoti Aneja and Hany Awadalla and Ahmed Awadallah and Ammar Ahmad Awan and Nguyen Bach and Amit Bahree and Arash Bakhtiari and Jianmin Bao and Harkirat Behl and Alon Benhaim and Misha Bilenko and Johan Bjorck and Sébastien Bubeck and Martin Cai and Qin Cai and Vishrav Chaudhary and Dong Chen and Dongdong Chen and Weizhu Chen and Yen-Chun Chen and Yi-Ling Chen and Hao Cheng and Parul Chopra and Xiyang Dai and Matthew Dixon and Ronen Eldan and Victor Fragoso and Jianfeng Gao and Mei Gao and Min Gao and Amit Garg and Allie Del Giorno and Abhishek Goswami and Suriya Gunasekar and Emman Haider and Junheng Hao and Russell J. Hewett and Wenxiang Hu and Jamie Huynh and Dan Iter and Sam Ade Jacobs and Mojan Javaheripi and Xin Jin and Nikos Karampatziakis and Piero Kauffmann and Mahoud Khademi and Dongwoo Kim and Young Jin Kim and Lev Kurilenko and James R. Lee and Yin Tat Lee and Yuanzhi Li and Yunsheng Li and Chen Liang and Lars Liden and Xihui Lin and Zeqi Lin and Ce Liu and Liyuan Liu and Mengchen Liu and Weishung Liu and Xiaodong Liu and Chong Luo and Piyush Madan and Ali Mahmoudzadeh and David Majercak and Matt Mazzola and Caio César Teodoro Mendes and Arindam Mitra and Hardik Modi and Anh Nguyen and Brandon Norick and Barun Patra and Daniel Perez-Becker and Thomas Portet and Reid Pryzant and Heyang Qin and Marko Radmilac and Liliang Ren and Gustavo de Rosa and Corby Rosset and Sambudha Roy and Olatunji Ruwase and Olli Saarikivi and Amin Saied and Adil Salim and Michael Santacroce and Shital Shah and Ning Shang and Hiteshi Sharma and Yelong Shen and Swadheen Shukla and Xia Song and Masahiro Tanaka and Andrea Tupini and Praneetha Vaddamanu and Chunyu Wang and Guanhua Wang and Lijuan Wang and Shuohang Wang and Xin Wang and Yu Wang and Rachel Ward and Wen Wen and Philipp Witte and Haiping Wu and Xiaoxia Wu and Michael Wyatt and Bin Xiao and Can Xu and Jiahang Xu and Weijian Xu and Jilong Xue and Sonali Yadav and Fan Yang and Jianwei Yang and Yifan Yang and Ziyi Yang and Donghan Yu and Lu Yuan and Chenruidong Zhang and Cyril Zhang and Jianwen Zhang and Li Lyna Zhang and Yi Zhang and Yue Zhang and Yunan Zhang and Xiren Zhou},
      year={2024},
      eprint={2404.14219},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.14219}, 
}

@article{qu2024mupt,
  title={MuPT: A Generative Symbolic Music Pretrained Transformer},
  author={Qu, Xingwei and Bai, Yuelin and Ma, Yinghao and Zhou, Ziya and Lo, Ka Man and Liu, Jiaheng and Yuan, Ruibin and Min, Lejun and Liu, Xueling and Zhang, Tianyu and others},
  journal={arXiv preprint arXiv:2404.06393},
  year={2024}
}

@article{dhariwal2020jukebox,
  title={Jukebox: A generative model for music},
  author={Dhariwal, Prafulla and Jun, Heewoo and Payne, Christine and Kim, Jong Wook and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2005.00341},
  year={2020}
}

@article{lu2023musecoco,
  title={Musecoco: Generating symbolic music from text},
  author={Lu, Peiling and Xu, Xin and Kang, Chenfei and Yu, Botao and Xing, Chengyi and Tan, Xu and Bian, Jiang},
  journal={arXiv preprint arXiv:2306.00110},
  year={2023}
}

@article{zhang2024speechlm,
  title={Speechlm: Enhanced speech pre-training with unpaired textual data},
  author={Zhang, Ziqiang and Chen, Sanyuan and Zhou, Long and Wu, Yu and Ren, Shuo and Liu, Shujie and Yao, Zhuoyuan and Gong, Xun and Dai, Lirong and Li, Jinyu and others},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2024},
  publisher={IEEE}
}
@article{hu2024chain11,
  title={Chain-of-Thought Prompting for Speech Translation},
  author={Hu, Ke and Chen, Zhehuai and Yang, Chao-Han Huck and {\.Z}elasko, Piotr and Hrinchuk, Oleksii and Lavrukhin, Vitaly and Balam, Jagadeesh and Ginsburg, Boris},
  journal={arXiv preprint arXiv:2409.11538},
  year={2024}
}
@article{wang2023neural,
  title={Neural codec language models are zero-shot text to speech synthesizers},
  author={Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2301.02111},
  year={2023}
}

@inproceedings{law2009evaluation,
  title={Evaluation of algorithms using games: The case of music tagging.},
  author={Law, Edith and West, Kris and Mandel, Michael I and Bay, Mert and Downie, J Stephen},
  booktitle={ISMIR},
  pages={387--392},
  year={2009},
  organization={Citeseer}
}
@article{fu2024touch,
  title   = {A Touch, Vision, and Language Dataset for Multimodal Alignment},
  author  = {Letian Fu and Gaurav Datta and Huang Huang and William Chung-Ho Panitch and Jaimyn Drake and Joseph Ortiz and Mustafa Mukadam and Mike Lambeta and Roberto Calandra and Ken Goldberg},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2402.13232}
}
@article{baevski2022data2vec,
  title   = {data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language},
  author  = {Alexei Baevski and Wei-Ning Hsu and Qiantong Xu and Arun Babu and Jiatao Gu and Michael Auli},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2202.03555}
}
@article{wang2023onepeace,
  title   = {ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities},
  author  = {Peng Wang and Shijie Wang and Junyang Lin and Shuai Bai and Xiaohuan Zhou and Jingren Zhou and Xinggang Wang and Chang Zhou},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2305.11172}
}
@article{li2022mapmusic2vec,
  title   = {MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation Learning},
  author  = {Yizhi Li and Ruibin Yuan and Ge Zhang and Yinghao Ma and Chenghua Lin and Xingran Chen and Anton Ragni and Hanzhi Yin and Zhijie Hu and Haoyu He and Emmanouil Benetos and Norbert Gyenge and Ruibo Liu and Jie Fu},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2212.02508}
}

@article{bertin2011million,
  title={The million song dataset},
  author={Bertin-Mahieux, Thierry and Ellis, Daniel PW and Whitman, Brian and Lamere, Paul},
  year={2011}
}

@article{doh2023lp,
  title={Lp-musiccaps: Llm-based pseudo music captioning},
  author={Doh, SeungHeon and Choi, Keunwoo and Lee, Jongpil and Nam, Juhan},
  journal={arXiv preprint arXiv:2307.16372},
  year={2023}
}

@article{defferrard2016fma,
  title={FMA: A dataset for music analysis},
  author={Defferrard, Micha{\"e}l and Benzi, Kirell and Vandergheynst, Pierre and Bresson, Xavier},
  journal={arXiv preprint arXiv:1612.01840},
  year={2016}
}

@inproceedings{bogdanov2019mtg,
  title={The mtg-jamendo dataset for automatic music tagging},
  author={Bogdanov, Dmitry and Won, Minz and Tovstogan, Philip and Porter, Alastair and Serra, Xavier},
  year={2019},
  organization={ICML}
}

@article{lanzendorfer2024disco,
  title={DISCO-10M: A Large-Scale Music Dataset},
  author={Lanzend{\"o}rfer, Luca and Gr{\"o}tschla, Florian and Funke, Emil and Wattenhofer, Roger},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{li2023yodas,
  title={Yodas: Youtube-Oriented Dataset for Audio and Speech},
  author={Li, Xinjian and Takamichi, Shinnosuke and Saeki, Takaaki and Chen, William and Shiota, Sayaka and Watanabe, Shinji},
  booktitle={2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}

@inproceedings{zhang2022wenetspeech,
  title={Wenetspeech: A 10000+ hours multi-domain mandarin corpus for speech recognition},
  author={Zhang, Binbin and Lv, Hang and Guo, Pengcheng and Shao, Qijie and Yang, Chao and Xie, Lei and Xu, Xin and Bu, Hui and Chen, Xiaoyu and Zeng, Chenchen and others},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6182--6186},
  year={2022},
  organization={IEEE}
}

@article{chen2021gigaspeech,
  title={Gigaspeech: An evolving, multi-domain asr corpus with 10,000 hours of transcribed audio},
  author={Chen, Guoguo and Chai, Shuzhou and Wang, Guanbo and Du, Jiayu and Zhang, Wei-Qiang and Weng, Chao and Su, Dan and Povey, Daniel and Trmal, Jan and Zhang, Junbo and others},
  journal={arXiv preprint arXiv:2106.06909},
  year={2021}
}

@article{deshmukh2023pengi,
  title={Pengi: An audio language model for audio tasks},
  author={Deshmukh, Soham and Elizalde, Benjamin and Singh, Rita and Wang, Huaming},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={18090--18108},
  year={2023}
}

@article{gong2023listen,
  title={Listen, think, and understand},
  author={Gong, Yuan and Luo, Hongyin and Liu, Alexander H and Karlinsky, Leonid and Glass, James},
  journal={arXiv preprint arXiv:2305.10790},
  year={2023}
}

@article{tang2023salmonn,
  title={Salmonn: Towards generic hearing abilities for large language models},
  author={Tang, Changli and Yu, Wenyi and Sun, Guangzhi and Chen, Xianzhao and Tan, Tian and Li, Wei and Lu, Lu and Ma, Zejun and Zhang, Chao},
  journal={arXiv preprint arXiv:2310.13289},
  year={2023}
}

@article{chu2023qwen,
  title={Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models},
  author={Chu, Yunfei and Xu, Jin and Zhou, Xiaohuan and Yang, Qian and Zhang, Shiliang and Yan, Zhijie and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2311.07919},
  year={2023}
}

@article{kong2024audio,
  title={Audio flamingo: A novel audio language model with few-shot learning and dialogue abilities},
  author={Kong, Zhifeng and Goel, Arushi and Badlani, Rohan and Ping, Wei and Valle, Rafael and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:2402.01831},
  year={2024}
}

@inproceedings{wu2023decoder,
  title={On decoder-only architecture for speech-to-text and large language model integration},
  author={Wu, Jian and Gaur, Yashesh and Chen, Zhuo and Zhou, Long and Zhu, Yimeng and Wang, Tianrui and Li, Jinyu and Liu, Shujie and Ren, Bo and Liu, Linquan and others},
  booktitle={2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}

@article{hu2024wavllm,
  title={Wavllm: Towards robust and adaptive speech large language model},
  author={Hu, Shujie and Zhou, Long and Liu, Shujie and Chen, Sanyuan and Hao, Hongkun and Pan, Jing and Liu, Xunying and Li, Jinyu and Sivasankaran, Sunit and Liu, Linquan and others},
  journal={arXiv preprint arXiv:2404.00656},
  year={2024}
}

@article{das2024speechverse,
  title={SpeechVerse: A Large-scale Generalizable Audio Language Model},
  author={Das, Nilaksh and Dingliwal, Saket and Ronanki, Srikanth and Paturi, Rohit and Huang, David and Mathur, Prashant and Yuan, Jie and Bekal, Dhanush and Niu, Xing and Jayanthi, Sai Muralidhar and others},
  journal={arXiv preprint arXiv:2405.08295},
  year={2024}
}

@inproceedings{shen2018natural,
  title={Natural tts synthesis by conditioning wavenet on mel spectrogram predictions},
  author={Shen, Jonathan and Pang, Ruoming and Weiss, Ron J and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and others},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={4779--4783},
  year={2018},
  organization={IEEE}
}


@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@article{lakhotia2021generative,
  title={On generative spoken language modeling from raw audio},
  author={Lakhotia, Kushal and Kharitonov, Eugene and Hsu, Wei-Ning and Adi, Yossi and Polyak, Adam and Bolte, Benjamin and Nguyen, Tu-Anh and Copet, Jade and Baevski, Alexei and Mohamed, Abdelrahman and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={1336--1354},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

 @article{borsos2023audiolm,
  title={Audiolm: a language modeling approach to audio generation},
  author={Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and others},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={31},
  pages={2523--2533},
  year={2023},
  publisher={IEEE}
}

 @article{kreuk2022audiogen,
  title={Audiogen: Textually guided audio generation},
  author={Kreuk, Felix and Synnaeve, Gabriel and Polyak, Adam and Singer, Uriel and D{\'e}fossez, Alexandre and Copet, Jade and Parikh, Devi and Taigman, Yaniv and Adi, Yossi},
  journal={arXiv preprint arXiv:2209.15352},
  year={2022}
}

@article{wang2024mio,
  title   = {MIO: A Foundation Model on Multimodal Tokens},
  author  = {Zekun Wang and King Zhu and Chunpu Xu and Wangchunshu Zhou and Jiaheng Liu and Yibo Zhang and Jiashuo Wang and Ning Shi and Siyu Li and Yizhi Li and Haoran Que and Zhaoxiang Zhang and Yuanxing Zhang and Ge Zhang and Ke Xu and Jie Fu and Wenhao Huang},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2409.17692}
}

 @article{yang2023uniaudio,
  title={Uniaudio: An audio foundation model toward universal audio generation},
  author={Yang, Dongchao and Tian, Jinchuan and Tan, Xu and Huang, Rongjie and Liu, Songxiang and Chang, Xuankai and Shi, Jiatong and Zhao, Sheng and Bian, Jiang and Wu, Xixin and others},
  journal={arXiv preprint arXiv:2310.00704},
  year={2023}
}

 @article{kharitonov2023speak,
  title={Speak, read and prompt: High-fidelity text-to-speech with minimal supervision},
  author={Kharitonov, Eugene and Vincent, Damien and Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Girgin, Sertan and Pietquin, Olivier and Sharifi, Matt and Tagliasacchi, Marco and Zeghidour, Neil},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={1703--1718},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

 @article{wang2023neural,
  title={Neural codec language models are zero-shot text to speech synthesizers},
  author={Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2301.02111},
  year={2023}
}

 @article{lajszczak2024base,
  title={BASE TTS: Lessons from building a billion-parameter text-to-speech model on 100K hours of data},
  author={{\L}ajszczak, Mateusz and C{\'a}mbara, Guillermo and Li, Yang and Beyhan, Fatih and van Korlaar, Arent and Yang, Fan and Joly, Arnaud and Mart{\'\i}n-Cortinas, {\'A}lvaro and Abbas, Ammar and Michalski, Adam and others},
  journal={arXiv preprint arXiv:2402.08093},
  year={2024}
}

 @article{peng2024voicecraft,
  title={VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild},
  author={Peng, Puyuan and Huang, Po-Yao and Li, Daniel and Mohamed, Abdelrahman and Harwath, David},
  journal={arXiv preprint arXiv:2403.16973},
  year={2024}
}

 @article{meng2024autoregressive,
  title={Autoregressive speech synthesis without vector quantization},
  author={Meng, Lingwei and Zhou, Long and Liu, Shujie and Chen, Sanyuan and Han, Bing and Hu, Shujie and Liu, Yanqing and Li, Jinyu and Zhao, Sheng and Wu, Xixin and others},
  journal={arXiv preprint arXiv:2407.08551},
  year={2024}
}

 @article{anastassiou2024seed,
  title={Seed-TTS: A Family of High-Quality Versatile Speech Generation Models},
  author={Anastassiou, Philip and Chen, Jiawei and Chen, Jitong and Chen, Yuanzhe and Chen, Zhuo and Chen, Ziyi and Cong, Jian and Deng, Lelai and Ding, Chuang and Gao, Lu and others},
  journal={arXiv preprint arXiv:2406.02430},
  year={2024}
}

@article{wu2023speechgen,
  title={Speechgen: Unlocking the generative power of speech language models with prompts},
  author={Wu, Haibin and Chang, Kai-Wei and Wu, Yuan-Kuei and Lee, Hung-yi},
  journal={arXiv preprint arXiv:2306.02207},
  year={2023}
}

@inproceedings{maiti2024voxtlm,
  title={VoxtLM: Unified Decoder-Only Models for Consolidating Speech Recognition, Synthesis and Speech, Text Continuation Tasks},
  author={Maiti, Soumi and Peng, Yifan and Choi, Shukjae and Jung, Jee-weon and Chang, Xuankai and Watanabe, Shinji},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={13326--13330},
  year={2024},
  organization={IEEE}
}

 @article{du2024cosyvoice,
  title={Cosyvoice: A scalable multilingual zero-shot text-to-speech synthesizer based on supervised semantic tokens},
  author={Du, Zhihao and Chen, Qian and Zhang, Shiliang and Hu, Kai and Lu, Heng and Yang, Yexin and Hu, Hangrui and Zheng, Siqi and Gu, Yue and Ma, Ziyang and others},
  journal={arXiv preprint arXiv:2407.05407},
  year={2024}
}

 @article{copet2024simple,
  title={Simple and controllable music generation},
  author={Copet, Jade and Kreuk, Felix and Gat, Itai and Remez, Tal and Kant, David and Synnaeve, Gabriel and Adi, Yossi and D{\'e}fossez, Alexandre},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

 @article{ding2024songcomposer,
  title={Songcomposer: A large language model for lyric and melody composition in song generation},
  author={Ding, Shuangrui and Liu, Zihan and Dong, Xiaoyi and Zhang, Pan and Qian, Rui and He, Conghui and Lin, Dahua and Wang, Jiaqi},
  journal={arXiv preprint arXiv:2402.17645},
  year={2024}
}


 @article{zhang2023speechgpt,
  title={Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities},
  author={Zhang, Dong and Li, Shimin and Zhang, Xin and Zhan, Jun and Wang, Pengyu and Zhou, Yaqian and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2305.11000},
  year={2023}
}

 @article{rubenstein2023audiopalm,
  title={Audiopalm: A large language model that can speak and listen},
  author={Rubenstein, Paul K and Asawaroengchai, Chulayuth and Nguyen, Duc Dung and Bapna, Ankur and Borsos, Zal{\'a}n and Quitry, F{\'e}lix de Chaumont and Chen, Peter and Badawy, Dalia El and Han, Wei and Kharitonov, Eugene and others},
  journal={arXiv preprint arXiv:2306.12925},
  year={2023}
}

 @article{wang2023viola,
  title={Viola: Unified codec language models for speech recognition, synthesis, and translation},
  author={Wang, Tianrui and Zhou, Long and Zhang, Ziqiang and Wu, Yu and Liu, Shujie and Gaur, Yashesh and Chen, Zhuo and Li, Jinyu and Wei, Furu},
  journal={arXiv preprint arXiv:2305.16107},
  year={2023}
}

 @article{du2023lauragpt,
  title={Lauragpt: Listen, attend, understand, and regenerate audio with gpt},
  author={Du, Zhihao and Wang, Jiaming and Chen, Qian and Chu, Yunfei and Gao, Zhifu and Li, Zerui and Hu, Kai and Zhou, Xiaohuan and Xu, Jin and Ma, Ziyang and others},
  journal={arXiv preprint arXiv:2310.04673},
  year={2023}
}

 @article{fang2024llama,
  title={Llama-omni: Seamless speech interaction with large language models},
  author={Fang, Qingkai and Guo, Shoutao and Zhou, Yan and Ma, Zhengrui and Zhang, Shaolei and Feng, Yang},
  journal={arXiv preprint arXiv:2409.06666},
  year={2024}
}

 @article{xie2024mini,
  title={Mini-omni: Language models can hear, talk while thinking in streaming},
  author={Xie, Zhifei and Wu, Changqiao},
  journal={arXiv preprint arXiv:2408.16725},
  year={2024}
}

@article{huang2023make,
  title={Make-a-voice: Unified voice synthesis with discrete representation},
  author={Huang, Rongjie and Zhang, Chunlei and Wang, Yongqi and Yang, Dongchao and Liu, Luping and Ye, Zhenhui and Jiang, Ziyue and Weng, Chao and Zhao, Zhou and Yu, Dong},
  journal={arXiv preprint arXiv:2305.19269},
  year={2023}
}

@inproceedings{chiu2022self,
  title={Self-supervised learning with random-projection quantizer for speech recognition},
  author={Chiu, Chung-Cheng and Qin, James and Zhang, Yu and Yu, Jiahui and Wu, Yonghui},
  booktitle={International Conference on Machine Learning},
  pages={3915--3924},
  year={2022},
  organization={PMLR}
}

@article{kong2020hifi,
  title={Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={17022--17033},
  year={2020}
}

@inproceedings{elizalde2024natural,
  title={Natural language supervision for general-purpose audio representations},
  author={Elizalde, Benjamin and Deshmukh, Soham and Wang, Huaming},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={336--340},
  year={2024},
  organization={IEEE}
}

 @article{defossez2024moshi,
  title={Moshi: a speech-text foundation model for real-time dialogue},
  author={D{\'e}fossez, Alexandre and Mazar{\'e}, Laurent and Orsini, Manu and Royer, Am{\'e}lie and P{\'e}rez, Patrick and J{\'e}gou, Herv\'{e} and Grave, Edouard and Zeghidour, Neil},
  journal={arXiv preprint arXiv:2410.00037},
  year={2024}
}

@inproceedings{elizalde2023clap,
  title={Clap learning audio concepts from natural language supervision},
  author={Elizalde, Benjamin and Deshmukh, Soham and Al Ismail, Mahmoud and Wang, Huaming},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@article{yuan2024chatmusician,
  title={Chatmusician: Understanding and generating music intrinsically with llm},
  author={Yuan, Ruibin and Lin, Hanfeng and Wang, Yi and Tian, Zeyue and Wu, Shangda and Shen, Tianhao and Zhang, Ge and Wu, Yuhang and Liu, Cong and Zhou, Ziya and others},
  journal={arXiv preprint arXiv:2402.16153},
  year={2024}
}


@inproceedings{liu2024music,
  title={Music understanding LLaMA: Advancing text-to-music generation with question answering and captioning},
  author={Liu, Shansong and Hussain, Atin Sakkeer and Sun, Chenshuo and Shan, Ying},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={286--290},
  year={2024},
  organization={IEEE}
}

@article{ma2023emotion2vec,
  title={emotion2vec: Self-supervised pre-training for speech emotion representation},
  author={Ma, Ziyang and Zheng, Zhisheng and Ye, Jiaxin and Li, Jinchao and Gao, Zhifu and Zhang, Shiliang and Chen, Xie},
  journal={arXiv preprint arXiv:2312.15185},
  year={2023}
}


@article{chen2024eat,
  title={EAT: Self-supervised pre-training with efficient audio transformer},
  author={Chen, Wenxi and Liang, Yuzhe and Ma, Ziyang and Zheng, Zhisheng and Chen, Xie},
  journal={arXiv preprint arXiv:2401.03497},
  year={2024}
}

@article{chen2022beats,
  title={Beats: Audio pre-training with acoustic tokenizers},
  author={Chen, Sanyuan and Wu, Yu and Wang, Chengyi and Liu, Shujie and Tompkins, Daniel and Chen, Zhuo and Wei, Furu},
  journal={arXiv preprint arXiv:2212.09058},
  year={2022}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@article{zen2019libritts,
  title={Libritts: A corpus derived from librispeech for text-to-speech},
  author={Zen, Heiga and Dang, Viet and Clark, Rob and Zhang, Yu and Weiss, Ron J and Jia, Ye and Chen, Zhifeng and Wu, Yonghui},
  journal={arXiv preprint arXiv:1904.02882},
  year={2019}
}

@inproceedings{kang2024libriheavy,
  title={Libriheavy: a 50,000 hours asr corpus with punctuation casing and context},
  author={Kang, Wei and Yang, Xiaoyu and Yao, Zengwei and Kuang, Fangjun and Yang, Yifan and Guo, Liyong and Lin, Long and Povey, Daniel},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={10991--10995},
  year={2024},
  organization={IEEE}
}

@misc{chang2023muse,
      title={Muse: Text-To-Image Generation via Masked Generative Transformers}, 
      author={Huiwen Chang and Han Zhang and Jarred Barber and AJ Maschinot and Jose Lezama and Lu Jiang and Ming-Hsuan Yang and Kevin Murphy and William T. Freeman and Michael Rubinstein and Yuanzhen Li and Dilip Krishnan},
      year={2023},
      eprint={2301.00704},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}

@inproceedings{kahn2020libri,
  title={Libri-light: A benchmark for asr with limited or no supervision},
  author={Kahn, Jacob and Riviere, Morgane and Zheng, Weiyi and Kharitonov, Evgeny and Xu, Qiantong and Mazar{\'e}, Pierre-Emmanuel and Karadayi, Julien and Liptchinsky, Vitaliy and Collobert, Ronan and Fuegen, Christian and others},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7669--7673},
  year={2020},
  organization={IEEE}
}

@inproceedings{drossos2020clotho,
  title={Clotho: An audio captioning dataset},
  author={Drossos, Konstantinos and Lipping, Samuel and Virtanen, Tuomas},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={736--740},
  year={2020},
  organization={IEEE}
}

@inproceedings{chen2020vggsound,
  title={Vggsound: A large-scale audio-visual dataset},
  author={Chen, Honglie and Xie, Weidi and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={721--725},
  year={2020},
  organization={IEEE}
}

@inproceedings{wu2023large,
  title={Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation},
  author={Wu, Yusong and Chen, Ke and Zhang, Tianyu and Hui, Yuchen and Berg-Kirkpatrick, Taylor and Dubnov, Shlomo},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@article{copet2024simple,
  title={Simple and controllable music generation},
  author={Copet, Jade and Kreuk, Felix and Gat, Itai and Remez, Tal and Kant, David and Synnaeve, Gabriel and Adi, Yossi and D{\'e}fossez, Alexandre},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{rubenstein2023audiopalm,
  title={Audiopalm: A large language model that can speak and listen},
  author={Rubenstein, Paul K and Asawaroengchai, Chulayuth and Nguyen, Duc Dung and Bapna, Ankur and Borsos, Zal{\'a}n and Quitry, F{\'e}lix de Chaumont and Chen, Peter and Badawy, Dalia El and Han, Wei and Kharitonov, Eugene and others},
  journal={arXiv preprint arXiv:2306.12925},
  year={2023}
}

@article{zhang2023speechtokenizer,
  title={SpeechTokenizer: Unified speech tokenizer for speech large language models},
  author={Zhang, Xin and Zhang, Dong and Li, Shimin and Zhou, Yaqian and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2308.16692},
  year={2023}
}

@article{liu2024semanticodec,
  title={SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound},
  author={Liu, Haohe and Xu, Xuenan and Yuan, Yi and Wu, Mengyue and Wang, Wenwu and Plumbley, Mark D},
  journal={arXiv preprint arXiv:2405.00233},
  year={2024}
}

@article{ji2024wavtokenizer,
  title={Wavtokenizer: an efficient acoustic discrete codec tokenizer for audio language modeling},
  author={Ji, Shengpeng and Jiang, Ziyue and Cheng, Xize and Chen, Yifu and Fang, Minghui and Zuo, Jialong and Yang, Qian and Li, Ruiqi and Zhang, Ziang and Yang, Xiaoda and others},
  journal={arXiv preprint arXiv:2408.16532},
  year={2024}
}

@article{defossez2024moshi,
  title={Moshi: a speech-text foundation model for real-time dialogue},
  author={D{\'e}fossez, Alexandre and Mazar{\'e}, Laurent and Orsini, Manu and Royer, Am{\'e}lie and P{\'e}rez, Patrick and J{\'e}gou, Herv\'{e} and Grave, Edouard and Zeghidour, Neil},
  journal={arXiv preprint arXiv:2410.00037},
  year={2024}
}

@article{zhang2023speechtokenizer,
  title={Speechtokenizer: Unified speech tokenizer for speech large language models},
  author={Zhang, Xin and Zhang, Dong and Li, Shimin and Zhou, Yaqian and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2308.16692},
  year={2023}
}

@article{ju2024naturalspeech,
  title={Naturalspeech 3: Zero-shot speech synthesis with factorized codec and diffusion models},
  author={Ju, Zeqian and Wang, Yuancheng and Shen, Kai and Tan, Xu and Xin, Detai and Yang, Dongchao and Liu, Yanqing and Leng, Yichong and Song, Kaitao and Tang, Siliang and others},
  journal={arXiv preprint arXiv:2403.03100},
  year={2024}
}

@article{yang2023hifi,
  title={Hifi-codec: Group-residual vector quantization for high fidelity audio codec},
  author={Yang, Dongchao and Liu, Songxiang and Huang, Rongjie and Tian, Jinchuan and Weng, Chao and Zou, Yuexian},
  journal={arXiv preprint arXiv:2305.02765},
  year={2023}
}

@article{kumar2024high,
  title={High-fidelity audio compression with improved rvqgan},
  author={Kumar, Rithesh and Seetharaman, Prem and Luebs, Alejandro and Kumar, Ishaan and Kumar, Kundan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@inproceedings{jenrungrot2023lmcodec,
  title={Lmcodec: A low bitrate speech codec with causal transformer models},
  author={Jenrungrot, Teerapat and Chinen, Michael and Kleijn, W Bastiaan and Skoglund, Jan and Borsos, Zal{\'a}n and Zeghidour, Neil and Tagliasacchi, Marco},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@article{li2023mert,
  title={Mert: Acoustic music understanding model with large-scale self-supervised training},
  author={Li, Yizhi and Yuan, Ruibin and Zhang, Ge and Ma, Yinghao and Chen, Xingran and Yin, Hanzhi and Xiao, Chenghao and Lin, Chenghua and Ragni, Anton and Benetos, Emmanouil and others},
  journal={arXiv preprint arXiv:2306.00107},
  year={2023}
}


@article{gulati2020conformer,
  title={Conformer: Convolution-augmented transformer for speech recognition},
  author={Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and others},
  journal={arXiv preprint arXiv:2005.08100},
  year={2020}
}

@article{guo2024fireredtts,
  title={Fireredtts: A foundation text-to-speech framework for industry-level generative speech applications},
  author={Guo, Hao-Han and Liu, Kun and Shen, Fei-Yu and Wu, Yi-Chen and Xie, Feng-Long and Xie, Kun and Xu, Kai-Tuo},
  journal={arXiv preprint arXiv:2409.03283},
  year={2024}
}

@article{desplanques2020ecapa,
  title={Ecapa-tdnn: Emphasized channel attention, propagation and aggregation in tdnn based speaker verification},
  author={Desplanques, Brecht and Thienpondt, Jenthe and Demuynck, Kris},
  journal={arXiv preprint arXiv:2005.07143},
  year={2020}
}

@article{popuri2022enhanced,
  title={Enhanced direct speech-to-speech translation using self-supervised pre-training and data augmentation},
  author={Popuri, Sravya and Chen, Peng-Jen and Wang, Changhan and Pino, Juan and Adi, Yossi and Gu, Jiatao and Hsu, Wei-Ning and Lee, Ann},
  journal={arXiv preprint arXiv:2204.02967},
  year={2022}
}


@inproceedings{du2024funcodec,
  title={Funcodec: A fundamental, reproducible and integrable open-source toolkit for neural speech codec},
  author={Du, Zhihao and Zhang, Shiliang and Hu, Kai and Zheng, Siqi},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={591--595},
  year={2024},
  organization={IEEE}
}

@inproceedings{chung2021w2v,
  title={W2v-bert: Combining contrastive learning and masked language modeling for self-supervised speech pre-training},
  author={Chung, Yu-An and Zhang, Yu and Han, Wei and Chiu, Chung-Cheng and Qin, James and Pang, Ruoming and Wu, Yonghui},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={244--250},
  year={2021},
  organization={IEEE}
}

@article{borsos2023audiolm,
  title={Audiolm: a language modeling approach to audio generation},
  author={Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and others},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2023},
  publisher={IEEE}
}

@inproceedings{van-noord-etal-2019-linguistic,
    title = "Linguistic Information in Neural Semantic Parsing with Multiple Encoders",
    author = "van Noord, Rik  and
      Toral, Antonio  and
      Bos, Johan",
    editor = "Dobnik, Simon  and
      Chatzikyriakidis, Stergios  and
      Demberg, Vera",
    booktitle = "Proceedings of the 13th International Conference on Computational Semantics - Short Papers",
    month = may,
    year = "2019",
    address = "Gothenburg, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-0504",
    doi = "10.18653/v1/W19-0504",
    pages = "24--31",
    abstract = "Recently, sequence-to-sequence models have achieved impressive performance on a number of semantic parsing tasks. However, they often do not exploit available linguistic resources, while these, when employed correctly, are likely to increase performance even further. Research in neural machine translation has shown that employing this information has a lot of potential, especially when using a multi-encoder setup. We employ a range of semantic and syntactic resources to improve performance for the task of Discourse Representation Structure Parsing. We show that (i) linguistic features can be beneficial for neural semantic parsing and (ii) the best method of adding these features is by using multiple encoders.",
}
@inproceedings{spae,
  author    = {Lijun Yu and Yong Cheng and Zhiruo Wang and Vivek Kumar and Wolfgang Macherey and Yanping Huang and David A. Ross and Irfan Essa and Yonatan Bisk and Ming{-}Hsuan Yang and Kevin P. Murphy and Alexander G. Hauptmann and Lu Jiang},
  editor    = {Alice Oh and Tristan Naumann and Amir Globerson and Kate Saenko and Moritz Hardt and Sergey Levine},
  title     = {{SPAE:} Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs},
  booktitle = {Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023},
  year      = {2023},
  url       = {http://papers.nips.cc/paper\_files/paper/2023/hash/a526cc8f6ffb74bedb6ff313e3fdb450-Abstract-Conference.html},
  timestamp = {Fri, 01 Mar 2024 16:26:20 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/YuCWKMHREB0MH023.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ma2023effectiveness,
  title={On the effectiveness of speech self-supervised learning for music},
  author={Ma, Yinghao and Yuan, Ruibin and Li, Yizhi and Zhang, Ge and Chen, Xingran and Yin, Hanzhi and Lin, Chenghua and Benetos, Emmanouil and Ragni, Anton and Gyenge, Norbert and others},
  journal={arXiv preprint arXiv:2307.05161},
  year={2023}
}

@article{chen2022wavlm,
  title={Wavlm: Large-scale self-supervised pre-training for full stack speech processing},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={16},
  number={6},
  pages={1505--1518},
  year={2022},
  publisher={IEEE}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@article{baevski2019vq,
  title={vq-wav2vec: Self-supervised learning of discrete speech representations},
  author={Baevski, Alexei and Schneider, Steffen and Auli, Michael},
  journal={arXiv preprint arXiv:1910.05453},
  year={2019}
}

@article{schneider2019wav2vec,
  title={wav2vec: Unsupervised pre-training for speech recognition},
  author={Schneider, Steffen and Baevski, Alexei and Collobert, Ronan and Auli, Michael},
  journal={arXiv preprint arXiv:1904.05862},
  year={2019}
}

@article{jiang2019improving,
  title={Improving transformer-based speech recognition using unsupervised pre-training},
  author={Jiang, Dongwei and Lei, Xiaoning and Li, Wubo and Luo, Ne and Hu, Yuxuan and Zou, Wei and Li, Xiangang},
  journal={arXiv preprint arXiv:1910.09932},
  year={2019}
}

@article{chung2019unsupervised,
  title={An unsupervised autoregressive model for speech representation learning},
  author={Chung, Yu-An and Hsu, Wei-Ning and Tang, Hao and Glass, James},
  journal={arXiv preprint arXiv:1904.03240},
  year={2019}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@misc{kumar2023highfidelity,
      title={High-Fidelity Audio Compression with Improved RVQGAN}, 
      author={Rithesh Kumar and Prem Seetharaman and Alejandro Luebs and Ishaan Kumar and Kundan Kumar},
      year={2023},
      eprint={2306.06546},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}

@article{zeghidour2021soundstream,
  title={Soundstream: An end-to-end neural audio codec},
  author={Zeghidour, Neil and Luebs, Alejandro and Omran, Ahmed and Skoglund, Jan and Tagliasacchi, Marco},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={495--507},
  year={2021},
  publisher={IEEE}
}

@inproceedings{wmttaker1915functions,
  title={On the functions which are represented by the expansions of the interpolatory theory},
  author={WmTTAKER, ET},
  booktitle={Proc. Royal Soc. Edinburgh},
  volume={35},
  pages={181--194},
  year={1915}
}

@article{defossez2022high,
  title={High fidelity neural audio compression},
  author={D{\'e}fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},
  journal={arXiv preprint arXiv:2210.13438},
  year={2022}
}

@inproceedings{juang1982multiple,
  title={Multiple stage vector quantization for speech coding},
  author={Juang, Biing-Hwang and Gray, A},
  booktitle={ICASSP'82. IEEE International Conference on Acoustics, Speech, and Signal Processing},
  volume={7},
  pages={597--600},
  year={1982},
  organization={IEEE}
}

@article{atal1971speech,
  title={Speech analysis and synthesis by linear prediction of the speech wave},
  author={Atal, Bishnu S and Hanauer, Suzanne L},
  journal={The journal of the acoustical society of America},
  volume={50},
  number={2B},
  pages={637--655},
  year={1971},
  publisher={Acoustical Society of America}
}

@misc{gpt4o,
      title={hello-gpt-4o}, 
      author={OpenAI},
      year={2024},
      url={https://openai.com/index/hello-gpt-4o/} 
}

@misc{chen2024image,
      title={An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models}, 
      author={Liang Chen and Haozhe Zhao and Tianyu Liu and Shuai Bai and Junyang Lin and Chang Zhou and Baobao Chang},
      year={2024},
      eprint={2403.06764},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{tschannen2024givt,
      title={GIVT: Generative Infinite-Vocabulary Transformers}, 
      author={Michael Tschannen and Cian Eastwood and Fabian Mentzer},
      year={2024},
      eprint={2312.02116},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{li2024denoising,
      title={Denoising Autoregressive Representation Learning}, 
      author={Yazhe Li and Jorg Bornschein and Ting Chen},
      year={2024},
      eprint={2403.05196},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{chameleonteam2024chameleon,
      title={Chameleon: Mixed-Modal Early-Fusion Foundation Models}, 
      author={Chameleon Team},
      year={2024},
      eprint={2405.09818},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{chen2024pcabench,
      title={PCA-Bench: Evaluating Multimodal Large Language Models in Perception-Cognition-Action Chain}, 
      author={Liang Chen and Yichi Zhang and Shuhuai Ren and Haozhe Zhao and Zefan Cai and Yuchi Wang and Peiyi Wang and Xiangdi Meng and Tianyu Liu and Baobao Chang},
      year={2024},
      eprint={2402.15527},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ho2020denoising,
      title={Denoising Diffusion Probabilistic Models}, 
      author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
      year={2020},
      eprint={2006.11239},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{AIM,
      title={Scalable Pre-training of Large Autoregressive Image Models}, 
      author={Alaaeldin El-Nouby and Michal Klein and Shuangfei Zhai and Miguel Angel Bautista and Alexander Toshev and Vaishaal Shankar and Joshua M Susskind and Armand Joulin},
      year={2024},
      eprint={2401.08541},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{kirstain2024pick,
  title={Pick-a-pic: An open dataset of user preferences for text-to-image generation},
  author={Kirstain, Yuval and Polyak, Adam and Singer, Uriel and Matiana, Shahbuland and Penna, Joe and Levy, Omer},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@misc{li2024denoising,
      title={Denoising Autoregressive Representation Learning}, 
      author={Yazhe Li and Jorg Bornschein and Ting Chen},
      year={2024},
      eprint={2403.05196},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{zhang2023pretrained,
      title={Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation}, 
      author={Yuhui Zhang and Brandon McKinzie and Zhe Gan and Vaishaal Shankar and Alexander Toshev},
      year={2023},
      eprint={2311.16201},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{Zhan2024AnyGPT,
  title={AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling},
  author={Jun Zhan and Junqi Dai and Jiasheng Ye and Yunhua Zhou and Dong Zhang and Zhigeng Liu and Xin Zhang and Ruibin Yuan and Ge Zhang and Linyang Li and Hang Yan and Jie Fu and Tao Gui and Tianxiang Sun and Yugang Jiang and Xipeng Qiu},
  journal={ArXiv},
  year={2024},
  volume={abs/2402.12226},
  url={https://api.semanticscholar.org/CorpusID:267750101}
}
@misc{ramesh2021zeroshot,
      title={Zero-Shot Text-to-Image Generation}, 
      author={Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
      year={2021},
      eprint={2102.12092},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{inlp,
  title={Interactive Natural Language Processing},
  author={Wang, Zekun and Zhang, Ge and Yang, Kexin and Shi, Ning and Zhou, Wangchunshu and Hao, Shaochun and Xiong, Guangzheng and Li, Yizhi and Sim, Mong Yuan and Chen, Xiuying and others},
  journal={arXiv preprint arXiv:2305.13246},
  year={2023}
}

@misc{brohan2023rt2,
      title={RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control}, 
      author={Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Xi Chen and Krzysztof Choromanski and Tianli Ding and Danny Driess and Avinava Dubey and Chelsea Finn and Pete Florence and Chuyuan Fu and Montse Gonzalez Arenas and Keerthana Gopalakrishnan and Kehang Han and Karol Hausman and Alexander Herzog and Jasmine Hsu and Brian Ichter and Alex Irpan and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Lisa Lee and Tsang-Wei Edward Lee and Sergey Levine and Yao Lu and Henryk Michalewski and Igor Mordatch and Karl Pertsch and Kanishka Rao and Krista Reymann and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Pierre Sermanet and Jaspiar Singh and Anikait Singh and Radu Soricut and Huong Tran and Vincent Vanhoucke and Quan Vuong and Ayzaan Wahid and Stefan Welker and Paul Wohlhart and Jialin Wu and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich},
      year={2023},
      eprint={2307.15818},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@misc{jiang2023vima,
      title={VIMA: General Robot Manipulation with Multimodal Prompts}, 
      author={Yunfan Jiang and Agrim Gupta and Zichen Zhang and Guanzhi Wang and Yongqiang Dou and Yanjun Chen and Li Fei-Fei and Anima Anandkumar and Yuke Zhu and Linxi Fan},
      year={2023},
      eprint={2210.03094},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
@article{lu2023unifiedio,
  title   = {Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision, Language, Audio, and Action},
  author  = {Jiasen Lu and Christopher Clark and Sangho Lee and Zichen Zhang and Savya Khosla and Ryan Marten and Derek Hoiem and Aniruddha Kembhavi},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2312.17172}
}
@article{madani2023large,
  title={Large language models generate functional protein sequences across diverse families},
  author={Madani, Ali and Krause, Ben and Greene, Eric R and Subramanian, Subu and Mohr, Benjamin P and Holton, James M and Olmos, Jose Luis and Xiong, Caiming and Sun, Zachary Z and Socher, Richard and others},
  journal={Nature Biotechnology},
  volume={41},
  number={8},
  pages={1099--1106},
  year={2023},
  publisher={Nature Publishing Group}
}

@article{ruffolo2024designing,
  title={Designing proteins with language models},
  author={Ruffolo, Jeffrey A and Madani, Ali},
  journal={Nature Biotechnology},
  volume={42},
  number={2},
  pages={200--202},
  year={2024},
  publisher={Nature Publishing Group US New York}
}
@article{imagegpt,
  title={Generative Pretraining from Pixels},
  author={Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeff and Jun, Heewoo and Dhariwal, Prafulla and Luan, David and Sutskever, Ilya},
  year={2020}
}
@misc{wang2023images,
      title={Images Speak in Images: A Generalist Painter for In-Context Visual Learning}, 
      author={Xinlong Wang and Wen Wang and Yue Cao and Chunhua Shen and Tiejun Huang},
      year={2023},
      eprint={2212.02499},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{fuyu,
  author = {Bavishi, Rohan and Elsen, Erich and Hawthorne, Curtis and Nye, Maxwell and Odena, Augustus and Somani, Arushi and  Ta\c{s}\i{}rlar, Sa\u{g}nak},
  title = {Introducing our Multimodal Models},
  url = {https://www.adept.ai/blog/fuyu-8b},
  year = {2023}
}

@article{liu2023world,
    title={World Model on Million-Length Video and Language with RingAttention},
    author={Liu, Hao and Yan, Wilson and Zaharia, Matei and Abbeel, Pieter},
    journal={arXiv preprint},
    year={2024},
}

@misc{magvit2,
      title={Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation}, 
      author={Lijun Yu and José Lezama and Nitesh B. Gundavarapu and Luca Versari and Kihyuk Sohn and David Minnen and Yong Cheng and Vighnesh Birodkar and Agrim Gupta and Xiuye Gu and Alexander G. Hauptmann and Boqing Gong and Ming-Hsuan Yang and Irfan Essa and David A. Ross and Lu Jiang},
      year={2024},
      eprint={2310.05737},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{arnab2021vivit,
      title={ViViT: A Video Vision Transformer}, 
      author={Anurag Arnab and Mostafa Dehghani and Georg Heigold and Chen Sun and Mario Lučić and Cordelia Schmid},
      year={2021},
      eprint={2103.15691},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{villegas2022phenaki,
      title={Phenaki: Variable Length Video Generation From Open Domain Textual Description}, 
      author={Ruben Villegas and Mohammad Babaeizadeh and Pieter-Jan Kindermans and Hernan Moraldo and Han Zhang and Mohammad Taghi Saffar and Santiago Castro and Julius Kunze and Dumitru Erhan},
      year={2022},
      eprint={2210.02399},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@online{kexuefm-9984,
        title={“闭门造车”之多模态模型方案浅谈},
        author={苏剑林},
        year={2024},
        month={Feb},
        url={\url{https://spaces.ac.cn/archives/9984}},
}

@inproceedings{bertasius2021space,
  title={Is space-time attention all you need for video understanding?},
  author={Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  booktitle={ICML},
  volume={2},
  number={3},
  pages={4},
  year={2021}
}

@inproceedings{lei2021less,
  title={Less is more: Clipbert for video-and-language learning via sparse sampling},
  author={Lei, Jie and Li, Linjie and Zhou, Luowei and Gan, Zhe and Berg, Tamara L and Bansal, Mohit and Liu, Jingjing},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7331--7341},
  year={2021}
}

@article{wu2024number,
  title={Number it: Temporal Grounding Videos like Flipping Manga},
  author={Wu, Yongliang and Hu, Xinting and Sun, Yuyang and Zhou, Yizhou and Zhu, Wenbo and Rao, Fengyun and Schiele, Bernt and Yang, Xu},
  journal={arXiv preprint arXiv:2411.10332},
  year={2024}
}

@article{tong2022videomae,
  title={Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training},
  author={Tong, Zhan and Song, Yibing and Wang, Jue and Wang, Limin},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={10078--10093},
  year={2022}
}

@inproceedings{lin2022swinbert,
  title={Swinbert: End-to-end transformers with sparse attention for video captioning},
  author={Lin, Kevin and Li, Linjie and Lin, Chung-Ching and Ahmed, Faisal and Gan, Zhe and Liu, Zicheng and Lu, Yumao and Wang, Lijuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17949--17958},
  year={2022}
}

@misc{yan2021videogpt,
      title={VideoGPT: Video Generation using VQ-VAE and Transformers}, 
      author={Wilson Yan and Yunzhi Zhang and Pieter Abbeel and Aravind Srinivas},
      year={2021},
      eprint={2104.10157},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{encodec,
  title={High Fidelity Neural Audio Compression},
  author={Défossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},
  journal={arXiv preprint arXiv:2210.13438},
  year={2022}
}
@article{diba2017temporal,
  title   = {Temporal 3D ConvNets: New Architecture and Transfer Learning for Video Classification},
  author  = {Ali Diba and Mohsen Fayyaz and Vivek Sharma and Amir Hossein Karami and Mohammad Mahdi Arzani and Rahman Yousefzadeh and Luc Van Gool},
  year    = {2017},
  journal = {arXiv preprint arXiv: 1711.08200}
}
@article{magvit,
  title   = {MAGVIT: Masked Generative Video Transformer},
  author  = {Lijun Yu and Yong Cheng and Kihyuk Sohn and José Lezama and Han Zhang and Huiwen Chang and Alexander G. Hauptmann and Ming-Hsuan Yang and Yuan Hao and Irfan Essa and Lu Jiang},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2212.05199}
}
@article{Pags2015IntroductionTV,
  title={Introduction to vector quantization and its applications for numerics},
  author={Gilles Pag{\`e}s},
  journal={Esaim: Proceedings},
  year={2015},
  volume={48},
  pages={29-79},
  url={https://api.semanticscholar.org/CorpusID:56105648}
}
@misc{musevl,
      title={MUSE-VL: Modeling Unified VLM through Semantic Discrete Encoding}, 
      author={Rongchang Xie and Chen Du and Ping Song and Chang Liu},
      year={2025},
      eprint={2411.17762},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.17762}, 
}
@article{gemini1,
  title   = {Gemini: A Family of Highly Capable Multimodal Models},
  author  = {Gemini Team},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2312.11805}
}
@article{layoutlm,
  title   = {LayoutLM: Pre-training of Text and Layout for Document Image Understanding},
  author  = {Yiheng Xu and Minghao Li and Lei Cui and Shaohan Huang and Furu Wei and Ming Zhou},
  year    = {2019},
  journal = {arXiv preprint arXiv: 1912.13318}
}
@article{textmonkey,
  title   = {TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document},
  author  = {Yuliang Liu and Biao Yang and Qiang Liu and Zhang Li and Zhiyin Ma and Shuo Zhang and Xiang Bai},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2403.04473}
}
@article{ureader,
  title     = {UReader: Universal OCR-free Visually-situated Language Understanding with Multimodal Large Language Model},
  author    = {Jiabo Ye and Anwen Hu and Haiyang Xu and Qinghao Ye and Mingshi Yan and Guohai Xu and Chenliang Li and Junfeng Tian and Qi Qian and Ji Zhang and Qin Jin and Liang He and Xin Alex Lin and Feiyan Huang},
  journal   = {Conference on Empirical Methods in Natural Language Processing},
  year      = {2023},
  doi       = {10.48550/arXiv.2310.05126},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/69b90bd79bb0fc87d39180161926964ae9dd7cbc}
}
@misc{li2024textbind,
      title={TextBind: Multi-turn Interleaved Multimodal Instruction-following in the Wild}, 
      author={Huayang Li and Siheng Li and Deng Cai and Longyue Wang and Lemao Liu and Taro Watanabe and Yujiu Yang and Shuming Shi},
      year={2024},
      eprint={2309.08637},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{gupta2022visprog,
      title={Visual Programming: Compositional visual reasoning without training}, 
      author={Tanmay Gupta and Aniruddha Kembhavi},
      year={2022},
      eprint={2211.11559},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{llava-uhd,
  title={{LLaVA-UHD}: an LMM Perceiving Any Aspect Ratio and High-Resolution Images},
  author={Xu, Ruyi and Yao, Yuan and Guo, Zonghao and Cui, Junbo and Ni, Zanlin and Ge, Chunjiang and Chua, Tat-Seng and Liu, Zhiyuan and Huang, Gao},
  journal={arXiv preprint arXiv:2403.11703},
  year={2024}
}
@misc{shen2023hugginggpt,
      title={HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face}, 
      author={Yongliang Shen and Kaitao Song and Xu Tan and Dongsheng Li and Weiming Lu and Yueting Zhuang},
      year={2023},
      eprint={2303.17580},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{qin2023toolllm,
      title={ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs}, 
      author={Yujia Qin and Shihao Liang and Yining Ye and Kunlun Zhu and Lan Yan and Yaxi Lu and Yankai Lin and Xin Cong and Xiangru Tang and Bill Qian and Sihan Zhao and Lauren Hong and Runchu Tian and Ruobing Xie and Jie Zhou and Mark Gerstein and Dahai Li and Zhiyuan Liu and Maosong Sun},
      year={2023},
      eprint={2307.16789},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@article{navit,
  title     = {Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution},
  author    = {Mostafa Dehghani and Basil Mustafa and Josip Djolonga and J. Heek and Matthias Minderer and Mathilde Caron and A. Steiner and J. Puigcerver and Robert Geirhos and Ibrahim M. Alabdulmohsin and Avital Oliver and Piotr Padlewski and A. Gritsenko and Mario Luvci'c and N. Houlsby},
  journal   = {Neural Information Processing Systems},
  year      = {2023},
  doi       = {10.48550/arXiv.2307.06304},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/918617dbc02fa4df1999599bcf967acd2ea84d71}
}
@article{msvit,
  title   = {MSViT: Dynamic Mixed-Scale Tokenization for Vision Transformers},
  author  = {Jakob Drachmann Havtorn and Amelie Royer and Tijmen Blankevoort and Babak Ehteshami Bejnordi},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2307.02321}
}
@article{samclip,
  title   = {SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding},
  author  = {Haoxiang Wang and Pavan Kumar Anasosalu Vasu and Fartash Faghri and Raviteja Vemulapalli and Mehrdad Farajtabar and Sachin Mehta and Mohammad Rastegari and Oncel Tuzel and Hadi Pouransari},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2310.15308}
}
@article{fixres,
  title   = {Fixing the train-test resolution discrepancy},
  author  = {Hugo Touvron and Andrea Vedaldi and Matthijs Douze and Herv\'{e} J\'{e}gou},
  year    = {2019},
  journal = {arXiv preprint arXiv: 1906.06423}
}
@article{perceiver,
  title   = {Perceiver: General Perception with Iterative Attention},
  author  = {Andrew Jaegle and Felix Gimeno and Andrew Brock and Andrew Zisserman and Oriol Vinyals and Joao Carreira},
  year    = {2021},
  journal = {arXiv preprint arXiv: 2103.03206}
}
@article{hip,
  title   = {HiP: Hierarchical Perceiver},
  author  = {Joao Carreira and Skanda Koppula and Daniel Zoran and Adria Recasens and Catalin Ionescu and Olivier Henaff and Evan Shelhamer and Relja Arandjelovic and Matt Botvinick and Oriol Vinyals and Karen Simonyan and Andrew Zisserman and Andrew Jaegle},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2202.10890}
}
@article{perceiverio,
  title   = {Perceiver IO: A General Architecture for Structured Inputs \& Outputs},
  author  = {Andrew Jaegle and Sebastian Borgeaud and Jean-Baptiste Alayrac and Carl Doersch and Catalin Ionescu and David Ding and Skanda Koppula and Daniel Zoran and Andrew Brock and Evan Shelhamer and Olivier Hénaff and Matthew M. Botvinick and Andrew Zisserman and Oriol Vinyals and Joāo Carreira},
  year    = {2021},
  journal = {arXiv preprint arXiv: 2107.14795}
}
@article{nfnet,
  title     = {High-Performance Large-Scale Image Recognition Without Normalization},
  author    = {Andrew Brock and Soham De and Samuel L. Smith and K. Simonyan},
  journal   = {International Conference on Machine Learning},
  year      = {2021},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/c16835c8e535ebd9c10a550ca9455fe384a14449}
}
@article{resnet,
  title   = {Deep Residual Learning for Image Recognition},
  author  = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  year    = {2015},
  journal = {arXiv preprint arXiv: 1512.03385}
}
@ARTICLE{vq,
  author={Gray, R.},
  journal={IEEE ASSP Magazine}, 
  title={Vector quantization}, 
  year={1984},
  volume={1},
  number={2},
  pages={4-29},
  keywords={Vector quantization;Data compression;Speech processing;Speech coding;Communication channels;Channel capacity;Phase change materials;Information theory},
  doi={10.1109/MASSP.1984.1162229}}


@misc{tang2023codi2,
      title={CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation}, 
      author={Zineng Tang and Ziyi Yang and Mahmoud Khademi and Yang Liu and Chenguang Zhu and Mohit Bansal},
      year={2023},
      eprint={2311.18775},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{yang2023d3po,
  title={Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model},
  author={Yang, Kai and Tao, Jian and Lyu, Jiafei and Ge, Chunjiang and Chen, Jiaxin and Li, Qimai and Shen, Weihan and Zhu, Xiaolong and Li, Xiu},
  journal={arXiv preprint arXiv:2311.13231},
  year={2023}
}
@article{diffusion_dpo1,
  title={Diffusion model alignment using direct preference optimization},
  author={Wallace, Bram and Dang, Meihua and Rafailov, Rafael and Zhou, Linqi and Lou, Aaron and Purushwalkam, Senthil and Ermon, Stefano and Xiong, Caiming and Joty, Shafiq and Naik, Nikhil},
  journal={arXiv preprint arXiv:2311.12908},
  year={2023}
}
@article{koh2023GILL,
  title={Generating Images with Multimodal Language Models},
  author={Koh, Jing Yu and Fried, Daniel and Salakhutdinov, Ruslan},
  journal={NeurIPS},
  year={2023}
}
@misc{SDEdit,
      title={SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations}, 
      author={Chenlin Meng and Yutong He and Yang Song and Jiaming Song and Jiajun Wu and Jun-Yan Zhu and Stefano Ermon},
      year={2022},
      eprint={2108.01073},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2108.01073}, 
}
@misc{suti,
      title={Subject-driven Text-to-Image Generation via Apprenticeship Learning}, 
      author={Wenhu Chen and Hexiang Hu and Yandong Li and Nataniel Ruiz and Xuhui Jia and Ming-Wei Chang and William W. Cohen},
      year={2023},
      eprint={2304.00186},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2304.00186}, 
}
@misc{ma2024subjectdiffusionopendomainpersonalizedtexttoimage,
      title={Subject-Diffusion:Open Domain Personalized Text-to-Image Generation without Test-time Fine-tuning}, 
      author={Jian Ma and Junhao Liang and Chen Chen and Haonan Lu},
      year={2024},
      eprint={2307.11410},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.11410}, 
}
@misc{gal2022imageworthwordpersonalizing,
      title={An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion}, 
      author={Rinon Gal and Yuval Alaluf and Yuval Atzmon and Or Patashnik and Amit H. Bermano and Gal Chechik and Daniel Cohen-Or},
      year={2022},
      eprint={2208.01618},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2208.01618}, 
}
@misc{ruiz2023dreamboothfinetuningtexttoimage,
      title={DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation}, 
      author={Nataniel Ruiz and Yuanzhen Li and Varun Jampani and Yael Pritch and Michael Rubinstein and Kfir Aberman},
      year={2023},
      eprint={2208.12242},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2208.12242}, 
}
@misc{MVADER,
      title={M-VADER: A Model for Diffusion with Multimodal Context}, 
      author={Samuel Weinbach and Marco Bellagente and Constantin Eichenberg and Andrew Dai and Robert Baldock and Souradeep Nanda and Björn Deiseroth and Koen Oostermeijer and Hannah Teufel and Andres Felipe Cruz-Salinas},
      year={2022},
      eprint={2212.02936},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.02936}, 
}
@misc{zheng2023minigpt5,
      title={MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens}, 
      author={Kaizhi Zheng and Xuehai He and Xin Eric Wang},
      year={2023},
      journal={arXiv preprint arXiv:2310.02239}
}

@misc{sun2023emu1,
      title={Generative Pretraining in Multimodality}, 
      author={Quan Sun and Qiying Yu and Yufeng Cui and Fan Zhang and Xiaosong Zhang and Yueze Wang and Hongcheng Gao and Jingjing Liu and Tiejun Huang and Xinlong Wang},
      year={2023},
      eprint={2307.05222},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


% ======================= datasets ===================== %
@article{pham2023combined,
  title={Combined scaling for zero-shot transfer learning},
  author={Pham, Hieu and Dai, Zihang and Ghiasi, Golnaz and Kawaguchi, Kenji and Liu, Hanxiao and Yu, Adams Wei and Yu, Jiahui and Chen, Yi-Ting and Luong, Minh-Thang and Wu, Yonghui and others},
  journal={Neurocomputing},
  volume={555},
  pages={126658},
  year={2023},
  publisher={Elsevier}
}
@article{yuan2021florence,
  title={Florence: A new foundation model for computer vision},
  author={Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and others},
  journal={arXiv preprint arXiv:2111.11432},
  year={2021}
}
@article{nextgpt,
  title   = {NExT-GPT: Any-to-Any Multimodal LLM},
  author  = {Shengqiong Wu and Hao Fei and Leigang Qu and Wei Ji and Tat-Seng Chua},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2309.05519},
  url     = {https://arxiv.org/abs/2309.05519v2},
  pdf     = {https://arxiv.org/pdf/2309.05519.pdf}
}
@inproceedings{brooks2023instructpix2pix,
  title={Instructpix2pix: Learning to follow image editing instructions},
  author={Brooks, Tim and Holynski, Aleksander and Efros, Alexei A},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18392--18402},
  year={2023}
}
@article{Hertz2022PrompttoPromptIE,
  title={Prompt-to-Prompt Image Editing with Cross Attention Control},
  author={Amir Hertz and Ron Mokady and Jay M. Tenenbaum and Kfir Aberman and Yael Pritch and Daniel Cohen-Or},
  journal={ArXiv},
  year={2022},
  volume={abs/2208.01626},
  url={https://api.semanticscholar.org/CorpusID:251252882}
}
@article{zhang2023hive,
  title={Hive: Harnessing human feedback for instructional visual editing},
  author={Zhang, Shu and Yang, Xinyi and Feng, Yihao and Qin, Can and Chen, Chia-Chih and Yu, Ning and Chen, Zeyuan and Wang, Huan and Savarese, Silvio and Ermon, Stefano and others},
  journal={arXiv preprint arXiv:2303.09618},
  year={2023}
}
@article{zhang2024magicbrush,
  title={Magicbrush: A manually annotated dataset for instruction-guided image editing},
  author={Zhang, Kai and Mo, Lingbo and Chen, Wenhu and Sun, Huan and Su, Yu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{hui2024hq,
  title={HQ-Edit: A High-Quality Dataset for Instruction-based Image Editing},
  author={Hui, Mude and Yang, Siwei and Zhao, Bingchen and Shi, Yichun and Wang, Heng and Wang, Peng and Zhou, Yuyin and Xie, Cihang},
  journal={arXiv preprint arXiv:2404.09990},
  year={2024}
}
@article{lyu2023macaw,
  title={Macaw-llm: Multi-modal language modeling with image, audio, video, and text integration},
  author={Lyu, Chenyang and Wu, Minghao and Wang, Longyue and Huang, Xinting and Liu, Bingshuai and Du, Zefeng and Shi, Shuming and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2306.09093},
  year={2023}
}
@article{wang2023see,
  title={To see is to believe: Prompting gpt-4v for better visual instruction tuning},
  author={Wang, Junke and Meng, Lingchen and Weng, Zejia and He, Bo and Wu, Zuxuan and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2311.07574},
  year={2023}
}
@article{li2023m3dbench,
  title={M3DBench: Let's Instruct Large Models with Multi-modal 3D Prompts},
  author={Li, Mingsheng and Chen, Xin and Zhang, Chi and Chen, Sijin and Zhu, Hongyuan and Yin, Fukun and Yu, Gang and Chen, Tao},
  journal={arXiv preprint arXiv:2312.10763},
  year={2023}
}
@article{gunjal2023detecting,
  title={Detecting and preventing hallucinations in large vision language models},
  author={Gunjal, Anisha and Yin, Jihan and Bas, Erhan},
  journal={arXiv preprint arXiv:2308.06394},
  year={2023}
}
@article{huang2023sparkles,
  title={Sparkles: Unlocking chats across multiple images for multimodal instruction-following models},
  author={Huang, Yupan and Meng, Zaiqiao and Liu, Fangyu and Su, Yixuan and Collier, Nigel and Lu, Yutong},
  journal={arXiv preprint arXiv:2308.16463},
  year={2023}
}
@article{li2023stablellava,
  title={Stablellava: Enhanced visual instruction tuning with synthesized image-dialogue data},
  author={Li, Yanda and Zhang, Chi and Yu, Gang and Wang, Zhibin and Fu, Bin and Lin, Guosheng and Shen, Chunhua and Chen, Ling and Wei, Yunchao},
  journal={arXiv preprint arXiv:2308.10253},
  year={2023}
}
@article{zhao2023chatspot,
  title={Chatspot: Bootstrapping multimodal llms via precise referring instruction tuning},
  author={Zhao, Liang and Yu, En and Ge, Zheng and Yang, Jinrong and Wei, Haoran and Zhou, Hongyu and Sun, Jianjian and Peng, Yuang and Dong, Runpei and Han, Chunrui and others},
  journal={arXiv preprint arXiv:2307.09474},
  year={2023}
}
@inproceedings{liu2023mitigating,
  title={Mitigating hallucination in large multi-modal models via robust instruction tuning},
  author={Liu, Fuxiao and Lin, Kevin and Li, Linjie and Wang, Jianfeng and Yacoob, Yaser and Wang, Lijuan},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}
@article{jiang2024motiongpt,
  title={Motiongpt: Human motion as a foreign language},
  author={Jiang, Biao and Chen, Xin and Liu, Wen and Yu, Jingyi and Yu, Gang and Chen, Tao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{chen2023visual,
  title={Visual instruction tuning with polite flamingo},
  author={Chen, Delong and Liu, Jianfeng and Dai, Wenliang and Wang, Baoyuan},
  journal={arXiv preprint arXiv:2307.01003},
  year={2023}
}
@article{zhao2023svit,
  title={Svit: Scaling up visual instruction tuning},
  author={Zhao, Bo and Wu, Boya and Huang, Tiejun},
  journal={arXiv preprint arXiv:2307.04087},
  year={2023}
}
@article{zhao2023bubogpt,
  title={Bubogpt: Enabling visual grounding in multi-modal llms},
  author={Zhao, Yang and Lin, Zhijie and Zhou, Daquan and Huang, Zilong and Feng, Jiashi and Kang, Bingyi},
  journal={arXiv preprint arXiv:2307.08581},
  year={2023}
}
@article{zhang2023llavar,
  title={Llavar: Enhanced visual instruction tuning for text-rich image understanding},
  author={Zhang, Yanzhe and Zhang, Ruiyi and Gu, Jiuxiang and Zhou, Yufan and Lipka, Nedim and Yang, Diyi and Sun, Tong},
  journal={arXiv preprint arXiv:2306.17107},
  year={2023}
}
@article{yin2024lamm,
  title={Lamm: Language-assisted multi-modal instruction-tuning dataset, framework, and benchmark},
  author={Yin, Zhenfei and Wang, Jiong and Cao, Jianjian and Shi, Zhelun and Liu, Dingning and Li, Mukai and Huang, Xiaoshui and Wang, Zhiyong and Sheng, Lu and Bai, Lei and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{maaz2023video,
  title={Video-chatgpt: Towards detailed video understanding via large vision and language models},
  author={Maaz, Muhammad and Rasheed, Hanoona and Khan, Salman and Khan, Fahad Shahbaz},
  journal={arXiv preprint arXiv:2306.05424},
  year={2023}
}
@article{pi2023detgpt,
  title={Detgpt: Detect what you need via reasoning},
  author={Pi, Renjie and Gao, Jiahui and Diao, Shizhe and Pan, Rui and Dong, Hanze and Zhang, Jipeng and Yao, Lewei and Han, Jianhua and Xu, Hang and Zhang, Lingpeng Kong Tong},
  journal={arXiv preprint arXiv:2305.14167},
  year={2023}
}
@article{yang2024gpt4tools,
  title={Gpt4tools: Teaching large language model to use tools via self-instruction},
  author={Yang, Rui and Song, Lin and Li, Yanwei and Zhao, Sijie and Ge, Yixiao and Li, Xiu and Shan, Ying},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{li2024llava,
  title={Llava-med: Training a large language-and-vision assistant for biomedicine in one day},
  author={Li, Chunyuan and Wong, Cliff and Zhang, Sheng and Usuyama, Naoto and Liu, Haotian and Yang, Jianwei and Naumann, Tristan and Poon, Hoifung and Gao, Jianfeng},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{li2023lmeye,
  title={Lmeye: An interactive perception network for large language models},
  author={Li, Yunxin and Hu, Baotian and Chen, Xinyu and Ma, Lin and Zhang, Min},
  journal={arXiv preprint arXiv:2305.03701},
  year={2023}
}
@article{chen2023x,
  title={X-llm: Bootstrapping advanced large language models by treating multi-modalities as foreign languages},
  author={Chen, Feilong and Han, Minglun and Zhao, Haozhi and Zhang, Qingyang and Shi, Jing and Xu, Shuang and Xu, Bo},
  journal={arXiv preprint arXiv:2305.04160},
  year={2023}
}
@article{zhang2023pmc,
  title={Pmc-vqa: Visual instruction tuning for medical visual question answering},
  author={Zhang, Xiaoman and Wu, Chaoyi and Zhao, Ziheng and Lin, Weixiong and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},
  journal={arXiv preprint arXiv:2305.10415},
  year={2023}
}
@article{li2023videochat,
  title={Videochat: Chat-centric video understanding},
  author={Li, KunChang and He, Yinan and Wang, Yi and Li, Yizhuo and Wang, Wenhai and Luo, Ping and Wang, Yali and Wang, Limin and Qiao, Yu},
  journal={arXiv preprint arXiv:2305.06355},
  year={2023}
}


@software{together2023redpajama,
  author = {Together Computer},
  title = {RedPajama: an Open Dataset for Training Large Language Models},
  month = October,
  year = 2023,
  url = {https://github.com/togethercomputer/RedPajama-Data}
}
# mC4
@inproceedings{xue2021mt5,
  title={mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer},
  author={Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={483--498},
  year={2021}
}
# C4
@inproceedings{habernal2016c4corpus,
  title={C4Corpus: Multilingual Web-size corpus with free license},
  author={Habernal, Ivan and Zayed, Omnia and Gurevych, Iryna},
  booktitle={Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)},
  pages={914--922},
  year={2016}
}
# Wiki
@inproceedings{guo2020wiki,
  title={Wiki-40b: Multilingual language model dataset},
  author={Guo, Mandy and Dai, Zihang and Vrande{\v{c}}i{\'c}, Denny and Al-Rfou, Rami},
  booktitle={Proceedings of the Twelfth Language Resources and Evaluation Conference},
  pages={2440--2452},
  year={2020}
}
# Pile
@article{gao2020pile,
  title={The pile: An 800gb dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}
# ImageNet-1K
@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  pages={211--252},
  year={2015},
  publisher={Springer}
}
#ImageNet-21k
@article{ridnik2021imagenet,
  title={Imagenet-21k pretraining for the masses},
  author={Ridnik, Tal and Ben-Baruch, Emanuel and Noy, Asaf and Zelnik-Manor, Lihi},
  journal={arXiv preprint arXiv:2104.10972},
  year={2021}
}
# JFT-300M
@inproceedings{sun2017revisiting,
  title={Revisiting unreasonable effectiveness of data in deep learning era},
  author={Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={843--852},
  year={2017}
}
# JFT-3B
@inproceedings{zhai2022scaling,
  title={Scaling vision transformers},
  author={Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12104--12113},
  year={2022}
}
# IG-3.6B
@inproceedings{singh2022revisiting,
  title={Revisiting weakly supervised pre-training of visual perception models},
  author={Singh, Mannat and Gustafson, Laura and Adcock, Aaron and de Freitas Reis, Vinicius and Gedik, Bugra and Kosaraju, Raj Prateek and Mahajan, Dhruv and Girshick, Ross and Doll{\'a}r, Piotr and Van Der Maaten, Laurens},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={804--814},
  year={2022}
}
# I2E
@article{wu2023mofi,
  title={MOFI: Learning Image Representations from Noisy Entity Annotated Images},
  author={Wu, Wentao and Timofeev, Aleksei and Chen, Chen and Zhang, Bowen and Duan, Kun and Liu, Shuangning and Zheng, Yantao and Shlens, Jon and Du, Xianzhi and Gan, Zhe and others},
  journal={arXiv preprint arXiv:2306.07952},
  year={2023}
}
@article{strokenvwa,
  title   = {StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis},
  author  = {Zecheng Tang and Chenfei Wu and Zekai Zhang and Mingheng Ni and Shengming Yin and Yu Liu and Zhengyuan Yang and Lijuan Wang and Zicheng Liu and Juntao Li and Nan Duan},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2401.17093}
}

# UVD-v1
@article{bai2023sequential,
  title={Sequential modeling enables scalable learning for large vision models},
  author={Bai, Yutong and Geng, Xinyang and Mangalam, Karttikeya and Bar, Amir and Yuille, Alan and Darrell, Trevor and Malik, Jitendra and Efros, Alexei A},
  journal={arXiv preprint arXiv:2312.00785},
  year={2023}
}

% Cross-Modal
# SBU
@article{ordonez2011im2text,
  title={Im2text: Describing images using 1 million captioned photographs},
  author={Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}
# MSCOCO
@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}
# flickr30k
@inproceedings{plummer2015flickr30k,
  title={Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models},
  author={Plummer, Bryan A and Wang, Liwei and Cervantes, Chris M and Caicedo, Juan C and Hockenmaier, Julia and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2641--2649},
  year={2015}
}
# yfcc-100m
@article{thomee2016yfcc100m,
  title={YFCC100M: The new data in multimedia research},
  author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={Communications of the ACM},
  volume={59},
  number={2},
  pages={64--73},
  year={2016},
  publisher={ACM New York, NY, USA}
}
# VG
@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  pages={32--73},
  year={2017},
  publisher={Springer}
}
# AI-Caps
@article{wu2017ai,
  title={Ai challenger: A large-scale dataset for going deeper in image understanding},
  author={Wu, Jiahong and Zheng, He and Zhao, Bo and Li, Yixin and Yan, Baoming and Liang, Rui and Wang, Wenjia and Zhou, Shipei and Lin, Guosen and Fu, Yanwei and others},
  journal={arXiv preprint arXiv:1711.06475},
  year={2017}
}
# CC3M
@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2556--2565},
  year={2018}
}
# CC12M
@inproceedings{changpinyo2021conceptual,
  title={Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3558--3568},
  year={2021}
}
# WIT
@inproceedings{srinivasan2021wit,
  title={Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning},
  author={Srinivasan, Krishna and Raman, Karthik and Chen, Jiecao and Bendersky, Michael and Najork, Marc},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2443--2449},
  year={2021}
}
# RedCaps
@article{desai2021redcaps,
  title={RedCaps: Web-curated image-text data created by the people, for the people},
  author={Desai, Karan and Kaul, Gaurav and Aysola, Zubin and Johnson, Justin},
  journal={arXiv preprint arXiv:2111.11431},
  year={2021}
}
# filip
@article{yao2021filip,
  title={Filip: Fine-grained interactive language-image pre-training},
  author={Yao, Lewei and Huang, Runhui and Hou, Lu and Lu, Guansong and Niu, Minzhe and Xu, Hang and Liang, Xiaodan and Li, Zhenguo and Jiang, Xin and Xu, Chunjing},
  journal={arXiv preprint arXiv:2111.07783},
  year={2021}
}
# Laion-400M
@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}
# wukong
@article{gu2022wukong,
  title={Wukong: A 100 million large-scale chinese cross-modal pre-training benchmark},
  author={Gu, Jiaxi and Meng, Xiaojun and Lu, Guansong and Hou, Lu and Minzhe, Niu and Liang, Xiaodan and Yao, Lewei and Huang, Runhui and Zhang, Wei and Jiang, Xin and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={26418--26431},
  year={2022}
}
# Shutterstock
@article{nguyen2022quality,
  title={Quality not quantity: On the interaction between dataset design and robustness of clip},
  author={Nguyen, Thao and Ilharco, Gabriel and Wortsman, Mitchell and Oh, Sewoong and Schmidt, Ludwig},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21455--21469},
  year={2022}
}
# Coyo-700m
@misc{kakaobrain2022coyo-700m,
title = {COYO-700M: Image-Text Pair Dataset},
author = {Byeon, Minwoo and Park, Beomhee and Kim, Haecheon and Lee, Sungjun and Baek, Woonhyuk and Kim, Saehoon},
year = {2022},
howpublished = {\url{https://github.com/kakaobrain/coyo-dataset}},
}
# Laion-5b
@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}
# Datacomp
@article{gadre2023datacomp,
  title={DataComp: In search of the next generation of multimodal datasets},
  author={Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and others},
  journal={arXiv preprint arXiv:2304.14108},
  year={2023}
}
# AS-1B
@article{wang2023all,
  title={The all-seeing project: Towards panoptic visual recognition and understanding of the open world},
  author={Wang, Weiyun and Shi, Min and Li, Qingyun and Wang, Wenhai and Huang, Zhenhang and Xing, Linjie and Chen, Zhe and Li, Hao and Zhu, Xizhou and Cao, Zhiguo and others},
  journal={arXiv preprint arXiv:2308.01907},
  year={2023}
}
# capsfusion
@article{yu2023capsfusion,
  title={CapsFusion: Rethinking Image-Text Data at Scale},
  author={Yu, Qiying and Sun, Quan and Zhang, Xiaosong and Cui, Yufeng and Zhang, Fan and Wang, Xinlong and Liu, Jingjing},
  journal={arXiv preprint arXiv:2310.20550},
  year={2023}
}
# sharegpt4v
@article{chen2023sharegpt4v,
  title={ShareGPT4V: Improving Large Multi-Modal Models with Better Captions},
  author={Chen, Lin and Li, Jisong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
  journal={arXiv preprint arXiv:2311.12793},
  year={2023}
}
# Video-text
# Msr-vtt
@inproceedings{xu2016msr,
  title={Msr-vtt: A large video description dataset for bridging video and language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5288--5296},
  year={2016}
}
# Howto100m
@inproceedings{miech2019howto100m,
  title={Howto100m: Learning a text-video embedding by watching hundred million narrated video clips},
  author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2630--2640},
  year={2019}
}
# Acav100m
@inproceedings{lee2021acav100m,
  title={Acav100m: Automatic curation of large-scale datasets for audio-visual video representation learning},
  author={Lee, Sangho and Chung, Jiwan and Yu, Youngjae and Kim, Gunhee and Breuel, Thomas and Chechik, Gal and Song, Yale},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10274--10284},
  year={2021}
}

# ego4d
@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}
# HD-VILA
@inproceedings{xue2022advancing,
  title={Advancing high-resolution video-language representation with large-scale video transcriptions},
  author={Xue, Hongwei and Hang, Tiankai and Zeng, Yanhong and Sun, Yuchong and Liu, Bei and Yang, Huan and Fu, Jianlong and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5036--5045},
  year={2022}
}
# YT-T
@inproceedings{zellers2022merlot,
  title={Merlot reserve: Neural script knowledge through vision and language and sound},
  author={Zellers, Rowan and Lu, Jiasen and Lu, Ximing and Yu, Youngjae and Zhao, Yanpeng and Salehi, Mohammadreza and Kusupati, Aditya and Hessel, Jack and Farhadi, Ali and Choi, Yejin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16375--16387},
  year={2022}
}
# VideoCC3M
@inproceedings{nagrani2022learning,
  title={Learning audio-video modalities from image captions},
  author={Nagrani, Arsha and Seo, Paul Hongsuck and Seybold, Bryan and Hauth, Anja and Manen, Santiago and Sun, Chen and Schmid, Cordelia},
  booktitle={European Conference on Computer Vision},
  pages={407--426},
  year={2022},
  organization={Springer}
}
# Youku-mplug
@article{xu2023youku,
  title={Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for Pre-training and Benchmarks},
  author={Xu, Haiyang and Ye, Qinghao and Wu, Xuan and Yan, Ming and Miao, Yuan and Ye, Jiabo and Xu, Guohai and Hu, Anwen and Shi, Yaya and Xu, Guangwei and others},
  journal={arXiv preprint arXiv:2306.04362},
  year={2023}
}
# internvid
@article{wang2023internvid,
  title={Internvid: A large-scale video-text dataset for multimodal understanding and generation},
  author={Wang, Yi and He, Yinan and Li, Yizhuo and Li, Kunchang and Yu, Jiashuo and Ma, Xin and Li, Xinhao and Chen, Guo and Chen, Xinyuan and Wang, Yaohui and others},
  journal={arXiv preprint arXiv:2307.06942},
  year={2023}
}
# Interleaved
# M3W
@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}
# MMC4
@article{zhu2023multimodal,
  title={Multimodal c4: An open, billion-scale corpus of images interleaved with text},
  author={Zhu, Wanrong and Hessel, Jack and Awadalla, Anas and Gadre, Samir Yitzhak and Dodge, Jesse and Fang, Alex and Yu, Youngjae and Schmidt, Ludwig and Wang, William Yang and Choi, Yejin},
  journal={arXiv preprint arXiv:2304.06939},
  year={2023}
}
# obelisc
@article{laurenccon2023obelisc,
  title={Obelisc: An open web-scale filtered dataset of interleaved image-text documents},
  author={Lauren{\c{c}}on, Hugo and Saulnier, Lucile and Tronchon, L{\'e}o and Bekman, Stas and Singh, Amanpreet and Lozhkov, Anton and Wang, Thomas and Karamcheti, Siddharth and Rush, Alexander M and Kiela, Douwe and others},
  journal={arXiv preprint arXiv:2306.16527},
  year={2023}
}
# kosmos GRIT
@article{peng2023kosmos,
  title={Kosmos-2: Grounding Multimodal Large Language Models to the World},
  author={Peng, Zhiliang and Wang, Wenhui and Dong, Li and Hao, Yaru and Huang, Shaohan and Ma, Shuming and Wei, Furu},
  journal={arXiv preprint arXiv:2306.14824},
  year={2023}
}

@article{sun2023generative,
  title={Generative Multimodal Models are In-Context Learners},
  author={Sun, Quan and Cui, Yufeng and Zhang, Xiaosong and Zhang, Fan and Yu, Qiying and Luo, Zhengxiong and Wang, Yueze and Rao, Yongming and Liu, Jingjing and Huang, Tiejun and others},
  journal={arXiv preprint arXiv:2312.13286},
  year={2023}
}
 @article{FSQ,  
 title={Finite Scalar Quantization: VQ-VAE Made Simple}, 
 author={Mentzer, Fabian and Minnen, David and Agustsson, Eirikur and Tschannen, Michael}, 
 year={2023}, 
 month={Sep}, 
 language={en-US} 
 }
# Audio set
@inproceedings{gemmeke2017audio,
  title={Audio set: An ontology and human-labeled dataset for audio events},
  author={Gemmeke, Jort F and Ellis, Daniel PW and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle={2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={776--780},
  year={2017},
  organization={IEEE}
}
# aishell-1
@inproceedings{bu2017aishell,
  title={Aishell-1: An open-source mandarin speech corpus and a speech recognition baseline},
  author={Bu, Hui and Du, Jiayu and Na, Xingyu and Wu, Bengu and Zheng, Hao},
  booktitle={2017 20th conference of the oriental chapter of the international coordinating committee on speech databases and speech I/O systems and assessment (O-COCOSDA)},
  pages={1--5},
  year={2017},
  organization={IEEE}
}
# aishell-2
@article{du2018aishell,
  title={Aishell-2: Transforming mandarin asr research into industrial scale},
  author={Du, Jiayu and Na, Xingyu and Liu, Xuechen and Bu, Hui},
  journal={arXiv preprint arXiv:1808.10583},
  year={2018}
}
# wavcaps
@article{mei2023wavcaps,
  title={Wavcaps: A chatgpt-assisted weakly-labelled audio captioning dataset for audio-language multimodal research},
  author={Mei, Xinhao and Meng, Chutong and Liu, Haohe and Kong, Qiuqiang and Ko, Tom and Zhao, Chengqi and Plumbley, Mark D and Zou, Yuexian and Wang, Wenwu},
  journal={arXiv preprint arXiv:2303.17395},
  year={2023}
}
% ============================ datesets end ======================== %

@article{Chen_Radford_Child_Wu_Jun_Luan_Sutskever_2020_GPP,   title={Generative Pretraining From Pixels},  journal={International Conference on Machine Learning,International Conference on Machine Learning},  author={Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},  year={2020},  month={Jul},  language={en-US}  }

@inproceedings{Radford2021LearningTV,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  booktitle={International Conference on Machine Learning},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:231591445}
}

@misc{lu2023unifiedio2,
      title={Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision, Language, Audio, and Action}, 
      author={Jiasen Lu and Christopher Clark and Sangho Lee and Zichen Zhang and Savya Khosla and Ryan Marten and Derek Hoiem and Aniruddha Kembhavi},
      year={2023},
      eprint={2312.17172},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{lu2022unifiedio,
      title={Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks}, 
      author={Jiasen Lu and Christopher Clark and Rowan Zellers and Roozbeh Mottaghi and Aniruddha Kembhavi},
      year={2022},
      eprint={2206.08916},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@article{wang2022ofa,
  author    = {Peng Wang and
               An Yang and
               Rui Men and
               Junyang Lin and
               Shuai Bai and
               Zhikang Li and
               Jianxin Ma and
               Chang Zhou and
               Jingren Zhou and
               Hongxia Yang},
  title     = {OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence
               Learning Framework},
  journal   = {CoRR},
  volume    = {abs/2202.03052},
  year      = {2022}
}

@inproceedings{Lu2023UnifiedIO2S,
  title={Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision, Language, Audio, and Action},
  author={Jiasen Lu and Christopher Clark and Sangho Lee and Zichen Zhang and Savya Khosla and Ryan Marten and Derek Hoiem and Aniruddha Kembhavi},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:266573555}
}
@article{ast,
  title     = {AST: Audio Spectrogram Transformer},
  author    = {Yuan Gong and Yu-An Chung and James R. Glass},
  journal   = {INTERSPEECH},
  year      = {2021},
  doi       = {10.21437/interspeech.2021-698},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/0e2d8b8d81092037f9866c1ceddcebb87318e38b}
}
@article{sam,
  title   = {Segment Anything},
  author  = {Alexander Kirillov and Eric Mintun and Nikhila Ravi and Hanzi Mao and Chloe Rolland and Laura Gustafson and Tete Xiao and Spencer Whitehead and Alexander C. Berg and Wan-Yen Lo and Piotr Dollár and Ross Girshick},
  year    = {2023},
  journal = {ICCV}
}
@article{beit,
  title   = {BEiT: BERT Pre-Training of Image Transformers},
  author  = {Hangbo Bao and Li Dong and Songhao Piao and Furu Wei},
  year    = {2021},
  journal = {arXiv preprint arXiv: 2106.08254}
}
@article{prismer,
  title   = {Prismer: A Vision-Language Model with Multi-Task Experts},
  author  = {Shikun Liu and Linxi Fan and Edward Johns and Zhiding Yu and Chaowei Xiao and Anima Anandkumar},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2303.02506}
}
@article{mert,
  title   = {MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training},
  author  = {Yizhi Li and Ruibin Yuan and Ge Zhang and Yinghao Ma and Xingran Chen and Hanzhi Yin and Chenghao Xiao and Chenghua Lin and Anton Ragni and Emmanouil Benetos and Norbert Gyenge and Roger Dannenberg and Ruibo Liu and Wenhu Chen and Gus Xia and Yemin Shi and Wenhao Huang and Zili Wang and Yike Guo and Jie Fu},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2306.00107}
}
@article{usm,
  title   = {Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages},
  author  = {Yu Zhang and Wei Han and James Qin and Yongqiang Wang and Ankur Bapna and Zhehuai Chen and Nanxin Chen and Bo Li and Vera Axelrod and Gary Wang and Zhong Meng and Ke Hu and Andrew Rosenberg and Rohit Prabhavalkar and Daniel S. Park and Parisa Haghani and Jason Riesa and Ginger Perng and Hagen Soltau and Trevor Strohman and Bhuvana Ramabhadran and Tara Sainath and Pedro Moreno and Chung-Cheng Chiu and Johan Schalkwyk and Françoise Beaufays and Yonghui Wu},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2303.01037}
}
@article{Sennrich2015NeuralMT,
  title={Neural Machine Translation of Rare Words with Subword Units},
  author={Rico Sennrich and Barry Haddow and Alexandra Birch},
  journal={ArXiv},
  year={2015},
  volume={abs/1508.07909},
  url={https://api.semanticscholar.org/CorpusID:1114678}
}
@misc{cao2023efficientvqgan,
      title={Efficient-VQGAN: Towards High-Resolution Image Generation with Efficient Vision Transformers}, 
      author={Shiyue Cao and Yueqin Yin and Lianghua Huang and Yu Liu and Xin Zhao and Deli Zhao and Kaiqi Huang},
      year={2023},
      eprint={2310.05400},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{imagebind,
  title   = {ImageBind: One Embedding Space To Bind Them All},
  author  = {Rohit Girdhar and Alaaeldin El-Nouby and Zhuang Liu and Mannat Singh and Kalyan Vasudev Alwala and Armand Joulin and Ishan Misra},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2305.05665}
}
@misc{liu2021swinTransformer,
      title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows}, 
      author={Ze Liu and Yutong Lin and Yue Cao and Han Hu and Yixuan Wei and Zheng Zhang and Stephen Lin and Baining Guo},
      year={2021},
      eprint={2103.14030},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{liu2022swinV2,
      title={Swin Transformer V2: Scaling Up Capacity and Resolution}, 
      author={Ze Liu and Han Hu and Yutong Lin and Zhuliang Yao and Zhenda Xie and Yixuan Wei and Jia Ning and Yue Cao and Zheng Zhang and Li Dong and Furu Wei and Baining Guo},
      year={2022},
      eprint={2111.09883},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{cao2021swinunet,
      title={Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation}, 
      author={Hu Cao and Yueyue Wang and Joy Chen and Dongsheng Jiang and Xiaopeng Zhang and Qi Tian and Manning Wang},
      year={2021},
      eprint={2105.05537},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}
@misc{xu2023swin,
      title={Swin MAE: Masked Autoencoders for Small Datasets}, 
      author={Zi'an Xu and Yin Dai and Fayu Liu and Weibing Chen and Yue Liu and Lifu Shi and Sheng Liu and Yuhang Zhou},
      year={2023},
      eprint={2212.13805},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{yu2022vectorquantized,
      title={Vector-quantized Image Modeling with Improved VQGAN}, 
      author={Jiahui Yu and Xin Li and Jing Yu Koh and Han Zhang and Ruoming Pang and James Qin and Alexander Ku and Yuanzhong Xu and Jason Baldridge and Yonghui Wu},
      year={2022},
      eprint={2110.04627},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{EVA-02,
title = {EVA-02: A visual representation for neon genesis},
journal = {Image and Vision Computing},
volume = {149},
pages = {105171},
year = {2024},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2024.105171},
url = {https://www.sciencedirect.com/science/article/pii/S0262885624002762},
author = {Yuxin Fang and Quan Sun and Xinggang Wang and Tiejun Huang and Xinlong Wang and Yue Cao},
keywords = {Representation learning, Foundation model, Vision transformer},
abstract = {We launch EVA-02, a next-generation Transformer-based visual representation pre-trained to reconstruct strong and robust language-aligned vision features via masked image modeling. With an updated plain Transformer architecture as well as extensive pre-training from an open & accessible giant CLIP vision encoder, EVA-02 demonstrates superior performance compared to prior state-of-the-art approaches across various representative vision tasks, while utilizing significantly fewer parameters and compute budgets. Notably, using exclusively publicly accessible training data, EVA-02 with only 304 M parameters achieves a phenomenal 90.0 fine-tuning top-1 accuracy on ImageNet-1 K val set. Additionally, our EVA-02-CLIP can reach up to 80.4 zero-shot top-1 on ImageNet-1 K, outperforming the previous largest & best open-sourced CLIP with only ∼1/6 parameters and ∼ 1/6 image-text training data. We offer four EVA-02 variants in various model sizes, ranging from 6 M to 304 M parameters, all with impressive performance. To facilitate open access and open research, we release the complete suite of EVA-02 to the community at https://github.com/baaivision/EVA/tree/master/EVA-02.}
}
@article{Esser2020TamingTF,
  title={Taming Transformers for High-Resolution Image Synthesis},
  author={Patrick Esser and Robin Rombach and Bj{\"o}rn Ommer},
  journal={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
  pages={12868-12878},
  url={https://api.semanticscholar.org/CorpusID:229297973}
}
 @article{Lee_Kim_Kim_Cho_Han_2022,  
 title={Autoregressive Image Generation using Residual Quantization}, 
 journal={Cornell University - arXiv,Cornell University - arXiv}, 
 author={Lee, Doyup and Kim, Chiheon and Kim, Saehoon and Cho, Minsu and Han, Wook-Shin}, 
 year={2022}, 
 month={Mar}, 
 language={en-US} 
 }

 @article{PO-VAE,  
 title={Image Compression with Product Quantized Masked Image Modeling}, 
 author={El-Nouby, Alaaeldin and Muckley, MatthewJ. and Ullrich, Karen and Laptev, Ivan and Verbeek, Jakob and J\'{e}gou, Herv\'{e}}, 
 year={2022}, 
 month={Dec}, 
 language={en-US} 
 }

 @article{Zeghidour_Luebs_Omran_Skoglund_Tagliasacchi_2022,  
 title={SoundStream: An End-to-End Neural Audio Codec}, 
 url={http://dx.doi.org/10.1109/taslp.2021.3129994}, 
 DOI={10.1109/taslp.2021.3129994}, 
 journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
 author={Zeghidour, Neil and Luebs, Alejandro and Omran, Ahmed and Skoglund, Jan and Tagliasacchi, Marco}, 
 year={2022}, 
 month={Jan}, 
 pages={495–507}, 
 language={en-US} 
 }
@inproceedings{Razavi2019GeneratingDH,
  title={Generating Diverse High-Fidelity Images with VQ-VAE-2},
  author={Ali Razavi and A{\"a}ron van den Oord and Oriol Vinyals},
  booktitle={Neural Information Processing Systems},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:173990382}
}

@article{Oord2017NeuralDR,
  title={Neural Discrete Representation Learning},
  author={A{\"a}ron van den Oord and Oriol Vinyals and Koray Kavukcuoglu},
  journal={ArXiv},
  year={2017},
  volume={abs/1711.00937},
  url={https://api.semanticscholar.org/CorpusID:20282961}
}

@article{Tschannen2023ImageCA,
  title={Image Captioners Are Scalable Vision Learners Too},
  author={Michael Tschannen and Manoj Kumar and Andreas Steiner and Xiaohua Zhai and Neil Houlsby and Lucas Beyer},
  journal={ArXiv},
  year={2023},
  volume={abs/2306.07915},
  url={https://api.semanticscholar.org/CorpusID:259145047}
}

% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries

@Article{Abril07,
  author        = "Patricia S. Abril and Robert Plant",
  title         = "The patent holder's dilemma: Buy, sell, or troll?",
  journal       = "Communications of the ACM",
  volume        = "50",
  number        = "1",
  month         = jan,
  year          = "2007",
  pages         = "36--44",
  doi           = "10.1145/1188913.1188915",
  url           = "http://doi.acm.org/10.1145/1219092.1219093",
  note          = "",
}

@Article{Cohen07,
  author        = "Sarah Cohen and Werner Nutt and Yehoshua Sagic",
  title         = "Deciding equivalances among conjunctive aggregate queries",
  journal       = JACM,
  articleno     = 5,
  numpages      = 50,
  volume        = 54,
  number        = 2,
  month         = apr,
  year          = 2007,
  doi           = "10.1145/1219092.1219093",
  url           = "http://doi.acm.org/10.1145/1219092.1219093",
  acmid         = 1219093,
}


@periodical{JCohen96,
  key =          "Cohen",
  editor =       "Jacques Cohen",
  title =        "Special issue: Digital Libraries",
  journal =      CACM,
  volume =       "39",
  number =       "11",
  month =        nov,
  year =         "1996",
}


@Book{Kosiur01,
  author =       "David Kosiur",
  title =        "Understanding Policy-Based Networking",
  publisher =    "Wiley",
  year =         "2001",
  address =      "New York, NY",
  edition =      "2nd.",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  month =        "",
  note =         "",
}


@Book{Harel79,
  author =       "David Harel",
  year =         "1979",
  title =        "First-Order Dynamic Logic",
  series =       "Lecture Notes in Computer Science",
  volume =       "68",
  address =      "New York, NY",
  publisher =    "Springer-Verlag",
  doi =          "10.1007/3-540-09237-4",
  url =          "http://dx.doi.org/10.1007/3-540-09237-4",
  editor =       "",
  number =       "",
  month =        "",
  note =         "",
}


@Inbook{Editor00,
  author =       "",
  editor =       "Ian Editor",
  title =        "The title of book one",
  subtitle =     "The book subtitle",
  series =       "The name of the series one",
  year =         "2007",
  volume =       "9",
  address =      "Chicago",
  edition =      "1st.",
  publisher =    "University of Chicago Press",
  doi =          "10.1007/3-540-09237-4",
  url =          "http://dx.doi.org/10.1007/3-540-09456-9",
  chapter =      "",
  pages =        "",
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}

%
@InBook{Editor00a,
  author =       "",
  editor =       "Ian Editor",
  title =        "The title of book two",
  subtitle =     "The book subtitle",
  series =       "The name of the series two",
  year =         "2008",
  address =      "Chicago",
  edition =      "2nd.",
  publisher =    "University of Chicago Press",
  doi =          "10.1007/3-540-09237-4",
  url =          "http://dx.doi.org/10.1007/3-540-09456-9",
  volume =       "",
  chapter =      "100",
  pages =        "",
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}


% incollection (has an editor, title, and possibly a booktitle)
@Incollection{Spector90,
  author =       "Asad Z. Spector",
  title =        "Achieving application requirements",
  booktitle =    "Distributed Systems",
  publisher =    "ACM Press",
  address =      "New York, NY",
  year =         "1990",
  edition =      "2nd.",
  chapter =      "",
  editor =       "Sape Mullender",
  pages =        "19--33",
  doi =          "10.1145/90417.90738",
  url =          "http://doi.acm.org/10.1145/90417.90738",
  volume =       "",
  number =       "",
  series =       "",
  type =         "",
  month =        "",
  note =         "",
}


% incollection (has an editor, title, and possibly a booktitle)
@Incollection{Douglass98,
  author =       "Bruce P. Douglass and David Harel and Mark B. Trakhtenbrot",
  title =        "Statecarts in use: structured analysis and object-orientation",
  series =       "Lecture Notes in Computer Science",
  booktitle =    "Lectures on Embedded Systems",
  publisher =    "Springer-Verlag",
  address =      "London",
  volume =       "1494",
  year =         "1998",
  chapter =      "",
  editor =       "Grzegorz Rozenberg and Frits W. Vaandrager",
  pages =        "368--394",
  doi =          "10.1007/3-540-65193-4_29",
  url =          "http://dx.doi.org/10.1007/3-540-65193-4_29",
  edition =      "",
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}


@Book{Knuth97,
  author =       "Donald E. Knuth",
  title =        "The Art of Computer Programming, Vol. 1: Fundamental Algorithms (3rd. ed.)",
  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
  year =         "1997",
  address =      "",
  edition =      "",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  month =        "",
  note =         "",
}


@Book{Knuth98,
  author =       "Donald E. Knuth",
  year =         "1998",
  title =        "The Art of Computer Programming",
  series =       "Fundamental Algorithms",
  volume =       "1",
  edition =      "3rd",
  address =      "",
  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
  doi =          "",
  url =          "",
  editor =       "",
  number =       "",
  month =        "",
  note =         "(book)",
}
@misc{tian2024VAR,
      title={Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction}, 
      author={Keyu Tian and Yi Jiang and Zehuan Yuan and Bingyue Peng and Liwei Wang},
      year={2024},
      eprint={2404.02905},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
%Inbook{Knuth97,
%  author =       "Donald E. Knuth",
%  title =        "The Art of Computer Programming",
%  booktitle =    "the booktitle",
%  edition =      "3",
%  volume =       "1",
%  year =         "1997",
%  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
%  editor =       "",
%  number =       "",
%  series =       "Fundamental Algorithms",
%  type =         "",
%  chapter =      "",
%  pages =        "",
%  address =      "",
%  month =        "",
%  note =         "(inbook)",
%}

%INBOOK{DK:73-inbook-full,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (inbook w series)",
%   volume = 1,
%   series = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   edition = "Second",
%   month = "10~" # jan,
%   year = "1973",
%   type = "Section",
%   chapter = "1.2",
%   pages = "10--119",
%   note = "Full INBOOK entry (w series)",
%}

%INcollection{DK:74-incoll,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (incoll)",
%   volume = 1,
%   booktitle = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   month = "10~" # jan,
%   year = "1974",
%   pages = "10--119",
%   editor = "Bernard Rous",
%   note = "This is a full incoll entry with an editor",
%}

%INcollection{DK:75-incollws,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (incoll w series)",
%   volume = 1,
%   booktitle = "The Art of Computer Programming",
%   series = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   month = "10~" # jan,
%   year = "1975",
%   pages = "10--119",
%   editor = "Bernard Rous",
%   note = "This is a full incoll entry with an editor and series",
%}

@misc{zhao2024surveylargelanguagemodels,
      title={A Survey of Large Language Models}, 
      author={Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
      year={2024},
      eprint={2303.18223},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.18223}, 
}

@article{clap,
  title   = {CLAP: Learning Audio Concepts From Natural Language Supervision},
  author  = {Benjamin Elizalde and Soham Deshmukh and Mahmoud Al Ismail and Huaming Wang},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2206.04769}
}
@article{eva-clip,
  title   = {EVA-CLIP: Improved Training Techniques for CLIP at Scale},
  author  = {Quan Sun and Yuxin Fang and Ledell Wu and Xinlong Wang and Yue Cao},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2303.15389}
}
@incollection{GM05,
Author= "Dan Geiger and Christopher Meek",
Title= "Structured Variational Inference Procedures and their Realizations (as incol)",
Year= 2005,
Booktitle="Proceedings of Tenth International Workshop on Artificial Intelligence and Statistics, {\rm The Barbados}",
Publisher="The Society for Artificial Intelligence and Statistics",
Month= jan,
Editors= "Z. Ghahramani and R. Cowell"
}

@Inproceedings{Smith10,
  author =       "Stan W. Smith",
  title =        "An experiment in bibliographic mark-up: Parsing metadata for XML export",
  booktitle =    "Proceedings of the 3rd. annual workshop on Librarians and Computers",
  series =       "LAC '10",
  editor =       "Reginald N. Smythe and Alexander Noble",
  volume =       "3",
  year =         "2010",
  publisher =    "Paparazzi Press",
  address =      "Milan Italy",
  pages =        "422--431",
  doi =          "99.9999/woot07-S422",
  url =          "http://dx.doi.org/99.0000/woot07-S422",
  number =       "",
  month =        "",
  organization = "",
  note =         "",
}

@Inproceedings{VanGundy07,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         2007,
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '07",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  articleno =    {Paper 7},
  numpages =     9,
}

@Inproceedings{VanGundy08,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         2008,
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '08",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  articleno =    7,
  numpages =     2,
  pages =        "99-100",
}

@Inproceedings{VanGundy09,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         2009,
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '09",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  pages =        "90--100",
}

@Inproceedings{Andler79,
  author =       "Sten Andler",
  title =        "Predicate Path expressions",
  booktitle =    "Proceedings of the 6th. ACM SIGACT-SIGPLAN symposium on Principles of Programming Languages",
  series =       "POPL '79",
  year =         "1979",
  publisher =    "ACM Press",
  address =      "New York, NY",
  pages =        "226--236",
  doi =          "10.1145/567752.567774",
  url =          "http://doi.acm.org/10.1145/567752.567774",
  editor =       "",
  volume =       "",
  number =       "",
  month =        "",
  organization = "",
  note =         "",
}

@Techreport{Harel78,
  author =       "David Harel",
  year =         "1978",
  title =        "LOGICS of Programs: AXIOMATICS and DESCRIPTIVE POWER",
  institution =  "Massachusetts Institute of Technology",
  type =         "MIT Research Lab Technical Report",
  number =       "TR-200",
  address =      "Cambridge, MA",
  month =        "",
  note =         "",
}

@MASTERSTHESIS{anisi03,
author = {David A. Anisi},
title = {Optimal Motion Control of a Ground Vehicle},
school = {Royal Institute of Technology (KTH), Stockholm, Sweden},
intitution = {FOI-R-0961-SE, Swedish Defence Research Agency (FOI)},
year = {2003},
}


@Phdthesis{Clarkson85,
  author =       "Kenneth L. Clarkson",
  year =         "1985",
  title =        "Algorithms for Closest-Point Problems (Computational Geometry)",
  school =       "Stanford University",
  address =      "Palo Alto, CA",
  note =         "UMI Order Number: AAT 8506171",
  type =         "",
  month =        "",
}


@online{Thornburg01,
  author =       "Harry Thornburg",
  year =         "2001",
  title =        "Introduction to Bayesian Statistics",
  url =          "http://ccrma.stanford.edu/~jos/bayes/bayes.html",
  month =        mar,
  lastaccessed = "March 2, 2005",
}


@online{Ablamowicz07,
  author =       "Rafal Ablamowicz and Bertfried Fauser",
  year =         "2007",
  title =        "CLIFFORD: a Maple 11 Package for Clifford Algebra Computations, version 11",
  url =          "http://math.tntech.edu/rafal/cliff11/index.html",
  lastaccessed = "February 28, 2008",
}


@misc{Poker06,
  author =       "Poker-Edge.Com",
  year =         "2006",
  month =        mar,
  title =        "Stats and Analysis",
  lastaccessed = "June 7, 2006",
  url =          "http://www.poker-edge.com/stats.php",
}

@misc{Obama08,
  author        = "Barack Obama",
  year          = "2008",
  title         = "A more perfect union",
  howpublished  = "Video",
  day           = "5",
  url           = "http://video.google.com/videoplay?docid=6528042696351994555",
  month         = mar,
  lastaccessed  = "March 21, 2008",
  note          =  "",
}

@misc{JoeScientist001,
  author =       "Joseph Scientist",
  year =         "2009",
  title =        "The fountain of youth",
  note =         "Patent No. 12345, Filed July 1st., 2008, Issued Aug. 9th., 2009",
  url =          "",
  howpublished = "",
  month =        aug,
  lastaccessed = "",
}


@Inproceedings{Novak03,
  author =       "Dave Novak",
  title =        "Solder man",
  booktitle =    "ACM SIGGRAPH 2003 Video Review on Animation theater Program: Part I - Vol. 145 (July 27--27, 2003)",
  year =         "2003",
  publisher =    "ACM Press",
  address =      "New York, NY",
  pages =        "4",
  month =        "March 21, 2008",
  doi =          "99.9999/woot07-S422",
  url =          "http://video.google.com/videoplay?docid=6528042696351994555",
  note =         "",
  howpublished = "Video",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  organization = "",
  distinctURL = 1
}

@misc{kondratyuk2023videopoet,
      title={VideoPoet: A Large Language Model for Zero-Shot Video Generation}, 
      author={Dan Kondratyuk and Lijun Yu and Xiuye Gu and José Lezama and Jonathan Huang and Rachel Hornung and Hartwig Adam and Hassan Akbari and Yair Alon and Vighnesh Birodkar and Yong Cheng and Ming-Chang Chiu and Josh Dillon and Irfan Essa and Agrim Gupta and Meera Hahn and Anja Hauth and David Hendon and Alonso Martinez and David Minnen and David Ross and Grant Schindler and Mikhail Sirotenko and Kihyuk Sohn and Krishna Somandepalli and Huisheng Wang and Jimmy Yan and Ming-Hsuan Yang and Xuan Yang and Bryan Seybold and Lu Jiang},
      year={2023},
      eprint={2312.14125},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{Lee05,
  author =       "Newton Lee",
  year =         "2005",
  title =        "Interview with Bill Kinder: January 13, 2005",
  journal =      "Comput. Entertain.",
  eid =          "4",
  volume =       "3",
  number =       "1",
  month =        "Jan.-March",
  doi =          "10.1145/1057270.1057278",
  url =          "http://doi.acm.org/10.1145/1057270.1057278",
  howpublished = "Video",
  note =         "",
}

@article{rous08,
  author =       "Bernard Rous",
  year =         "2008",
  title =        "The Enabling of Digital Libraries",
  journal =      "Digital Libraries",
  volume =       "12",
  number =       "3",
  month =        jul,
  articleno =    "Article~5",
  doi =          "",
  url =          "",
  howpublished = "",
  note =         "To appear",
}

@article{384253,
 author = {Werneck,, Renato and Setubal,, Jo\~{a}o and da Conceic\~{a}o,, Arlindo},
 title = {(old) Finding minimum congestion spanning trees},
 journal = {J. Exp. Algorithmics},
 volume = {5},
 year = {2000},
 issn = {1084-6654},
 pages = {11},
 doi = {http://doi.acm.org/10.1145/351827.384253},
 publisher = {ACM},
 address = {New York, NY, USA},
 }


@article{Werneck:2000:FMC:351827.384253,
 author = {Werneck, Renato and Setubal, Jo\~{a}o and da Conceic\~{a}o, Arlindo},
 title = {(new) Finding minimum congestion spanning trees},
 journal = {J. Exp. Algorithmics},
 volume = 5,
 month = dec,
 year = 2000,
 issn = {1084-6654},
 articleno = 11,
 url = {http://portal.acm.org/citation.cfm?id=351827.384253},
 doi = {10.1145/351827.384253},
 acmid = 384253,
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{1555162,
 author = {Conti, Mauro and Di Pietro, Roberto and Mancini, Luigi V. and Mei, Alessandro},
 title = {(old) Distributed data source verification in wireless sensor networks},
 journal = {Inf. Fusion},
 volume = {10},
 number = {4},
 year = {2009},
 issn = {1566-2535},
 pages = {342--353},
 doi = {http://dx.doi.org/10.1016/j.inffus.2009.01.002},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 }

@article{Conti:2009:DDS:1555009.1555162,
 author = {Conti, Mauro and Di Pietro, Roberto and Mancini, Luigi V. and Mei, Alessandro},
 title = {(new) Distributed data source verification in wireless sensor networks},
 journal = {Inf. Fusion},
 volume = {10},
 number = {4},
 month = oct,
 year = {2009},
 issn = {1566-2535},
 pages = {342--353},
 numpages = {12},
 url = {http://portal.acm.org/citation.cfm?id=1555009.1555162},
 doi = {10.1016/j.inffus.2009.01.002},
 acmid = {1555162},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 keywords = {Clone detection, Distributed protocol, Securing data fusion, Wireless sensor networks},
}

@inproceedings{Li:2008:PUC:1358628.1358946,
 author = {Li, Cheng-Lun and Buyuktur, Ayse G. and Hutchful, David K. and Sant, Natasha B. and Nainwal, Satyendra K.},
 title = {Portalis: using competitive online interactions to support aid initiatives for the homeless},
 booktitle = {CHI '08 extended abstracts on Human factors in computing systems},
 year = {2008},
 isbn = {978-1-60558-012-X},
 location = {Florence, Italy},
 pages = {3873--3878},
 numpages = {6},
 url = {http://portal.acm.org/citation.cfm?id=1358628.1358946},
 doi = {10.1145/1358628.1358946},
 acmid = {1358946},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {cscw, distributed knowledge acquisition, incentive design, online games, recommender systems, reputation systems, user studies, virtual community},
}

@book{Hollis:1999:VBD:519964,
 author = {Hollis, Billy S.},
 title = {Visual Basic 6: Design, Specification, and Objects with Other},
 year = {1999},
 isbn = {0130850845},
 edition = {1st},
 publisher = {Prentice Hall PTR},
 address = {Upper Saddle River, NJ, USA},
 }


@book{Goossens:1999:LWC:553897,
 author = {Goossens, Michel and Rahtz, S. P. and Moore, Ross and Sutor, Robert S.},
 title = {The  Latex Web Companion: Integrating TEX, HTML, and XML},
 year = {1999},
 isbn = {0201433117},
 edition = {1st},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
 }

% need to test genres for errant isbn output

% techreport
@techreport{897367,
 author = {Buss, Jonathan F. and Rosenberg, Arnold L. and Knott, Judson D.},
 title = {Vertex Types in Book-Embeddings},
 year = {1987},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Aumass_cs%3Ancstrl.umassa_cs%2F%2FUM-CS-1987-018},
 publisher = {University of Massachusetts},
 address = {Amherst, MA, USA},
 }

@techreport{Buss:1987:VTB:897367,
 author = {Buss, Jonathan F. and Rosenberg, Arnold L. and Knott, Judson D.},
 title = {Vertex Types in Book-Embeddings},
 year = {1987},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Aumass_cs%3Ancstrl.umassa_cs%2F%2FUM-CS-1987-018},
 publisher = {University of Massachusetts},
 address = {Amherst, MA, USA},
 }

% whole proceedings

@proceedings{Czerwinski:2008:1358628,
 author = {},
 note = {General Chair-Czerwinski, Mary and General Chair-Lund, Arnie and Program Chair-Tan, Desney},
 title = {CHI '08: CHI '08 extended abstracts on Human factors in computing systems},
 year = {2008},
 isbn = {978-1-60558-012-X},
 location = {Florence, Italy},
 order_no = {608085},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

% phdthesis

@phdthesis{Clarkson:1985:ACP:911891,
 author = {Clarkson, Kenneth Lee},
 advisor = {Yao, Andrew C.},
 title = {Algorithms for Closest-Point Problems (Computational Geometry)},
 year = {1985},
 note = {AAT 8506171},
 school = {Stanford University},
 address = {Stanford, CA, USA},
 }
% school is being picked up -- but not publisher (which is OK)
% Also -- the title is NOT being output in italics !!! Arrrrgh! - I fixed it. :-)


%%% compare with 'old'
%%% atsign-Phdthesis{Clarkson85,
%%%  author =       "Kenneth L. Clarkson",
%%%  year =         "1985",
%%%  title =        "Algorithms for Closest-Point Problems (Computational Geometry)",
%%%  school =       "Stanford University",
%%%  address =      "Palo Alto, CA",
%%%  note =         "UMI Order Number: AAT 8506171",
%%%  type =         "",
%%%  month =        "",
%%%}

% A bibliography
@Article{1984:1040142,
 key = {{$\!\!$}},
 journal = {SIGCOMM Comput. Commun. Rev.},
 year = {1984},
 issn = {0146-4833},
 volume = {13-14},
 number = {5-1},
 issue_date = {January/April 1984},
 publisher = {ACM},
 address = {New York, NY, USA},
 }


% grinder
@inproceedings{2004:ITE:1009386.1010128,
 key = {IEEE},
 title = {IEEE TCSC Executive Committee},
 booktitle = {Proceedings of the IEEE International Conference on Web Services},
 series = {ICWS '04},
 year = {2004},
 isbn = {0-7695-2167-3},
 pages = {21--22},
 url = {http://dx.doi.org/10.1109/ICWS.2004.64},
 doi = {http://dx.doi.org/10.1109/ICWS.2004.64},
 acmid = {1010128},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

% div book
@book{Mullender:1993:DS:302430,
 editor = {Mullender, Sape},
 title = {Distributed systems (2nd Ed.)},
 year = {1993},
 isbn = {0-201-62427-3},
 publisher = {ACM Press/Addison-Wesley Publishing Co.},
 address = {New York, NY, USA},
 }

% master thesis (as techreport and thesis)

@techreport{Petrie:1986:NAD:899644,
 author = {Petrie, Charles J.},
 title = {New Algorithms for Dependency-Directed Backtracking (Master's thesis)},
 year = {1986},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Autexas_cs%3AUTEXAS_CS%2F%2FAI86-33},
 publisher = {University of Texas at Austin},
 address = {Austin, TX, USA},
 }

@MASTERSTHESIS{Petrie:1986:NAD:12345,
 author = {Petrie, Charles J.},
 title = {New Algorithms for Dependency-Directed Backtracking (Master's thesis)},
 year = {1986},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Autexas_cs%3AUTEXAS_CS%2F%2FAI86-33},
 school = {University of Texas at Austin},
 address = {Austin, TX, USA},
 }




@BOOK{book-minimal,
   author = "Donald E. Knuth",
   title = "Seminumerical Algorithms",
   publisher = "Addison-Wesley",
   year = "1981",
}

% incollection (has an editor, title, and possibly a booktitle)
@INcollection{KA:2001,
 author = {Kong, Wei-Chang},
 Title = {The implementation of electronic commerce in SMEs in Singapore (as Incoll)},
 booktitle = {E-commerce and cultural values},
 year = {2001},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 url = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}


% with bibfield 'type' before chapter (note no editor)
@INBOOK{KAGM:2001,
 author = {Kong, Wei-Chang},
 type = {Name of Chapter:},
 chapter = {The implementation of electronic commerce in SMEs in Singapore (Inbook-w-chap-w-type)},
 title = {E-commerce and cultural values},
 year = {2001},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 url = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}

%%% Notes! This is because the atsign-INBOOK citation type specifies EITHER
%%% editor or author, but not both. In my experiments with the harvard/dcu
%%% bibtex style (and presumably this applies to other styles too), bibtex
%%% ignores the editor information if author information exists in an
%%% atsign-INBOOK entry. atsign-INCOLLECTION is far more commonly used in my references,
%%% and in the absence of an editor I believe most bibtex styles will just
%%% ommit the editor from the reference - the chapter information will not
%%% end up in the in-text citation as you suggest it should be but at least
%%% there is a place to put the editor if necessary.



% was 'Inbook' -- changed to incollection - (editor is different to author) - need to tell Asad to codify as such.
@incollection{Kong:2002:IEC:887006.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {Chapter 9},
  booktitle =   {E-commerce and cultural values (Incoll-w-text (chap 9) 'title')},
  year =        {2002},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  url =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  type =        "",
  month =       "",
  note =        "",
}

% incol when the chapter is 'text' - due to presence of editor (different to author)
@incollection{Kong:2003:IEC:887006.887011,
 author = {Kong, Wei-Chang},
 title = {The implementation of electronic commerce in SMEs in Singapore (Incoll)},
 booktitle = {E-commerce and cultural values},
 editor = {Thanasankit, Theerasak},
 year = {2003},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 url = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}

% ------ test
%incollection{Kong:2003:IEC:887006.887010,
% author = {Kong, Wei-Chang},
% chapter = {The implementation of electronic commerce in SMEs in Singapore (Incoll-text-in-chap)},
% booktitle = {booktitle E-commerce and cultural values},
% title =   {The title},
% editor = {Thanasankit, Theerasak},
% year = {2003},
% isbn = {1-59140-056-2},
% pages = {51--74},
% numpages = {24},
% url = {http://portal.acm.org/citation.cfm?id=887006.887010},
% acmid = {887010},
% publisher = {IGI Publishing},
% address = {Hershey, PA, USA},
%}


% ---------





% Need inbook with num in chapter

% and inbook with number in chapter
@InBook{Kong:2004:IEC:123456.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {E-commerce and cultural values - (InBook-num-in-chap)},
  chapter =     {9},
  year =        {2004},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  url =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  type =        "",
  month =       "",
  note =        "",
}


% and inbook with text in chapter
@Inbook{Kong:2005:IEC:887006.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {E-commerce and cultural values (Inbook-text-in-chap)},
  chapter =     {The implementation of electronic commerce in SMEs in Singapore},
  year =        {2005},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  url =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  type =        {Chapter:},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  month =       "",
  note =        "",
}


% and inbook with a num and type field
@Inbook{Kong:2006:IEC:887006.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {E-commerce and cultural values (Inbook-num chap)},
  chapter =     {22},
  year =        {2006},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  url =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  type =        {Chapter (in type field)},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  month =       "",
  note =        "",
}


% and incol coz we have a BLANK chapter - due to presence of editor
%atIncollection{Kong:2006:IEC:887006.887011,
%  author =     {Kong, Wei-Chang},
%  editor =     {Theerasak Thanasankit},
%  title =      "The title"
%  booktitle =  {E-commerce and cultural values (Incol-coz-blank-chap)},
%  year =       {2006},
%  address =    {Hershey, PA, USA},
%  publisher =  {IGI Publishing},
%  url =        {http://portal.acm.org/citation.cfm?id=887006.887010},
%  type =       {Type!},
%  chapter =    {},
%  pages =      {51--74},
%  numpages =   {24},
%  acmid =      {887010},
%  isbn =       {1-59140-056-2},
%  number =     "",
%  month =      "",
%  note =       "",
%}

@article{SaeediMEJ10,
            author = {Mehdi Saeedi and Morteza Saheb Zamani and Mehdi Sedighi},
            title = {A library-based synthesis methodology for reversible logic},
            journal = {Microelectron. J.},
            volume = {41},
            number = {4},
            month = apr,
            year = {2010},
            pages = {185--194},
}

@ARTICLE{SaeediJETC10,
            author = {Mehdi Saeedi and Morteza Saheb Zamani and Mehdi Sedighi and Zahra Sasanian},
            title = {Synthesis of Reversible Circuit Using Cycle-Based Approach},
            journal = {J. Emerg. Technol. Comput. Syst.},
            volume = {6},
            number = {4},
            month = dec,
            year = {2010}
            }

% Asad's new version
@article{Kirschmer:2010:AEI:1958016.1958018,
 author = {Kirschmer, Markus and Voight, John},
 title = {Algorithmic Enumeration of Ideal Classes for Quaternion Orders},
 journal = {SIAM J. Comput.},
 issue_date = {January 2010},
 volume = {39},
 number = {5},
 month = jan,
 year = {2010},
 issn = {0097-5397},
 pages = {1714--1747},
 numpages = {34},
 url = {http://dx.doi.org/10.1137/080734467},
 doi = {https://doi.org/10.1137/080734467},
 acmid = {1958018},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
 keywords = {ideal classes, maximal orders, number theory, quaternion algebras},
}


% incol due to presence of booktitle
@incollection{Hoare:1972:CIN:1243380.1243382,
 author = {Hoare, C. A. R.},
 title = {Chapter II: Notes on data structuring},
 booktitle = {Structured programming (incoll)},
 editor = {Dahl, O. J. and Dijkstra, E. W. and Hoare, C. A. R.},
 year = {1972},
 isbn = {0-12-200550-3},
 pages = {83--174},
 numpages = {92},
 url = {http://portal.acm.org/citation.cfm?id=1243380.1243382},
 acmid = {1243382},
 publisher = {Academic Press Ltd.},
 address = {London, UK, UK},
}

% incol due to presence of booktitle
@incollection{Lee:1978:TQA:800025.1198348,
 author = {Lee, Jan},
 title = {Transcript of question and answer session},
 booktitle = {History of programming languages I (incoll)},
 editor = {Wexelblat, Richard L.},
 year = {1981},
 isbn = {0-12-745040-8},
 pages = {68--71},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/800025.1198348},
 doi = {http://doi.acm.org/10.1145/800025.1198348},
 acmid = {1198348},
 publisher = {ACM},
 address = {New York, NY, USA},
}
% incol due to booktitle
@incollection{Dijkstra:1979:GSC:1241515.1241518,
 author = {Dijkstra, E.},
 title = {Go to statement considered harmful},
 booktitle = {Classics in software engineering (incoll)},
 year = {1979},
 isbn = {0-917072-14-6},
 pages = {27--33},
 numpages = {7},
 url = {http://portal.acm.org/citation.cfm?id=1241515.1241518},
 acmid = {1241518},
 publisher = {Yourdon Press},
 address = {Upper Saddle River, NJ, USA},
}

@article{zhu2024beyond,
  title   = {Beyond Text: Frozen Large Language Models in Visual Signal Comprehension},
  author  = {Lei Zhu and Fangyun Wei and Yanye Lu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2403.07874}
}

% incol due to booktitle
@incollection{Wenzel:1992:TVA:146022.146089,
 author = {Wenzel, Elizabeth M.},
 title = {Three-dimensional virtual acoustic displays},
 booktitle = {Multimedia interface design (incoll)},
 year = {1992},
 isbn = {0-201-54981-6},
 pages = {257--288},
 numpages = {32},
 url = {http://portal.acm.org/citation.cfm?id=146022.146089},
 doi = {10.1145/146022.146089},
 acmid = {146089},
 publisher = {ACM},
 address = {New York, NY, USA},
}

% incol due to booktitle
@incollection{Mumford:1987:MES:54905.54911,
 author = {Mumford, E.},
 title = {Managerial expert systems and organizational change: some critical research issues},
 booktitle = {Critical issues in information systems research (incoll)},
 year = {1987},
 isbn = {0-471-91281-6},
 pages = {135--155},
 numpages = {21},
 url = {http://portal.acm.org/citation.cfm?id=54905.54911},
 acmid = {54911},
 publisher = {John Wiley \& Sons, Inc.},
 address = {New York, NY, USA},
}

@book{McCracken:1990:SSC:575315,
 author = {McCracken, Daniel D. and Golden, Donald G.},
 title = {Simplified Structured COBOL with Microsoft/MicroFocus COBOL},
 year = {1990},
 isbn = {0471514071},
 publisher = {John Wiley \& Sons, Inc.},
 address = {New York, NY, USA},
}

% Let's include Boris / BBeeton entries  (multi-volume works)

@book {MR781537,
    AUTHOR = {H{\"o}rmander, Lars},
     TITLE = {The analysis of linear partial differential operators. {III}},
    SERIES = {Grundlehren der Mathematischen Wissenschaften [Fundamental
              Principles of Mathematical Sciences]},
    VOLUME = {275},
      NOTE = {Pseudodifferential operators},
PUBLISHER = {Springer-Verlag},
   ADDRESS = {Berlin, Germany},
      YEAR = {1985},
     PAGES = {viii+525},
      ISBN = {3-540-13828-5},
   MRCLASS = {35-02 (35Sxx 47G05 58G15)},
  MRNUMBER = {781536 (87d:35002a)},
MRREVIEWER = {Min You Qi},
}

@book {MR781536,
    AUTHOR = {H{\"o}rmander, Lars},
     TITLE = {The analysis of linear partial differential operators. {IV}},
    SERIES = {Grundlehren der Mathematischen Wissenschaften [Fundamental
              Principles of Mathematical Sciences]},
    VOLUME = {275},
      NOTE = {Fourier integral operators},
PUBLISHER = {Springer-Verlag},
   ADDRESS = {Berlin, Germany},
      YEAR = {1985},
     PAGES = {vii+352},
      ISBN = {3-540-13829-3},
   MRCLASS = {35-02 (35Sxx 47G05 58G15)},
  MRNUMBER = {781537 (87d:35002b)},
MRREVIEWER = {Min You Qi},
}

%%%%%%%%%%%%%%%%%%%%%% Start of Aptara sample bib entries

% acmsmall-sam.bib
@InProceedings{Adya-01,
  author        = {A. Adya and P. Bahl and J. Padhye and A.Wolman and L. Zhou},
  title         = {A multi-radio unification protocol for {IEEE} 802.11 wireless networks},
  booktitle     = {Proceedings of the IEEE 1st International Conference on Broadnets Networks (BroadNets'04)},
  publisher     = "IEEE",
  address       = "Los Alamitos, CA",
  year          = {2004},
  pages         = "210--217"
}

@article{Akyildiz-01,
  author        = {I. F. Akyildiz and W. Su and Y. Sankarasubramaniam and E. Cayirci},
  title         = {Wireless Sensor Networks: A Survey},
  journal       = {Comm. ACM},
  volume        = 38,
  number        = "4",
  year          = {2002},
  pages         = "393--422"
}

@article{Akyildiz-02,
  author        = {I. F. Akyildiz and T. Melodia and K. R. Chowdhury},
  title         = {A Survey on Wireless Multimedia Sensor Networks},
  journal       = {Computer Netw.},
  volume        = 51,
  number        = "4",
  year          = {2007},
  pages         = "921--960"
}

@InProceedings{Bahl-02,
  author        = {P. Bahl and R. Chancre and J. Dungeon},
  title         = {{SSCH}: Slotted Seeded Channel Hopping for Capacity Improvement in {IEEE} 802.11 Ad-Hoc Wireless Networks},
  booktitle     = {Proceeding of the 10th International Conference on Mobile Computing and Networking (MobiCom'04)},
  publisher     = "ACM",
  address       = "New York, NY",
  year          = {2004},
  pages         = "112--117"
}

@misc{CROSSBOW,
  key       = {CROSSBOW},
  title     = {{XBOW} Sensor Motes Specifications},
  note      = {http://www.xbow.com},
  year      = 2008
}

@article{Culler-01,
  author        = {D. Culler and D. Estrin and M. Srivastava},
  title         = {Overview of Sensor Networks},
  journal       = {IEEE Comput.},
  volume        = 37,
  number        = "8 (Special Issue on Sensor Networks)",
  publisher     = "IEEE",
  address       = "Los Alamitos, CA",
  year          = {2004},
  pages         = "41--49"
}

@misc{Harvard-01,
    key         = {Harvard CodeBlue},
    title       = {{CodeBlue}: Sensor Networks for Medical Care},
    note        = {http://www.eecs.harvard.edu/mdw/ proj/codeblue/},
    year        = 2008
}

@InProceedings{Natarajan-01,
    author      = {A. Natarajan and M. Motani and B. de Silva and K. Yap and K. C. Chua},
    title       = {Investigating Network Architectures for Body Sensor Networks},
    booktitle   = {Network Architectures},
    editor      = {G. Whitcomb and P. Neece},
    publisher   = "Keleuven Press",
    address     = "Dayton, OH",
    year        = {2007},
    pages       = "322--328",
    eprint      = "960935712",
    primaryclass = "cs",
}

@techreport{Tzamaloukas-01,
  author        = {A. Tzamaloukas and J. J. Garcia-Luna-Aceves},
  title         = {Channel-Hopping Multiple Access},
  number =        {I-CA2301},
  institution =   {Department of Computer Science, University of California},
  address =       {Berkeley, CA},
  year          = {2000}
}

@BOOK{Zhou-06,
  author        = {G. Zhou and J. Lu and C.-Y. Wan and M. D. Yarvis and J. A. Stankovic},
  title         = {Body Sensor Networks},
  publisher     = "MIT Press",
  address       = "Cambridge, MA",
  year          = {2008}
}

@mastersthesis{ko94,
author = "Jacob Kornerup",
title = "Mapping Powerlists onto Hypercubes",
school = "The University of Texas at Austin",
note = "(In preparation)",
year = "1994"}
%month = "dec",}

@PhdThesis{gerndt:89,
  author =       "Michael Gerndt",
  title =        "Automatic Parallelization for Distributed-Memory
                  Multiprocessing Systems",
  school =       "University of Bonn",
  year =         1989,
  address =      "Bonn, Germany",
  month =        dec
}

@article{6:1:1,
author = "J. E. {Archer, Jr.} and R. Conway and F. B. Schneider",
title = "User recovery and reversal in interactive systems",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "6",
number = "1",
month = jan,
year = 1984,
pages = "1--19"}

@article{7:1:137,
author = "D. D. Dunlop and V. R. Basili",
title = "Generalizing specifications for uniformly implemented loops",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "7",
number = "1",
month = jan,
year = 1985,
pages = "137--158"}

@article{7:2:183,
author = "J. Heering and P. Klint",
title = "Towards monolingual programming environments",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "7",
number = "2",
month = apr,
year = 1985,
pages = "183--213"}

@book{knuth:texbook,
author = "Donald E. Knuth",
title = "The {\TeX{}book}",
publisher = "Addison-Wesley",
address = "Reading, MA.",
year = 1984}

@article{6:3:380,
author = "E. Korach and D.  Rotem and N. Santoro",
title = "Distributed algorithms for finding centers and medians in networks",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "6",
number = "3",
month = jul,
year = 1984,
pages = "380--401"}

@book{Lamport:LaTeX,
author = "Leslie Lamport",
title = "\it {\LaTeX}: A Document Preparation System",
publisher = "Addison-Wesley",
address = "Reading, MA.",
year = 1986}

@article{7:3:359,
author = "F. Nielson",
title = "Program transformations in a denotational setting",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "7",
number = "3",
month = jul,
year = 1985,
pages = "359--379"}

%testing
@BOOK{test,
   author = "Donald E. Knuth",
   title = "Seminumerical Algorithms",
   volume = 2,
   series = "The Art of Computer Programming",
   publisher = "Addison-Wesley",
   address = "Reading, MA",
   edition = "2nd",
   month = "10~" # jan,
   year = "1981",
}

@inproceedings{reid:scribe,
author = "Brian K. Reid",
title = "A high-level approach to computer document formatting",
booktitle = "Proceedings of the 7th Annual Symposium on Principles of
  Programming Languages",
month = jan,
year = 1980,
publisher = "ACM",
address = "New York",
pages = "24--31"}

@article{Zhou:2010:MMS:1721695.1721705,
 author = {Zhou, Gang and Wu, Yafeng and Yan, Ting and He, Tian and Huang, Chengdu and Stankovic, John A. and Abdelzaher, Tarek F.},
 title = {A multifrequency MAC specially designed for wireless sensor network applications},
 journal = {ACM Trans. Embed. Comput. Syst.},
 issue_date = {March 2010},
 volume = 9,
 number = 4,
 month = {April},
 year = 2010,
 issn = {1539-9087},
 pages = {39:1--39:41},
 articleno = 39,
 numpages = 41,
 url = {http://doi.acm.org/10.1145/1721695.1721705},
 doi = {10.1145/1721695.1721705},
 acmid = 1721705,
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Wireless sensor networks, media access control, multi-channel, radio interference, time synchronization},
}


@online{TUGInstmem,
  key =          {TUG},
  year  =        2017,
  title =        "Institutional members of the {\TeX} Users Group",
  url =          "http://wwtug.org/instmem.html",
  lastaccessed = "May 27, 2017",
}

@online{CTANacmart,
  author =    {Boris Veytsman},
  title =  {acmart---{C}lass for typesetting publications of {ACM}},
  year = 2017,
  url =    {http://www.ctan.org/pkg/acmart},
  lastaccessed = {May 27, 2017}
  }

@ARTICLE{bowman:reasoning,
    author = {Bowman, Mic and Debray, Saumya K. and Peterson, Larry L.},
    title = {Reasoning About Naming Systems},
    journal = {ACM Trans. Program. Lang. Syst.},
    volume = {15},
    number = {5},
    pages = {795-825},
    month = {November},
    year = {1993},
    doi = {10.1145/161468.161471},
}

@ARTICLE{braams:babel,
    author = {Braams, Johannes},
    title = {Babel, a Multilingual Style-Option System for Use with LaTeX's Standard Document Styles},
    journal = {TUGboat},
    volume = {12},
    number = {2},
    pages = {291-301},
    month = {June},
    year = {1991},
}

@INPROCEEDINGS{clark:pct,
  AUTHOR = "Malcolm Clark",
  TITLE = "Post Congress Tristesse",
  BOOKTITLE = "TeX90 Conference Proceedings",
  PAGES = "84-89",
  ORGANIZATION = "TeX Users Group",
  MONTH = "March",
  YEAR = {1991}
}

@ARTICLE{herlihy:methodology,
    author = {Herlihy, Maurice},
    title = {A Methodology for Implementing Highly Concurrent Data Objects},
    journal = {ACM Trans. Program. Lang. Syst.},
    volume = {15},
    number = {5},
    pages = {745-770},
    month = {November},
    year = {1993},
    doi = {10.1145/161468.161469},
}

@BOOK{salas:calculus,
  AUTHOR = "S.L. Salas and Einar Hille",
  TITLE = "Calculus: One and Several Variable",
  PUBLISHER = "John Wiley and Sons",
  ADDRESS = "New York",
  YEAR = "1978"
}

@MANUAL{Fear05,
  title =        {Publication quality tables in {\LaTeX}},
  author =       {Simon Fear},
  month =        {April},
  year =         2005,
  note =         {\url{http://www.ctan.org/pkg/booktabs}}
}

@Manual{Amsthm15,
  title =        {Using the amsthm Package},
  organization = {American Mathematical Society},
  month =        {April},
  year =         2015,
  note =         {\url{http://www.ctan.org/pkg/amsthm}}
}

@ArtifactSoftware{R,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2019},
    url = {https://www.R-project.org/},
}

@ArtifactDataset{UMassCitations,
 author    =  {Sam Anzaroot and Andrew McCallum},
 title     =  {{UMass} Citation Field Extraction Dataset},
 year      = 2013,
 url       =
    {http://www.iesl.cs.umass.edu/data/data-umasscitationfield},
 lastaccessed = {May 27, 2019}
}

@Eprint{Bornmann2019,
       author = {Bornmann, Lutz and Wray, K. Brad and Haunschild,
                  Robin},
        title = {Citation concept analysis {(CCA)}---A new form of
                  citation analysis revealing the usefulness of
                  concepts for other researchers illustrated by two
                  exemplary case studies including classic books by
                  {Thomas S.~Kuhn} and {Karl R.~Popper}},
     keywords = {Computer Science - Digital Libraries},
         year = 2019,
        month = "May",
          eid = {arXiv:1905.12410},
archivePrefix = {arXiv},
       eprint = {1905.12410},
 primaryClass = {cs.DL},
}

@Eprint{AnzarootPBM14,
  author    = {Sam Anzaroot and
               Alexandre Passos and
               David Belanger and
               Andrew McCallum},
  title     = {Learning Soft Linear Constraints with Application to
                  Citation Field Extraction},
  year      = {2014},
  archivePrefix = {arXiv},
  eprint    = {1403.1349},
}

@inproceedings{Hagerup1993,
title        = {Maintaining Discrete Probability Distributions Optimally},
author       = {Hagerup, Torben and Mehlhorn, Kurt and Munro, J. Ian},
booktitle    = {Proceedings of the 20th International Colloquium on Automata, Languages and Programming},
series       = {Lecture Notes in Computer Science},
volume       = {700},
pages        = {253--264},
year         = {1993},
publisher    = {Springer-Verlag},
address      = {Berlin},
}
@article{scao2022bloom,
 author = {Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
 journal = {ArXiv preprint},
 title = {Bloom: A 176b-parameter open-access multilingual language model},
 volume = {abs/2211.05100},
 year = {2022}
}

@inproceedings{bertscore,
  title={BERTScore: Evaluating Text Generation with BERT},
  author={Tianyi Zhang* and Varsha Kishore* and Felix Wu* and Kilian Q. Weinberger and Yoav Artzi},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://openreview.net/forum?id=SkeHuCVFDr}
}

@misc{liu2023llava15,
      title={Improved Baselines with Visual Instruction Tuning}, 
      author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
      publisher={arXiv:2310.03744},
      year={2023},
}
@article{fu2023mme,
  title={MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models},
  author={Fu, Chaoyou and Chen, Peixian and Shen, Yunhang and Qin, Yulei and Zhang, Mengdan and Lin, Xu and Qiu, Zhenyu and Lin, Wei and Yang, Jinrui and Zheng, Xiawu and others},
  journal={arXiv preprint arXiv:2306.13394},
  year={2023}
}
@article{yang2023dawn,
  title={The dawn of lmms: Preliminary explorations with gpt-4v (ision)},
  author={Yang, Zhengyuan and Li, Linjie and Lin, Kevin and Wang, Jianfeng and Lin, Chung-Ching and Liu, Zicheng and Wang, Lijuan},
  journal={arXiv preprint arXiv:2309.17421},
  volume={9},
  year={2023}
}

@article{zhu2023multilingual,
 author = {Zhu, Wenhao and Liu, Hongyi and Dong, Qingxiu and Xu, Jingjing and Kong, Lingpeng and Chen, Jiajun and Li, Lei and Huang, Shujian},
 journal = {ArXiv preprint},
 title = {Multilingual machine translation with large language models: Empirical results and analysis},
 volume = {abs/2304.04675},
 year = {2023}
}

@article{chen2023visual,
 author = {Chen, Delong and Liu, Jianfeng and Dai, Wenliang and Wang, Baoyuan},
 journal = {ArXiv preprint},
 title = {Visual Instruction Tuning with Polite Flamingo},
 volume = {abs/2307.01003},
 year = {2023}
}

@inproceedings{thapliyal2022crossmodal,
 author = {Thapliyal, Ashish V.  and
Pont Tuset, Jordi  and
Chen, Xi  and
Soricut, Radu},
 booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
 pages = {715--729},
 title = {Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset},
 year = {2022}
}

@inproceedings{reimers-gurevych-2020-making,
 author = {Reimers, Nils  and
Gurevych, Iryna},
 booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
 pages = {4512--4525},
 title = {Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation},
 year = {2020}
}

@inproceedings{fm-iqa,
 author = {Haoyuan Gao and
Junhua Mao and
Jie Zhou and
Zhiheng Huang and
Lei Wang and
Wei Xu},
 booktitle = {Advances in Neural Information Processing Systems 28: Annual Conference
on Neural Information Processing Systems 2015, December 7-12, 2015,
Montreal, Quebec, Canada},
 editor = {Corinna Cortes and
Neil D. Lawrence and
Daniel D. Lee and
Masashi Sugiyama and
Roman Garnett},
 pages = {2296--2304},
 title = {Are You Talking to a Machine? Dataset and Methods for Multilingual
Image Question},
 year = {2015}
}

@article{DBLP:journals/tacl/GoyalGCCWJKRGF22,
 author = {Goyal, Naman  and
Gao, Cynthia  and
Chaudhary, Vishrav  and
Chen, Peng-Jen  and
Wenzek, Guillaume  and
Ju, Da  and
Krishnan, Sanjana  and
Ranzato, Marc{'}Aurelio  and
Guzm{\'a}n, Francisco  and
Fan, Angela},
 journal = {Transactions of the Association for Computational Linguistics},
 pages = {522--538},
 title = {The {F}lores-101 Evaluation Benchmark for Low-Resource and Multilingual Machine Translation},
 volume = {10},
 year = {2022}
}

@article{shtedritski2023does,
 author = {Shtedritski, Aleksandar and Rupprecht, Christian and Vedaldi, Andrea},
 journal = {ArXiv preprint},
 title = {What does CLIP know about a red circle? Visual prompt engineering for VLMs},
 volume = {abs/2304.06712},
 year = {2023}
}

@inproceedings{radford2021clip,
 author = {Alec Radford and
Jong Wook Kim and
Chris Hallacy and
Aditya Ramesh and
Gabriel Goh and
Sandhini Agarwal and
Girish Sastry and
Amanda Askell and
Pamela Mishkin and
Jack Clark and
Gretchen Krueger and
Ilya Sutskever},
 booktitle = {Proceedings of the 38th International Conference on Machine Learning,
{ICML} 2021, 18-24 July 2021, Virtual Event},
 editor = {Marina Meila and
Tong Zhang},
 pages = {8748--8763},
 series = {Proceedings of Machine Learning Research},
 title = {Learning Transferable Visual Models From Natural Language Supervision},
 volume = {139},
 year = {2021}
}

@inproceedings{gpt3,
 author = {Tom B. Brown and
Benjamin Mann and
Nick Ryder and
Melanie Subbiah and
Jared Kaplan and
Prafulla Dhariwal and
Arvind Neelakantan and
Pranav Shyam and
Girish Sastry and
Amanda Askell and
Sandhini Agarwal and
Ariel Herbert{-}Voss and
Gretchen Krueger and
Tom Henighan and
Rewon Child and
Aditya Ramesh and
Daniel M. Ziegler and
Jeffrey Wu and
Clemens Winter and
Christopher Hesse and
Mark Chen and
Eric Sigler and
Mateusz Litwin and
Scott Gray and
Benjamin Chess and
Jack Clark and
Christopher Berner and
Sam McCandlish and
Alec Radford and
Ilya Sutskever and
Dario Amodei},
 booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
on Neural Information Processing Systems 2020, NeurIPS 2020, December
6-12, 2020, virtual},
 editor = {Hugo Larochelle and
Marc'Aurelio Ranzato and
Raia Hadsell and
Maria{-}Florina Balcan and
Hsuan{-}Tien Lin},
 title = {Language Models are Few-Shot Learners},
 year = {2020}
}

@article{longpre2023flan,
 author = {Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and others},
 journal = {ArXiv preprint},
 title = {The flan collection: Designing data and methods for effective instruction tuning},
 volume = {abs/2301.13688},
 year = {2023}
}

@article{yao2022mocheg,
 author = {Yao, Barry Menglong and Shah, Aditya and Sun, Lichao and Cho, Jin-Hee and Huang, Lifu},
 journal = {ArXiv preprint},
 title = {End-to-End Multimodal Fact-Checking and Explanation Generation: A Challenging Dataset and Models},
 volume = {abs/2205.12487},
 year = {2022}
}

@inproceedings{mishra2022naturalinstruction,
 author = {Mishra, Swaroop  and
Khashabi, Daniel  and
Baral, Chitta  and
Hajishirzi, Hannaneh},
 booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
 pages = {3470--3487},
 title = {Cross-Task Generalization via Natural Language Crowdsourcing Instructions},
 year = {2022}
}

@article{gilardi2023chatgpt,
 author = {Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Ma{\"e}l},
 journal = {ArXiv preprint},
 title = {Chatgpt outperforms crowd-workers for text-annotation tasks},
 volume = {abs/2303.15056},
 year = {2023}
}

@article{chatgpt,
 author = {OpenAI},
 title = {Introducing ChatGPT},
 year = {2022}
}

@article{touvron2023llama2,
 author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
 journal = {ArXiv preprint},
 title = {Llama 2: Open foundation and fine-tuned chat models},
 volume = {abs/2307.09288},
 year = {2023}
}

@article{gpt4v,
 author = {OpenAI},
 title = {GPT-4V(ision) System Card},
 year = {2023}
}

@article{costa2022nllb,
 author = {Costa-juss{\`a}, Marta R and Cross, James and {\c{C}}elebi, Onur and Elbayad, Maha and Heafield, Kenneth and Heffernan, Kevin and Kalbassi, Elahe and Lam, Janice and Licht, Daniel and Maillard, Jean and others},
 journal = {ArXiv preprint},
 title = {No language left behind: Scaling human-centered machine translation},
 volume = {abs/2207.04672},
 year = {2022}
}

@inproceedings{lin-2004-rouge,
 author = {Lin, Chin-Yew},
 booktitle = {Text Summarization Branches Out},
 pages = {74--81},
 title = {{ROUGE}: A Package for Automatic Evaluation of Summaries},
 year = {2004}
}

@inproceedings{goyal2017something,
 author = {Raghav Goyal and
Samira Ebrahimi Kahou and
Vincent Michalski and
Joanna Materzynska and
Susanne Westphal and
Heuna Kim and
Valentin Haenel and
Ingo Fr{\"{u}}nd and
Peter Yianilos and
Moritz Mueller{-}Freitag and
Florian Hoppe and
Christian Thurau and
Ingo Bax and
Roland Memisevic},
 booktitle = {{IEEE} International Conference on Computer Vision, {ICCV} 2017, Venice,
Italy, October 22-29, 2017},
 pages = {5843--5851},
 title = {The "Something Something" Video Database for Learning and Evaluating
Visual Common Sense},
 year = {2017}
}

@inproceedings{yu2019activitynet,
 author = {Zhou Yu and
Dejing Xu and
Jun Yu and
Ting Yu and
Zhou Zhao and
Yueting Zhuang and
Dacheng Tao},
 booktitle = {The Thirty-Third {AAAI} Conference on Artificial Intelligence, {AAAI}
2019, The Thirty-First Innovative Applications of Artificial Intelligence
Conference, {IAAI} 2019, The Ninth {AAAI} Symposium on Educational
Advances in Artificial Intelligence, {EAAI} 2019, Honolulu, Hawaii,
USA, January 27 - February 1, 2019},
 pages = {9127--9134},
 title = {ActivityNet-QA: {A} Dataset for Understanding Complex Web Videos via
Question Answering},
 year = {2019}
}

@inproceedings{yang2021iVQA,
 author = {Antoine Yang and
Antoine Miech and
Josef Sivic and
Ivan Laptev and
Cordelia Schmid},
 booktitle = {2021 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
2021, Montreal, QC, Canada, October 10-17, 2021},
 pages = {1666--1677},
 title = {Just Ask: Learning to Answer Questions from Millions of Narrated Videos},
 year = {2021}
}

@inproceedings{flickr8kcn,
 author = {Li, Xirong and Lan, Weiyu and Dong, Jianfeng and Liu, Hailong},
 booktitle = {Proceedings of the 2016 ACM on international conference on multimedia retrieval},
 pages = {271--275},
 title = {Adding chinese captions to images},
 year = {2016}
}

@article{li2019cococn,
 author = {Li, Xirong and Xu, Chaoxi and Wang, Xiaoxu and Lan, Weiyu and Jia, Zhengxiong and Yang, Gang and Xu, Jieping},
 journal = {IEEE Transactions on Multimedia},
 number = {9},
 pages = {2347--2360},
 title = {COCO-CN for cross-lingual image tagging, captioning, and retrieval},
 volume = {21},
 year = {2019}
}

@inproceedings{hu2021lora,
 author = {Edward J. Hu and
Yelong Shen and
Phillip Wallis and
Zeyuan Allen{-}Zhu and
Yuanzhi Li and
Shean Wang and
Lu Wang and
Weizhu Chen},
 booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
2022, Virtual Event, April 25-29, 2022},
 title = {LoRA: Low-Rank Adaptation of Large Language Models},
 year = {2022}
}

@article{goyal2022flores,
 author = {Goyal, Naman  and
Gao, Cynthia  and
Chaudhary, Vishrav  and
Chen, Peng-Jen  and
Wenzek, Guillaume  and
Ju, Da  and
Krishnan, Sanjana  and
Ranzato, Marc{'}Aurelio  and
Guzm{\'a}n, Francisco  and
Fan, Angela},
 journal = {Transactions of the Association for Computational Linguistics},
 pages = {522--538},
 title = {The {F}lores-101 Evaluation Benchmark for Low-Resource and Multilingual Machine Translation},
 volume = {10},
 year = {2022}
}

@inproceedings{loshchilov2018decoupled,
 author = {Ilya Loshchilov and
Frank Hutter},
 booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
New Orleans, LA, USA, May 6-9, 2019},
 title = {Decoupled Weight Decay Regularization},
 year = {2019}
}

@article{it-with-gpt4,
 author = {Baolin Peng and Chunyuan Li and Pengcheng He and Michel Galley and Jianfeng Gao},
 journal = {ArXiv preprint},
 title = {Instruction Tuning with GPT-4},
 volume = {abs/2304.03277},
 year = {2023}
}

@article{laion400m,
 author = {Christoph Schuhmann and Richard Vencu and Romain Beaumont and Robert Kaczmarczyk and Clayton Mullis and Aarush Katta and Theo Coombes and Jenia Jitsev and Aran Komatsuzaki},
 journal = {ArXiv preprint},
 title = {LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs},
 volume = {abs/2111.02114},
 year = {2021}
}

@misc{alpaca,
 author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
 howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
 journal = {GitHub repository},
 title = {Stanford Alpaca: An Instruction-following LLaMA model},
 year = {2023}
}

@misc{laurencon2023obelics,
 archiveprefix = {arXiv},
 author = {Hugo Laurençon and Lucile Saulnier and Léo Tronchon and Stas Bekman and Amanpreet Singh and Anton Lozhkov and Thomas Wang and Siddharth Karamcheti and Alexander M. Rush and Douwe Kiela and Matthieu Cord and Victor Sanh},
 eprint = {2306.16527},
 primaryclass = {cs.IR},
 title = {OBELICS: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents},
 year = {2023}
}

@article{anil2023palm2,
 author = {Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
 journal = {ArXiv preprint},
 title = {Palm 2 technical report},
 volume = {abs/2305.10403},
 year = {2023}
}

@article{chowdhery2022palm,
 author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
 journal = {ArXiv preprint},
 title = {Palm: Scaling language modeling with pathways},
 volume = {abs/2204.02311},
 year = {2022}
}

@article{fengshenbang,
 author = {Jiaxing Zhang and Ruyi Gan and Junjie Wang and Yuxiang Zhang and Lin Zhang and Ping Yang and Xinyu Gao and Ziwei Wu and Xiaoqun Dong and Junqing He and Jianheng Zhuo and Qi Yang and Yongfeng Huang and Xiayu Li and Yanghan Wu and Junyu Lu and Xinyu Zhu and Weifeng Chen and Ting Han and Kunhao Pan and Rui Wang and Hao Wang and Xiaojun Wu and Zhongshen Zeng and Chongpei Chen},
 journal = {ArXiv preprint},
 title = {Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence},
 volume = {abs/2209.02970},
 year = {2022}
}

@inproceedings{driess2023palme,
 author = {Driess, Danny and Xia, Fei and Sajjadi, Mehdi S. M. and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and Huang, Wenlong and Chebotar, Yevgen and Sermanet, Pierre and Duckworth, Daniel and Levine, Sergey and Vanhoucke, Vincent and Hausman, Karol and Toussaint, Marc and Greff, Klaus and Zeng, Andy and Mordatch, Igor and Florence, Pete},
 journal = {ArXiv preprint},
 title = {PaLM-E: An Embodied Multimodal Language Model},
 volume = {abs/2303.03378},
 year = {2023}
}

@article{Chen2023PaLIX,
 author = {Xi Chen and Josip Djolonga and Piotr Padlewski and Basil Mustafa and Soravit Changpinyo and Jialin Wu and Carlos Riquelme Ruiz and Sebastian Goodman and Xiao Wang and Yi Tay and Siamak Shakeri and Mostafa Dehghani and Daniel M. Salz and Mario Lucic and Michael Tschannen and Arsha Nagrani and Hexiang Hu and Mandar Joshi and Bo Pang and Ceslee Montgomery and Paulina Pietrzyk and Marvin Ritter and A. J. Piergiovanni and Matthias Minderer and Filip Pavetic and Austin Waters and Gang Li and Ibrahim M. Alabdulmohsin and Lucas Beyer and Julien Amelot and Kenton Lee and Andreas Steiner and Yang Li and Daniel Keysers and Anurag Arnab and Yuanzhong Xu and Keran Rong and Alexander Kolesnikov and Mojtaba Seyedhosseini and Anelia Angelova and Xiaohua Zhai and Neil Houlsby and Radu Soricut},
 journal = {ArXiv preprint},
 title = {PaLI-X: On Scaling up a Multilingual Vision and Language Model},
 volume = {abs/2305.18565},
 year = {2023}
}
@inproceedings{pali,
  author    = {Xi Chen and Xiao Wang and Soravit Changpinyo and A. J. Piergiovanni and Piotr Padlewski and Daniel Salz and Sebastian Goodman and Adam Grycner and Basil Mustafa and Lucas Beyer and Alexander Kolesnikov and Joan Puigcerver and Nan Ding and Keran Rong and Hassan Akbari and Gaurav Mishra and Linting Xue and Ashish V. Thapliyal and James Bradbury and Weicheng Kuo},
  title     = {PaLI: {A} Jointly-Scaled Multilingual Language-Image Model},
  booktitle = {The Eleventh International Conference on Learning Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher = {OpenReview.net},
  year      = {2023},
  url       = {https://openreview.net/pdf?id=mWVoBz4W0u},
  timestamp = {Fri, 08 Dec 2023 09:08:11 +0100},
  biburl    = {https://dblp.org/rec/conf/iclr/Chen0CPPSGGMB0P23.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{ye2023mplugowl,
 archiveprefix = {arXiv},
 author = {Qinghao Ye and Haiyang Xu and Guohai Xu and Jiabo Ye and Ming Yan and Yiyang Zhou and Junyang Wang and Anwen Hu and Pengcheng Shi and Yaya Shi and Chaoya Jiang and Chenliang Li and Yuanhong Xu and Hehong Chen and Junfeng Tian and Qian Qi and Ji Zhang and Fei Huang},
 eprint = {2304.14178},
 primaryclass = {cs.CL},
 title = {mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality},
 year = {2023}
}

@article{QwenVL,
 author = {Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
 journal = {ArXiv preprint},
 title = {Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities},
 volume = {abs/2308.12966},
 year = {2023}
}

@article{dai2023instructblip,
 author = {Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale and Hoi, Steven},
 journal = {ArXiv preprint},
 title = {InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning},
 volume = {abs/2305.06500},
 year = {2023}
}

@article{touvron2023llama,
 author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
 journal = {ArXiv preprint},
 title = {Llama: Open and efficient foundation language models},
 volume = {abs/2302.13971},
 year = {2023}
}

@misc{openai2023gpt4,
 archiveprefix = {arXiv},
 author = {OpenAI},
 eprint = {2303.08774},
 primaryclass = {cs.CL},
 title = {GPT-4 Technical Report},
 year = {2023}
}

@inproceedings{lu2022scienceqa,
 author = {Lu, Pan and Mishra, Swaroop and Xia, Tony and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Ashwin Kalyan},
 booktitle = {The 36th Conference on Neural Information Processing Systems (NeurIPS)},
 title = {Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering},
 year = {2022}
}

@inproceedings{johnson2017clevr,
 author = {Justin Johnson and
Bharath Hariharan and
Laurens van der Maaten and
Li Fei{-}Fei and
C. Lawrence Zitnick and
Ross B. Girshick},
 booktitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition,
{CVPR} 2017, Honolulu, HI, USA, July 21-26, 2017},
 pages = {1988--1997},
 title = {{CLEVR:} {A} Diagnostic Dataset for Compositional Language and Elementary
Visual Reasoning},
 year = {2017}
}

@inproceedings{thrush2022winoground,
 author = {Thrush, Tristan and Jiang, Ryan and Bartolo, Max and Singh, Amanpreet and Williams, Adina and Kiela, Douwe and Ross, Candace},
 booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
 pages = {5238--5248},
 title = {Winoground: Probing vision and language models for visio-linguistic compositionality},
 year = {2022}
}

@inproceedings{wang2022superNI,
 author = {Wang, Yizhong  and
Mishra, Swaroop  and
Alipoormolabashi, Pegah  and
Kordi, Yeganeh  and
Mirzaei, Amirreza  and
Naik, Atharva  and
Ashok, Arjun  and
Dhanasekaran, Arut Selvan  and
Arunkumar, Anjana  and
Stap, David  and
Pathak, Eshaan  and
Karamanolakis, Giannis  and
Lai, Haizhi  and
Purohit, Ishan  and
Mondal, Ishani  and
Anderson, Jacob  and
Kuznia, Kirby  and
Doshi, Krima  and
Pal, Kuntal Kumar  and
Patel, Maitreya  and
Moradshahi, Mehrad  and
Parmar, Mihir  and
Purohit, Mirali  and
Varshney, Neeraj  and
Kaza, Phani Rohitha  and
Verma, Pulkit  and
Puri, Ravsehaj Singh  and
Karia, Rushang  and
Doshi, Savan  and
Sampat, Shailaja Keyur  and
Mishra, Siddhartha  and
Reddy A, Sujan  and
Patro, Sumanta  and
Dixit, Tanay  and
Shen, Xudong},
 booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
 pages = {5085--5109},
 title = {Super-{N}atural{I}nstructions: Generalization via Declarative Instructions on 1600+ {NLP} Tasks},
 year = {2022}
}

@inproceedings{weifinetuned,
 author = {Jason Wei and
Maarten Bosma and
Vincent Y. Zhao and
Kelvin Guu and
Adams Wei Yu and
Brian Lester and
Nan Du and
Andrew M. Dai and
Quoc V. Le},
 booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
2022, Virtual Event, April 25-29, 2022},
 title = {Finetuned Language Models are Zero-Shot Learners},
 year = {2022}
}

@article{von2022transformers,
 author = {von Oswald, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, Jo{\~a}o and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max},
 journal = {ArXiv preprint},
 title = {Transformers learn in-context by gradient descent},
 volume = {abs/2212.07677},
 year = {2022}
}

@inproceedings{marino2019okvqa,
 author = {Kenneth Marino and
Mohammad Rastegari and
Ali Farhadi and
Roozbeh Mottaghi},
 booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
2019, Long Beach, CA, USA, June 16-20, 2019},
 pages = {3195--3204},
 title = {{OK-VQA:} {A} Visual Question Answering Benchmark Requiring External
Knowledge},
 year = {2019}
}

@inproceedings{schwenk2022aokvqa,
 author = {Schwenk, Dustin and Khandelwal, Apoorv and Clark, Christopher and Marino, Kenneth and Mottaghi, Roozbeh},
 booktitle = {Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part VIII},
 organization = {Springer},
 pages = {146--162},
 title = {A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge},
 year = {2022}
}

@inproceedings{Suhr2017NLVR,
 author = {Suhr, Alane  and
Lewis, Mike  and
Yeh, James  and
Artzi, Yoav},
 booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
 pages = {217--223},
 title = {A Corpus of Natural Language for Visual Reasoning},
 year = {2017}
}

@article{zhu2023minigpt4,
 author = {Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
 journal = {ArXiv preprint},
 title = {MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models},
 volume = {abs/2304.10592},
 year = {2023}
}

@inproceedings{davinci,
  title={Write and Paint: Generative Vision-Language Models are Unified Modal Learners},
  author={Diao, Shizhe and Zhou, Wangchunshu and Zhang, Xinsong and Wang, Jiawei},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}
@article{zhang2023universal,
  title   = {Universal Multimodal Representation for Language Understanding},
  author  = {Zhuosheng Zhang and Kehai Chen and Rui Wang and Masao Utiyama and Eiichiro Sumita and Zuchao Li and Hai Zhao},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2301.03344}
}

@article{xu2022multiinstruct,
 author = {Xu, Zhiyang and Shen, Ying and Huang, Lifu},
 journal = {ArXiv preprint},
 title = {MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning},
 volume = {abs/2212.10773},
 year = {2022}
}

@article{liu2023llava,
 author = {Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},
 journal = {ArXiv preprint},
 title = {Visual Instruction Tuning},
 volume = {abs/2304.08485},
 year = {2023}
}

@inproceedings{li2022blip,
 author = {Junnan Li and
Dongxu Li and
Caiming Xiong and
Steven C. H. Hoi},
 booktitle = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
2022, Baltimore, Maryland, {USA}},
 editor = {Kamalika Chaudhuri and
Stefanie Jegelka and
Le Song and
Csaba Szepesv{\'{a}}ri and
Gang Niu and
Sivan Sabato},
 pages = {12888--12900},
 series = {Proceedings of Machine Learning Research},
 title = {{BLIP:} Bootstrapping Language-Image Pre-training for Unified Vision-Language
Understanding and Generation},
 volume = {162},
 year = {2022}
}

@article{li2023blip2,
 author = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
 journal = {ArXiv preprint},
 title = {Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
 volume = {abs/2301.12597},
 year = {2023}
}

@article{russakovsky2015imagenet,
 author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
 journal = {International journal of computer vision},
 pages = {211--252},
 title = {Imagenet large scale visual recognition challenge},
 volume = {115},
 year = {2015}
}

@inproceedings{sidorov2020textcaps,
 author = {Sidorov, Oleksii and Hu, Ronghang and Rohrbach, Marcus and Singh, Amanpreet},
 booktitle = {Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16},
 organization = {Springer},
 pages = {742--758},
 title = {Textcaps: a dataset for image captioning with reading comprehension},
 year = {2020}
}

@inproceedings{balanced_vqa_v2,
 author = {Yash Goyal and
Tejas Khot and
Douglas Summers{-}Stay and
Dhruv Batra and
Devi Parikh},
 booktitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition,
{CVPR} 2017, Honolulu, HI, USA, July 21-26, 2017},
 pages = {6325--6334},
 title = {Making the {V} in {VQA} Matter: Elevating the Role of Image Understanding
in Visual Question Answering},
 year = {2017}
}

@inproceedings{mishra2019ocr_vqa,
 author = {Mishra, Anand and Shekhar, Shashank and Singh, Ajeet Kumar and Chakraborty, Anirban},
 booktitle = {2019 international conference on document analysis and recognition (ICDAR)},
 organization = {IEEE},
 pages = {947--952},
 title = {OCR-VQA: Visual Question Answering by Reading Text in Images},
 year = {2019}
}

@inproceedings{singh2019text_vqa,
 author = {Amanpreet Singh and
Vivek Natarajan and
Meet Shah and
Yu Jiang and
Xinlei Chen and
Dhruv Batra and
Devi Parikh and
Marcus Rohrbach},
 booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
2019, Long Beach, CA, USA, June 16-20, 2019},
 pages = {8317--8326},
 title = {Towards {VQA} Models That Can Read},
 year = {2019}
}

@inproceedings{hudson2019gqa,
 author = {Drew A. Hudson and
Christopher D. Manning},
 booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
2019, Long Beach, CA, USA, June 16-20, 2019},
 pages = {6700--6709},
 title = {{GQA:} {A} New Dataset for Real-World Visual Reasoning and Compositional
Question Answering},
 year = {2019}
}

@inproceedings{lerner2022viquae,
 author = {Lerner, Paul and Ferret, Olivier and Guinaudeau, Camille and Le Borgne, Herv\'{e} and Besan{\c{c}}on, Romaric and Moreno, Jos{\'e} G and Lov{\'o}n Melgarejo, Jes{\'u}s},
 booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 pages = {3108--3120},
 title = {ViQuAE, a dataset for knowledge-based visual question answering about named entities},
 year = {2022}
}

@inproceedings{biten2019st_vqa,
 author = {Ali Furkan Biten and
Rub{\`{e}}n Tito and
Andr{\'{e}}s Mafla and
Llu{\'{\i}}s G{\'{o}}mez i Bigorda and
Mar{\c{c}}al Rusi{\~{n}}ol and
C. V. Jawahar and
Ernest Valveny and
Dimosthenis Karatzas},
 booktitle = {2019 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
2019, Seoul, Korea (South), October 27 - November 2, 2019},
 pages = {4290--4300},
 title = {Scene Text Visual Question Answering},
 year = {2019}
}

@inproceedings{huang2016vist,
 author = {Huang, Ting-Hao Kenneth  and
Ferraro, Francis  and
Mostafazadeh, Nasrin  and
Misra, Ishan  and
Agrawal, Aishwarya  and
Devlin, Jacob  and
Girshick, Ross  and
He, Xiaodong  and
Kohli, Pushmeet  and
Batra, Dhruv  and
Zitnick, C. Lawrence  and
Parikh, Devi  and
Vanderwende, Lucy  and
Galley, Michel  and
Mitchell, Margaret},
 booktitle = {Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
 pages = {1233--1239},
 title = {Visual Storytelling},
 year = {2016}
}

@inproceedings{esnlive,
 author = {Maxime Kayser and
Oana{-}Maria Camburu and
Leonard Salewski and
Cornelius Emde and
Virginie Do and
Zeynep Akata and
Thomas Lukasiewicz},
 booktitle = {2021 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
2021, Montreal, QC, Canada, October 10-17, 2021},
 pages = {1224--1234},
 title = {e-ViL: {A} Dataset and Benchmark for Natural Language Explanations
in Vision-Language Tasks},
 year = {2021}
}

@inproceedings{mathew2021docvqa,
 author = {Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, CV},
 booktitle = {Proceedings of the IEEE/CVF winter conference on applications of computer vision},
 pages = {2200--2209},
 title = {Docvqa: A dataset for vqa on document images},
 year = {2021}
}

@inproceedings{lin2014mscoco,
 author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
 booktitle = {Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
 organization = {Springer},
 pages = {740--755},
 title = {Microsoft coco: Common objects in context},
 year = {2014}
}

@article{dai2022can,
 author = {Dai, Damai and Sun, Yutao and Dong, Li and Hao, Yaru and Sui, Zhifang and Wei, Furu},
 journal = {ArXiv preprint},
 title = {Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta Optimizers},
 volume = {abs/2212.10559},
 year = {2022}
}

@inproceedings{das2017visual_dialog,
 author = {Abhishek Das and
Satwik Kottur and
Khushi Gupta and
Avi Singh and
Deshraj Yadav and
Jos{\'{e}} M. F. Moura and
Devi Parikh and
Dhruv Batra},
 booktitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition,
{CVPR} 2017, Honolulu, HI, USA, July 21-26, 2017},
 pages = {1080--1089},
 title = {Visual Dialog},
 year = {2017}
}

@inproceedings{elliott2016multi30k,
 author = {Elliott, Desmond  and
Frank, Stella  and
Sima{'}an, Khalil  and
Specia, Lucia},
 booktitle = {Proceedings of the 5th Workshop on Vision and Language},
 pages = {70--74},
 title = {{M}ulti30{K}: Multilingual {E}nglish-{G}erman Image Descriptions},
 year = {2016}
}

@inproceedings{yu2016modeling_refcoco,
 author = {Yu, Licheng and Poirson, Patrick and Yang, Shan and Berg, Alexander C and Berg, Tamara L},
 booktitle = {Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14},
 organization = {Springer},
 pages = {69--85},
 title = {Modeling context in referring expressions},
 year = {2016}
}

@inproceedings{kazemzadeh2014referitgame,
 author = {Kazemzadeh, Sahar  and
Ordonez, Vicente  and
Matten, Mark  and
Berg, Tamara},
 booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})},
 pages = {787--798},
 title = {{R}efer{I}t{G}ame: Referring to Objects in Photographs of Natural Scenes},
 year = {2014}
}

@article{duanmu2021iqa,
 author = {Duanmu, Zhengfang and Liu, Wentao and Wang, Zhongling and Wang, Zhou},
 journal = {Annual Review of Vision Science},
 pages = {437--464},
 title = {Quantifying visual image quality: A Bayesian view},
 volume = {7},
 year = {2021}
}

@inproceedings{zellers2019vcr,
 author = {Rowan Zellers and
Yonatan Bisk and
Ali Farhadi and
Yejin Choi},
 booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
2019, Long Beach, CA, USA, June 16-20, 2019},
 pages = {6720--6731},
 title = {From Recognition to Cognition: Visual Commonsense Reasoning},
 year = {2019}
}

@inproceedings{tanaka2021visualmrc,
 author = {Ryota Tanaka and
Kyosuke Nishida and
Sen Yoshida},
 booktitle = {Thirty-Fifth {AAAI} Conference on Artificial Intelligence, {AAAI}
2021, Thirty-Third Conference on Innovative Applications of Artificial
Intelligence, {IAAI} 2021, The Eleventh Symposium on Educational Advances
in Artificial Intelligence, {EAAI} 2021, Virtual Event, February 2-9,
2021},
 pages = {13878--13888},
 title = {VisualMRC: Machine Reading Comprehension on Document Images},
 year = {2021}
}

@article{li2019coco_cn,
 author = {Li, Xirong and Xu, Chaoxi and Wang, Xiaoxu and Lan, Weiyu and Jia, Zhengxiong and Yang, Gang and Xu, Jieping},
 journal = {IEEE Transactions on Multimedia},
 number = {9},
 pages = {2347--2360},
 title = {COCO-CN for cross-lingual image tagging, captioning, and retrieval},
 volume = {21},
 year = {2019}
}

@inproceedings{krause2016image_para_cap,
 author = {Jonathan Krause and
Justin Johnson and
Ranjay Krishna and
Li Fei{-}Fei},
 booktitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition,
{CVPR} 2017, Honolulu, HI, USA, July 21-26, 2017},
 pages = {3337--3345},
 title = {A Hierarchical Approach for Generating Descriptive Image Paragraphs},
 year = {2017}
}

@inproceedings{agrawal2019nocaps,
 author = {Harsh Agrawal and
Peter Anderson and
Karan Desai and
Yufei Wang and
Xinlei Chen and
Rishabh Jain and
Mark Johnson and
Dhruv Batra and
Devi Parikh and
Stefan Lee},
 booktitle = {2019 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
2019, Seoul, Korea (South), October 27 - November 2, 2019},
 pages = {8947--8956},
 title = {nocaps: novel object captioning at scale},
 year = {2019}
}

@article{krishna2017visual_genome,
 author = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
 journal = {International journal of computer vision},
 pages = {32--73},
 title = {Visual genome: Connecting language and vision using crowdsourced dense image annotations},
 volume = {123},
 year = {2017}
}

@inproceedings{xu2016msrvtt,
 author = {Jun Xu and
Tao Mei and
Ting Yao and
Yong Rui},
 booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition,
{CVPR} 2016, Las Vegas, NV, USA, June 27-30, 2016},
 pages = {5288--5296},
 title = {{MSR-VTT:} {A} Large Video Description Dataset for Bridging Video
and Language},
 year = {2016}
}

@inproceedings{xu2017msrvtt_qa,
 author = {Dejing Xu and
Zhou Zhao and
Jun Xiao and
Fei Wu and
Hanwang Zhang and
Xiangnan He and
Yueting Zhuang},
 booktitle = {Proceedings of the 2017 {ACM} on Multimedia Conference, {MM} 2017,
Mountain View, CA, USA, October 23-27, 2017},
 pages = {1645--1653},
 title = {Video Question Answering via Gradually Refined Attention over Appearance
and Motion},
 year = {2017}
}

@inproceedings{li2016flickr8k_cn,
 author = {Li, Xirong and Lan, Weiyu and Dong, Jianfeng and Liu, Hailong},
 booktitle = {Proceedings of the 2016 ACM on international conference on multimedia retrieval},
 pages = {271--275},
 title = {Adding chinese captions to images},
 year = {2016}
}

@article{veit2016coco_text,
 author = {Veit, Andreas and Matera, Tomas and Neumann, Lukas and Matas, Jiri and Belongie, Serge},
 journal = {ArXiv preprint},
 title = {Coco-text: Dataset and benchmark for text detection and recognition in natural images},
 volume = {abs/1601.07140},
 year = {2016}
}

@article{chen2017chinesefoodnet,
 author = {Chen, Xin and Zhu, Yu and Zhou, Hua and Diao, Liang and Wang, Dongyan},
 journal = {ArXiv preprint},
 title = {Chinesefoodnet: A large-scale image dataset for chinese food recognition},
 volume = {abs/1705.02743},
 year = {2017}
}
@article{anymal,
  title   = {AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model},
  author  = {Seungwhan Moon and Andrea Madotto and Zhaojiang Lin and Tushar Nagarajan and Matt Smith and Shashank Jain and Chun-Fu Yeh and Prakash Murugesan and Peyman Heidari and Yue Liu and Kavya Srinet and Babak Damavandi and Anuj Kumar},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2309.16058}
}
@inproceedings{goyal2017something_something,
 author = {Raghav Goyal and
Samira Ebrahimi Kahou and
Vincent Michalski and
Joanna Materzynska and
Susanne Westphal and
Heuna Kim and
Valentin Haenel and
Ingo Fr{\"{u}}nd and
Peter Yianilos and
Moritz Mueller{-}Freitag and
Florian Hoppe and
Christian Thurau and
Ingo Bax and
Roland Memisevic},
 booktitle = {{IEEE} International Conference on Computer Vision, {ICCV} 2017, Venice,
Italy, October 22-29, 2017},
 pages = {5843--5851},
 title = {The "Something Something" Video Database for Learning and Evaluating
Visual Common Sense},
 year = {2017}
}

@article{liu2022vsr,
 author = {Liu, Fangyu and Emerson, Guy and Collier, Nigel},
 journal = {ArXiv preprint},
 title = {Visual spatial reasoning},
 volume = {abs/2205.00363},
 year = {2022}
}

@inproceedings{zheng2021mmchat,
 author = {Zheng, Yinhe  and
Chen, Guanyi  and
Liu, Xin  and
Sun, Jian},
 booktitle = {Proceedings of the Thirteenth Language Resources and Evaluation Conference},
 pages = {5778--5786},
 title = {{MMC}hat: Multi-Modal Chat Dataset on Social Media},
 year = {2022}
}

@inproceedings{andreas2016shapes,
 author = {Jacob Andreas and
Marcus Rohrbach and
Trevor Darrell and
Dan Klein},
 booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition,
{CVPR} 2016, Las Vegas, NV, USA, June 27-30, 2016},
 pages = {39--48},
 title = {Neural Module Networks},
 year = {2016}
}

@article{sharma2017nlg_eval,
 author = {Sharma, Shikhar and Asri, Layla El and Schulz, Hannes and Zumer, Jeremie},
 journal = {ArXiv preprint},
 title = {Relevance of unsupervised metrics in task-oriented dialogue for evaluating natural language generation},
 volume = {abs/1706.09799},
 year = {2017}
}

@inproceedings{rohrbach2018object,
 author = {Rohrbach, Anna  and
Hendricks, Lisa Anne  and
Burns, Kaylee  and
Darrell, Trevor  and
Saenko, Kate},
 booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
 pages = {4035--4045},
 title = {Object Hallucination in Image Captioning},
 year = {2018}
}

@inproceedings{kim-etal-2019-audiocaps,
 author = {Kim, Chris Dongjoo  and
Kim, Byeongchang  and
Lee, Hyunmin  and
Kim, Gunhee},
 booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
 pages = {119--132},
 title = {{A}udio{C}aps: Generating Captions for Audios in The Wild},
 year = {2019}
}

@misc{icl_survey,
 archiveprefix = {arXiv},
 author = {Qingxiu Dong and Lei Li and Damai Dai and Ce Zheng and Zhiyong Wu and Baobao Chang and Xu Sun and Jingjing Xu and Lei Li and Zhifang Sui},
 eprint = {2301.00234},
 primaryclass = {cs.CL},
 title = {A Survey for In-context Learning},
 year = {2022}
}

@article{zhao2023mmicl,
 author = {Zhao, Haozhe and Cai, Zefan and Si, Shuzheng and Ma, Xiaojian and An, Kaikai and Chen, Liang and Liu, Zixuan and Wang, Sheng and Han, Wenjuan and Chang, Baobao},
 journal = {ArXiv preprint},
 title = {MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning},
 volume = {abs/2309.07915},
 year = {2023}
}

@inproceedings{lu2018neural,
 author = {Jiasen Lu and
Jianwei Yang and
Dhruv Batra and
Devi Parikh},
 booktitle = {2018 {IEEE} Conference on Computer Vision and Pattern Recognition,
{CVPR} 2018, Salt Lake City, UT, USA, June 18-22, 2018},
 pages = {7219--7228},
 title = {Neural Baby Talk},
 year = {2018}
}

@article{baichuan2023baichuan2,
 author = {Baichuan},
 journal = {ArXiv preprint},
 title = {Baichuan 2: Open Large-scale Language Models},
 volume = {abs/2309.10305},
 year = {2023}
}

@article{mei2023wavcaps,
 author = {Mei, Xinhao and Meng, Chutong and Liu, Haohe and Kong, Qiuqiang and Ko, Tom and Zhao, Chengqi and Plumbley, Mark D and Zou, Yuexian and Wang, Wenwu},
 journal = {ArXiv preprint},
 title = {WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research},
 volume = {abs/2303.17395},
 year = {2023}
}

@inproceedings{you-etal-2022-end,
 author = {You, Chenyu  and
Chen, Nuo  and
Liu, Fenglin  and
Ge, Shen  and
Wu, Xian  and
Zou, Yuexian},
 booktitle = {Findings of the Association for Computational Linguistics: NAACL 2022},
 pages = {1219--1232},
 title = {End-to-end Spoken Conversational Question Answering: Task, Dataset and Model},
 year = {2022}
}

@article{zhai2023investigating,
 author = {Zhai, Yuexiang and Tong, Shengbang and Li, Xiao and Cai, Mu and Qu, Qing and Lee, Yong Jae and Ma, Yi},
 journal = {ArXiv preprint},
 title = {Investigating the Catastrophic Forgetting in Multimodal Large Language Models},
 volume = {abs/2309.10313},
 year = {2023}
}

@article{li2023otter,
 author = {Li, Bo and Zhang, Yuanhan and Chen, Liangyu and Wang, Jinghao and Yang, Jingkang and Liu, Ziwei},
 journal = {ArXiv preprint},
 title = {Otter: A Multi-Modal Model with In-Context Instruction Tuning},
 volume = {abs/2305.03726},
 year = {2023}
}

@article{li2023mimicit,
 archiveprefix = {arXiv},
 author = {Bo Li and Yuanhan Zhang and Liangyu Chen and Jinghao Wang and Fanyi Pu and Jingkang Yang and Chunyuan Li and Ziwei Liu},
 eprint = {2306.05425},
 primaryclass = {cs.CV},
 title = {MIMIC-IT: Multi-Modal In-Context Instruction Tuning},
 year = {2023}
}

@article{2023llavarlhf,
 author = {Zhiqing Sun and Sheng Shen and Shengcao Cao and Haotian Liu and Chunyuan Li and Yikang Shen and Chuang Gan and Liang-Yan Gui and Yu-Xiong Wang and Yiming Yang and Kurt Keutzer and Trevor Darrell},
 journal = {ArXiv preprint},
 title = {Aligning Large Multimodal Models with Factually Augmented RLHF},
 volume = {abs/2309.14525},
 year = {2023}
}

@article{zhou2023lima,
 author = {Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srini and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
 journal = {ArXiv preprint},
 title = {Lima: Less is more for alignment},
 volume = {abs/2305.11206},
 year = {2023}
}

@article{awadalla2023openflamingo,
 author = {Anas Awadalla and Irena Gao and Josh Gardner and Jack Hessel and Yusuf Hanafy and Wanrong Zhu and Kalyani Marathe and Yonatan Bitton and Samir Gadre and Shiori Sagawa and Jenia Jitsev and Simon Kornblith and Pang Wei Koh and Gabriel Ilharco and Mitchell Wortsman and Ludwig Schmidt},
 journal = {ArXiv preprint},
 title = {OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models},
 volume = {abs/2308.01390},
 year = {2023}
}

@article{Alayrac2022FlamingoAV,
 author = {Jean-Baptiste Alayrac and Jeff Donahue and Pauline Luc and Antoine Miech and Iain Barr and Yana Hasson and Karel Lenc and Arthur Mensch and Katie Millican and Malcolm Reynolds and Roman Ring and Eliza Rutherford and Serkan Cabi and Tengda Han and Zhitao Gong and Sina Samangooei and Marianne Monteiro and Jacob Menick and Sebastian Borgeaud and Andy Brock and Aida Nematzadeh and Sahand Sharifzadeh and Mikolaj Binkowski and Ricardo Barreira and Oriol Vinyals and Andrew Zisserman and Karen Simonyan},
 journal = {ArXiv preprint},
 title = {Flamingo: a Visual Language Model for Few-Shot Learning},
 volume = {abs/2204.14198},
 year = {2022}
}

@article{ouyang2022instructgpt,
 author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
 journal = {Advances in Neural Information Processing Systems},
 pages = {27730--27744},
 title = {Training language models to follow instructions with human feedback},
 volume = {35},
 year = {2022}
}

@article{zhao2023svit,
 author = {Zhao, Bo and Wu, Boya and Huang, Tiejun},
 journal = {ArXiv preprint},
 title = {SVIT: Scaling up Visual Instruction Tuning},
 volume = {abs/2307.04087},
 year = {2023}
}

@article{zhang2023siren,
 author = {Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and others},
 journal = {ArXiv preprint},
 title = {Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models},
 volume = {abs/2309.01219},
 year = {2023}
}

@article{li2023hallucinate,
 author = {Li, Yifan and Du, Yifan and Zhou, Kun and Wang, Jinpeng and Zhao, Wayne Xin and Wen, Ji-Rong},
 journal = {ArXiv preprint},
 title = {Evaluating object hallucination in large vision-language models},
 volume = {abs/2305.10355},
 year = {2023}
}

@article{chen2023polite,
 author = {Chen, Delong and Liu, Jianfeng and Dai, Wenliang and Wang, Baoyuan},
 journal = {ArXiv preprint},
 title = {Visual Instruction Tuning with Polite Flamingo},
 volume = {abs/2307.01003},
 year = {2023}
}

@misc{vicuna2023,
 author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
 title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
 year = {2023}
}
@article{flexivit,
  title   = {FlexiViT: One Model for All Patch Sizes},
  author  = {Lucas Beyer and Pavel Izmailov and Alexander Kolesnikov and Mathilde Caron and Simon Kornblith and Xiaohua Zhai and Matthias Minderer and Michael Tschannen and Ibrahim Alabdulmohsin and Filip Pavetic},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2212.08013}
}

@article{lee2022pix2struct,
  title   = {Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding},
  author  = {Kenton Lee and Mandar Joshi and Iulia Turc and Hexiang Hu and Fangyu Liu and Julian Eisenschlos and Urvashi Khandelwal and Peter Shaw and Ming-Wei Chang and Kristina Toutanova},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2210.03347}
}

@article{chen2023internvl,
  title={InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and Li, Bin and Luo, Ping and Lu, Tong and Qiao, Yu and Dai, Jifeng},
  journal={arXiv preprint arXiv:2312.14238},
  year={2023}
}
@article{chen2024far,
  title={How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites},
  author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
  journal={arXiv preprint arXiv:2404.16821},
  year={2024}
}


@article{wang2023large,
 author = {Wang, Peiyi and Li, Lei and Chen, Liang and Zhu, Dawei and Lin, Binghuai and Cao, Yunbo and Liu, Qi and Liu, Tianyu and Sui, Zhifang},
 journal = {ArXiv preprint},
 title = {Large Language Models are not Fair Evaluators},
 volume = {abs/2305.17926},
 year = {2023}
}

@inproceedings{AdamRoberts2020HowMK,
 author = {Roberts, Adam  and
Raffel, Colin  and
Shazeer, Noam},
 booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
 pages = {5418--5426},
 title = {How Much Knowledge Can You Pack Into the Parameters of a Language Model?},
 year = {2020}
}

@inproceedings{albef,
 author = {Junnan Li and
Ramprasaath R. Selvaraju and
Akhilesh Gotmare and
Shafiq R. Joty and
Caiming Xiong and
Steven Chu{-}Hong Hoi},
 booktitle = {Advances in Neural Information Processing Systems 34: Annual Conference
on Neural Information Processing Systems 2021, NeurIPS 2021, December
6-14, 2021, virtual},
 editor = {Marc'Aurelio Ranzato and
Alina Beygelzimer and
Yann N. Dauphin and
Percy Liang and
Jennifer Wortman Vaughan},
 pages = {9694--9705},
 title = {Align before Fuse: Vision and Language Representation Learning with
Momentum Distillation},
 year = {2021}
}

@inproceedings{kim2021vilt,
 author = {Wonjae Kim and
Bokyung Son and
Ildoo Kim},
 booktitle = {Proceedings of the 38th International Conference on Machine Learning,
{ICML} 2021, 18-24 July 2021, Virtual Event},
 editor = {Marina Meila and
Tong Zhang},
 pages = {5583--5594},
 series = {Proceedings of Machine Learning Research},
 title = {ViLT: Vision-and-Language Transformer Without Convolution or Region
Supervision},
 volume = {139},
 year = {2021}
}

@inproceedings{abdou-etal-2021-languagecolor,
 author = {Abdou, Mostafa  and
Kulmizev, Artur  and
Hershcovich, Daniel  and
Frank, Stella  and
Pavlick, Ellie  and
S{\o}gaard, Anders},
 booktitle = {Proceedings of the 25th Conference on Computational Natural Language Learning},
 pages = {109--132},
 title = {Can Language Models Encode Perceptual Structure Without Grounding? A Case Study in Color},
 year = {2021}
}

@inproceedings{bisk2020piqa,
 author = {Yonatan Bisk and
Rowan Zellers and
Ronan LeBras and
Jianfeng Gao and
Yejin Choi},
 booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
2020, The Thirty-Second Innovative Applications of Artificial Intelligence
Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
February 7-12, 2020},
 pages = {7432--7439},
 title = {{PIQA:} Reasoning about Physical Commonsense in Natural Language},
 year = {2020}
}

@inproceedings{huang2022planner,
 author = {Wenlong Huang and
Pieter Abbeel and
Deepak Pathak and
Igor Mordatch},
 booktitle = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
2022, Baltimore, Maryland, {USA}},
 editor = {Kamalika Chaudhuri and
Stefanie Jegelka and
Le Song and
Csaba Szepesv{\'{a}}ri and
Gang Niu and
Sivan Sabato},
 pages = {9118--9147},
 series = {Proceedings of Machine Learning Research},
 title = {Language Models as Zero-Shot Planners: Extracting Actionable Knowledge
for Embodied Agents},
 volume = {162},
 year = {2022}
}

@article{ahn2022can,
 author = {Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and others},
 journal = {ArXiv preprint},
 title = {Do as i can, not as i say: Grounding language in robotic affordances},
 volume = {abs/2204.01691},
 year = {2022}
}

@inproceedings{hu2021unit,
 author = {Ronghang Hu and
Amanpreet Singh},
 booktitle = {2021 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
2021, Montreal, QC, Canada, October 10-17, 2021},
 pages = {1419--1429},
 title = {UniT: Multimodal Multitask Learning with a Unified Transformer},
 year = {2021}
}

@inproceedings{wang2021simvlm,
 author = {Zirui Wang and
Jiahui Yu and
Adams Wei Yu and
Zihang Dai and
Yulia Tsvetkov and
Yuan Cao},
 booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
2022, Virtual Event, April 25-29, 2022},
 title = {SimVLM: Simple Visual Language Model Pretraining with Weak Supervision},
 year = {2022}
}

@book{bloom2002children,
 author = {Bloom, Paul},
 title = {How children learn the meanings of words},
 year = {2002}
}

@inproceedings{tamari2020embodiedNLU,
 author = {Tamari, Ronen  and
Shani, Chen  and
Hope, Tom  and
Petruck, Miriam R L  and
Abend, Omri  and
Shahaf, Dafna},
 booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
 pages = {6268--6281},
 title = {{L}anguage (Re)modelling: {T}owards Embodied Language Understanding},
 year = {2020}
}

@inproceedings{singh2022flava,
 author = {Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
 booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
 pages = {15638--15650},
 title = {Flava: A foundational language and vision alignment model},
 year = {2022}
}

@article{huang2017nst,
 author = {Huang, Zehao and Wang, Naiyan},
 journal = {ArXiv preprint},
 title = {Like what you like: Knowledge distill via neuron selectivity transfer},
 volume = {abs/1707.01219},
 year = {2017}
}

@article{belinkov2022probing,
 author = {Belinkov, Yonatan},
 journal = {Computational Linguistics},
 number = {1},
 pages = {207--219},
 title = {Probing Classifiers: Promises, Shortcomings, and Advances},
 volume = {48},
 year = {2022}
}

@article{cohen1960coefficient,
 author = {Cohen, Jacob},
 journal = {Educational and psychological measurement},
 number = {1},
 pages = {37--46},
 title = {A coefficient of agreement for nominal scales},
 volume = {20},
 year = {1960}
}

@inproceedings{zhang-etal-2022-visual,
 author = {Zhang, Chenyu  and
Van Durme, Benjamin  and
Li, Zhuowan  and
Stengel-Eskin, Elias},
 booktitle = {Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
 pages = {5321--5335},
 title = {Visual Commonsense in Pretrained Unimodal and Multimodal Models},
 year = {2022}
}

@inproceedings{madureira-2021-flamingos,
 author = {Madureira, Brielen},
 booktitle = {Proceedings of the Fifth Workshop on Teaching NLP},
 pages = {87--91},
 title = {Flamingos and Hedgehogs in the Croquet-Ground: Teaching Evaluation of {NLP} Systems for Undergraduate Students},
 year = {2021}
}

@inproceedings{schick-schutze-2021-just,
 author = {Schick, Timo  and
Sch{\"u}tze, Hinrich},
 booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
 pages = {2339--2352},
 title = {It{'}s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners},
 year = {2021}
}
@misc{make-a-scene,
  doi = {10.48550/ARXIV.2203.13131},
  url = {https://arxiv.org/abs/2203.13131},
  author = {Gafni, Oran and Polyak, Adam and Ashual, Oron and Sheynin, Shelly and Parikh, Devi and Taigman, Yaniv},
  title = {Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@inproceedings{wang-etal-2019-make,
 author = {Wang, Cunxiang  and
Liang, Shuailong  and
Zhang, Yue  and
Li, Xiaonan  and
Gao, Tian},
 booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
 pages = {4020--4026},
 title = {Does it Make Sense? And Why? A Pilot Study for Sense Making and Explanation},
 year = {2019}
}

@inproceedings{patel2022mapping,
 author = {Roma Patel and
Ellie Pavlick},
 booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
2022, Virtual Event, April 25-29, 2022},
 title = {Mapping Language Models to Grounded Conceptual Spaces},
 year = {2022}
}

@inproceedings{bisk2020experience,
 author = {Bisk, Yonatan  and
Holtzman, Ari  and
Thomason, Jesse  and
Andreas, Jacob  and
Bengio, Yoshua  and
Chai, Joyce  and
Lapata, Mirella  and
Lazaridou, Angeliki  and
May, Jonathan  and
Nisnevich, Aleksandr  and
Pinto, Nicolas  and
Turian, Joseph},
 booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
 pages = {8718--8735},
 title = {Experience Grounds Language},
 year = {2020}
}


@inproceedings{changpinyo2021cc12m,
 author = {Soravit Changpinyo and
Piyush Sharma and
Nan Ding and
Radu Soricut},
 booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
2021, virtual, June 19-25, 2021},
 pages = {3558--3568},
 title = {Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize
Long-Tail Visual Concepts},
 year = {2021}
}

@article{Chen2019UNITER,
 author = {Yen-Chun Chen and Linjie Li and Licheng Yu and Ahmed El Kholy and Faisal Ahmed and Zhe Gan and Yu Cheng and Jingjing Liu},
 journal = {ArXiv},
 title = {UNITER: Learning UNiversal Image-TExt Representations},
 year = {2019}
}

@inproceedings{dai2022knowledge,
 author = {Dai, Damai  and
Dong, Li  and
Hao, Yaru  and
Sui, Zhifang  and
Chang, Baobao  and
Wei, Furu},
 booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
 pages = {8493--8502},
 title = {Knowledge Neurons in Pretrained Transformers},
 year = {2022}
}

@inproceedings{declip,
 author = {Yangguang Li and
Feng Liang and
Lichen Zhao and
Yufeng Cui and
Wanli Ouyang and
Jing Shao and
Fengwei Yu and
Junjie Yan},
 booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
2022, Virtual Event, April 25-29, 2022},
 title = {Supervision Exists Everywhere: {A} Data Efficient Contrastive Language-Image
Pre-training Paradigm},
 year = {2022}
}

@inproceedings{devlin2019bert,
 author = {Devlin, Jacob  and
Chang, Ming-Wei  and
Lee, Kenton  and
Toutanova, Kristina},
 booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
 pages = {4171--4186},
 title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
 year = {2019}
}

@inproceedings{fayyaz2021not,
 author = {Fayyaz, Mohsen  and
Aghazadeh, Ehsan  and
Modarressi, Ali  and
Mohebbi, Hosein  and
Pilehvar, Mohammad Taher},
 booktitle = {Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
 pages = {375--388},
 title = {Not All Models Localize Linguistic Knowledge in the Same Place: A Layer-wise Probing on {BERT}oids{'} Representations},
 year = {2021}
}

@book{fechner1948elements,
 author = {Fechner, Gustav Theodor and Howes, Davis H and Boring, Edwin Garrigues},
 title = {Elements of psychophysics},
 volume = {1},
 year = {1966}
}

@inproceedings{filip,
 author = {Lewei Yao and
Runhui Huang and
Lu Hou and
Guansong Lu and
Minzhe Niu and
Hang Xu and
Xiaodan Liang and
Zhenguo Li and
Xin Jiang and
Chunjing Xu},
 booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
2022, Virtual Event, April 25-29, 2022},
 title = {{FILIP:} Fine-grained Interactive Language-Image Pre-Training},
 year = {2022}
}

@inproceedings{forbes2019neuralphysical,
 author = {Forbes, Maxwell and Holtzman, Ari and Choi, Yejin},
 booktitle = {CogSci},
 title = {Do Neural Language Representations Learn Physical Commonsense?},
 year = {2019}
}

@article{gueorguiev2016touch,
 author = {Gueorguiev, David and Bochereau, S{\'e}r{\'e}na and Mouraux, Andr{\'e} and Hayward, Vincent and Thonnard, Jean-Louis},
 journal = {Scientific reports},
 title = {Touch uses frictional cues to discriminate flat materials},
 year = {2016}
}

@article{harnad1990symbol,
 author = {Harnad, Stevan},
 journal = {Physica D: Nonlinear Phenomena},
 title = {The symbol grounding problem},
 year = {1990}
}

@article{ren2022rethinking,
 author = {Ren, Shuhuai and Li, Lei and Ren, Xuancheng and Zhao, Guangxiang and Sun, Xu},
 journal = {ArXiv preprint},
 title = {Rethinking the Openness of CLIP},
 volume = {abs/2206.01986},
 year = {2022}
}

@article{hintonKD,
 author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others},
 journal = {ArXiv preprint},
 title = {Distilling the knowledge in a neural network},
 volume = {abs/1503.02531},
 year = {2015}
}

@article{iyer2017qqp,
 author = {Iyer, Shankar and Dandekar, Nikhil and Csernai, Korn{\'e}l},
 journal = {First Quora Dataset Release: Question Pairs},
 title = {Quora question pairs},
 year = {2017}
}

@inproceedings{jawahar2019does,
 author = {Jawahar, Ganesh  and
Sagot, Beno{\^\i}t  and
Seddah, Djam{\'e}},
 booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
 pages = {3651--3657},
 title = {What Does {BERT} Learn about the Structure of Language?},
 year = {2019}
}

@inproceedings{Jia2021ALIGN,
 author = {Chao Jia and
Yinfei Yang and
Ye Xia and
Yi{-}Ting Chen and
Zarana Parekh and
Hieu Pham and
Quoc V. Le and
Yun{-}Hsuan Sung and
Zhen Li and
Tom Duerig},
 booktitle = {Proceedings of the 38th International Conference on Machine Learning,
{ICML} 2021, 18-24 July 2021, Virtual Event},
 editor = {Marina Meila and
Tong Zhang},
 pages = {4904--4916},
 series = {Proceedings of Machine Learning Research},
 title = {Scaling Up Visual and Vision-Language Representation Learning With
Noisy Text Supervision},
 volume = {139},
 year = {2021}
}

@article{jones2009thermal,
 author = {Jones, Lynette},
 journal = {Scholarpedia},
 title = {Thermal touch},
 year = {2009}
}

@inproceedings{vaswani2017attention,
 author = {Ashish Vaswani and
Noam Shazeer and
Niki Parmar and
Jakob Uszkoreit and
Llion Jones and
Aidan N. Gomez and
Lukasz Kaiser and
Illia Polosukhin},
 booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
on Neural Information Processing Systems 2017, December 4-9, 2017,
Long Beach, CA, {USA}},
 editor = {Isabelle Guyon and
Ulrike von Luxburg and
Samy Bengio and
Hanna M. Wallach and
Rob Fergus and
S. V. N. Vishwanathan and
Roman Garnett},
 pages = {5998--6008},
 title = {Attention is All you Need},
 year = {2017}
}

@article{krizhevsky2009cifar100,
 author = {Krizhevsky, Alex and Hinton, Geoffrey and others},
 title = {Learning multiple layers of features from tiny images},
 year = {2009}
}

@inproceedings{LAMA,
 author = {Petroni, Fabio  and
Rockt{\"a}schel, Tim  and
Riedel, Sebastian  and
Lewis, Patrick  and
Bakhtin, Anton  and
Wu, Yuxiang  and
Miller, Alexander},
 booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
 pages = {2463--2473},
 title = {Language Models as Knowledge Bases?},
 year = {2019}
}

@article{Li2019VisualBERT,
 author = {Liunian Harold Li and Mark Yatskar and Da Yin and Cho-Jui Hsieh and Kai-Wei Chang},
 journal = {ArXiv},
 title = {VisualBERT: A Simple and Performant Baseline for Vision and Language},
 year = {2019}
}

@inproceedings{Li2020OscarOA,
 author = {Xiujun Li and Xi Yin and Chunyuan Li and Xiaowei Hu and Pengchuan Zhang and Lei Zhang and Lijuan Wang and Houdong Hu and Li Dong and Furu Wei and Yejin Choi and Jianfeng Gao},
 booktitle = {Proc. of ECCV},
 title = {Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks},
 year = {2020}
}

@inproceedings{liu-etal-2022-spatial-commonsense,
 author = {Liu, Xiao  and
Yin, Da  and
Feng, Yansong  and
Zhao, Dongyan},
 booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
 pages = {2365--2376},
 title = {Things not Written in Text: Exploring Spatial Commonsense from Visual Signals},
 year = {2022}
}

@inproceedings{liu2019linguistic,
 author = {Liu, Nelson F.  and
Gardner, Matt  and
Belinkov, Yonatan  and
Peters, Matthew E.  and
Smith, Noah A.},
 booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
 pages = {1073--1094},
 title = {Linguistic Knowledge and Transferability of Contextual Representations},
 year = {2019}
}

@article{kaplan2020scalinglaw,
 author = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
 journal = {ArXiv preprint},
 title = {Scaling laws for neural language models},
 volume = {abs/2001.08361},
 year = {2020}
}

@book{gopnik1999childrenLearn,
 author = {Gopnik, Alison and Meltzoff, Andrew N and Kuhl, Patricia K},
 title = {The scientist in the crib: Minds, brains, and how children learn.},
 year = {1999}
}

@article{hao2022LMasInterface,
 author = {Hao, Yaru and Song, Haoyu and Dong, Li and Huang, Shaohan and Chi, Zewen and Wang, Wenhui and Ma, Shuming and Wei, Furu},
 journal = {ArXiv preprint},
 title = {Language models are general-purpose interfaces},
 volume = {abs/2206.06336},
 year = {2022}
}

@article{thomee2016yfcc100m,
 author = {Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
 journal = {Communications of the ACM},
 number = {2},
 pages = {64--73},
 title = {YFCC100M: The new data in multimedia research},
 volume = {59},
 year = {2016}
}

@article{Liu2019RoBERTa,
 author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
 journal = {ArXiv preprint},
 title = {Ro{BERT}a: {A} Robustly Optimized {BERT} Pretraining Approach},
 year = {2019}
}

@inproceedings{liu2022things,
 author = {Liu, Xiao  and
Yin, Da  and
Feng, Yansong  and
Zhao, Dongyan},
 booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
 pages = {2365--2376},
 title = {Things not Written in Text: Exploring Spatial Commonsense from Visual Signals},
 year = {2022}
}

@inproceedings{lxmert,
 author = {Tan, Hao  and
Bansal, Mohit},
 booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
 pages = {5100--5111},
 title = {{LXMERT}: Learning Cross-Modality Encoder Representations from Transformers},
 year = {2019}
}

@article{ontonotesv5,
 author = {Weischedel, Ralph and Palmer, Martha and Marcus, Mitchell and Hovy, Eduard and Pradhan, Sameer and Ramshaw, Lance and Xue, Nianwen and Taylor, Ann and Kaufman, Jeff and Franchini, Michelle and others},
 journal = {Linguistic Data Consortium},
 title = {Ontonotes release 5.0 ldc2013t19},
 year = {2013}
}

@inproceedings{pmlr-v78-image2mass,
 author = {Standley, Trevor and Sener, Ozan and Chen, Dawn and Savarese, Silvio},
 booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
 title = {image2mass: Estimating the Mass of an Object from Its Image},
 year = {2017}
}

@article{radford2019gpt,
 author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
 journal = {OpenAI blog},
 title = {Language models are unsupervised multitask learners},
 year = {2019}
}

@inproceedings{rajpurkar2016squad,
 author = {Rajpurkar, Pranav  and
Zhang, Jian  and
Lopyrev, Konstantin  and
Liang, Percy},
 booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
 pages = {2383--2392},
 title = {{SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text},
 year = {2016}
}

@article{li2023m3it,
 author = {Lei Li and Yuwei Yin and Shicheng Li and Liang Chen and Peiyi Wang and Shuhuai Ren and Mukai Li and Yazheng Yang and Jingjing Xu and Xu Sun and Lingpeng Kong and Qi Liu},
 journal = {ArXiv preprint},
 title = {{M$^3$IT}: A Large-Scale Dataset towards Multi-Modal Multilingual Instruction Tuning},
 volume = {abs/2306.04387},
 year = {2023}
}

@article{rogers-etal-2020-BERTology,
 author = {Rogers, Anna  and
Kovaleva, Olga  and
Rumshisky, Anna},
 journal = {Transactions of the Association for Computational Linguistics},
 pages = {842--866},
 title = {A Primer in {BERT}ology: What We Know About How {BERT} Works},
 volume = {8},
 year = {2020}
}

@inproceedings{silveira2014UD,
 author = {Silveira, Natalia  and
Dozat, Timothy  and
de Marneffe, Marie-Catherine  and
Bowman, Samuel  and
Connor, Miriam  and
Bauer, John  and
Manning, Chris},
 booktitle = {Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)},
 pages = {2897--2904},
 title = {A Gold Standard Dependency Corpus for {E}nglish},
 year = {2014}
}

@inproceedings{socher2013sst,
 author = {Socher, Richard  and
Perelygin, Alex  and
Wu, Jean  and
Chuang, Jason  and
Manning, Christopher D.  and
Ng, Andrew  and
Potts, Christopher},
 booktitle = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
 pages = {1631--1642},
 title = {Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank},
 year = {2013}
}

@inproceedings{shen2021much,
 author = {Sheng Shen and
Liunian Harold Li and
Hao Tan and
Mohit Bansal and
Anna Rohrbach and
Kai{-}Wei Chang and
Zhewei Yao and
Kurt Keutzer},
 booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
2022, Virtual Event, April 25-29, 2022},
 title = {How Much Can {CLIP} Benefit Vision-and-Language Tasks?},
 year = {2022}
}

@article{srivastava2022bigbench,
 author = {Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
 journal = {ArXiv preprint},
 title = {Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
 year = {2022}
}

@inproceedings{Su2020VLBERT,
 author = {Weijie Su and
Xizhou Zhu and
Yue Cao and
Bin Li and
Lewei Lu and
Furu Wei and
Jifeng Dai},
 booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
Addis Ababa, Ethiopia, April 26-30, 2020},
 title = {{VL-BERT:} Pre-training of Generic Visual-Linguistic Representations},
 year = {2020}
}

@inproceedings{tan2020vokenization,
 author = {Tan, Hao  and
Bansal, Mohit},
 booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
 pages = {2066--2080},
 title = {Vokenization: Improving Language Understanding with Contextualized, Visual-Grounded Supervision},
 year = {2020}
}

@inproceedings{tenney2019bertpipeline,
 author = {Tenney, Ian  and
Das, Dipanjan  and
Pavlick, Ellie},
 booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
 pages = {4593--4601},
 title = {{BERT} Rediscovers the Classical {NLP} Pipeline},
 year = {2019}
}

@inproceedings{tenney2019probing,
 author = {Ian Tenney and
Patrick Xia and
Berlin Chen and
Alex Wang and
Adam Poliak and
R. Thomas McCoy and
Najoung Kim and
Benjamin Van Durme and
Samuel R. Bowman and
Dipanjan Das and
Ellie Pavlick},
 booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
New Orleans, LA, USA, May 6-9, 2019},
 title = {What do you learn from context? Probing for sentence structure in
contextualized word representations},
 year = {2019}
}

@book{thelen1994dynamic,
 author = {Thelen, Esther and Smith, Linda B},
 title = {A dynamic systems approach to the development of cognition and action},
 year = {1994}
}

@inproceedings{timoPET,
 author = {Schick, Timo  and
Sch{\"u}tze, Hinrich},
 booktitle = {Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume},
 pages = {255--269},
 title = {Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference},
 year = {2021}
}

@inproceedings{voita2020information,
 author = {Voita, Elena  and
Titov, Ivan},
 booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
 pages = {183--196},
 title = {Information-Theoretic Probing with Minimum Description Length},
 year = {2020}
}

@inproceedings{voita2020mdl,
 author = {Voita, Elena  and
Titov, Ivan},
 booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
 pages = {183--196},
 title = {Information-Theoretic Probing with Minimum Description Length},
 year = {2020}
}

@inproceedings{wallace-etal-2019-nlp,
 author = {Wallace, Eric  and
Wang, Yizhong  and
Li, Sujian  and
Singh, Sameer  and
Gardner, Matt},
 booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
 pages = {5307--5315},
 title = {Do {NLP} Models Know Numbers? Probing Numeracy in Embeddings},
 year = {2019}
}

@inproceedings{wallace2019numbers,
 author = {Wallace, Eric  and
Wang, Yizhong  and
Li, Sujian  and
Singh, Sameer  and
Gardner, Matt},
 booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
 pages = {5307--5315},
 title = {Do {NLP} Models Know Numbers? Probing Numeracy in Embeddings},
 year = {2019}
}

@inproceedings{Wang2018GLUE,
 author = {Alex Wang and
Amanpreet Singh and
Julian Michael and
Felix Hill and
Omer Levy and
Samuel R. Bowman},
 booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
New Orleans, LA, USA, May 6-9, 2019},
 title = {{GLUE:} {A} Multi-Task Benchmark and Analysis Platform for Natural
Language Understanding},
 year = {2019}
}

@inproceedings{wang2020align&uniform,
 author = {Tongzhou Wang and
Phillip Isola},
 booktitle = {Proceedings of the 37th International Conference on Machine Learning,
{ICML} 2020, 13-18 July 2020, Virtual Event},
 pages = {9929--9939},
 series = {Proceedings of Machine Learning Research},
 title = {Understanding Contrastive Representation Learning through Alignment
and Uniformity on the Hypersphere},
 volume = {119},
 year = {2020}
}

@article{wei2022emergent,
 author = {Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
 journal = {Transactions on Machine Learning Research},
 title = {Emergent Abilities of Large Language Models},
 year = {2022}
}

@inproceedings{williams2018mnli,
 author = {Williams, Adina  and
Nangia, Nikita  and
Bowman, Samuel},
 booktitle = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
 pages = {1112--1122},
 title = {A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference},
 year = {2018}
}

@inproceedings{yun2021lexicalGrounding,
 author = {Yun, Tian  and
Sun, Chen  and
Pavlick, Ellie},
 booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2021},
 pages = {4357--4366},
 title = {Does Vision-and-Language Pretraining Improve Lexical Grounding?},
 year = {2021}
}

@inproceedings{zhang2020captureScales,
 author = {Zhang, Xikun  and
Ramachandran, Deepak  and
Tenney, Ian  and
Elazar, Yanai  and
Roth, Dan},
 booktitle = {Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
 pages = {292--299},
 title = {Do Language Embeddings capture Scales?},
 year = {2020}
}

@misc{zhang2022opt,
 archiveprefix = {arXiv},
 author = {Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
 eprint = {2205.01068},
 title = {OPT: Open Pre-trained Transformer Language Models},
 year = {2022}
}

@inproceedings{Zhao2021CalibrateBU,
 author = {Zihao Zhao and
Eric Wallace and
Shi Feng and
Dan Klein and
Sameer Singh},
 booktitle = {Proceedings of the 38th International Conference on Machine Learning,
{ICML} 2021, 18-24 July 2021, Virtual Event},
 editor = {Marina Meila and
Tong Zhang},
 pages = {12697--12706},
 series = {Proceedings of Machine Learning Research},
 title = {Calibrate Before Use: Improving Few-shot Performance of Language Models},
 volume = {139},
 year = {2021}
}

@article{xia2023imagenetvc,
 author = {Xia, Heming and Dong, Qingxiu and Li, Lei and Xu, Jingjing and Qin, Ziwei and Sui, Zhifang},
 journal = {ArXiv preprint},
 title = {ImageNetVC: Zero-Shot Visual Commonsense Evaluation on 1000 ImageNet Categories},
 volume = {abs/2305.15028},
 year = {2023}
}

@inproceedings{ren-etal-2023-delving,
 author = {Ren, Shuhuai  and
Li, Lei  and
Ren, Xuancheng  and
Zhao, Guangxiang  and
Sun, Xu},
 booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
 pages = {9587--9606},
 title = {Delving into the Openness of {CLIP}},
 year = {2023}
}

@inproceedings{adam,
 author = {Diederik P. Kingma and
Jimmy Ba},
 booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
 editor = {Yoshua Bengio and
Yann LeCun},
 title = {Adam: {A} Method for Stochastic Optimization},
 year = {2015}
}

@inproceedings{wen2015semantically,
 author = {Wen, Tsung-Hsien  and
Ga{\v{s}}i{\'c}, Milica  and
Mrk{\v{s}}i{\'c}, Nikola  and
Su, Pei-Hao  and
Vandyke, David  and
Young, Steve},
 booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
 pages = {1711--1721},
 title = {Semantically Conditioned {LSTM}-based Natural Language Generation for Spoken Dialogue Systems},
 year = {2015}
}

@inproceedings{zhang2014chinese,
 author = {Zhang, Xingxing  and
Lapata, Mirella},
 booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})},
 pages = {670--680},
 title = {{C}hinese Poetry Generation with Recurrent Neural Networks},
 year = {2014}
}

@inproceedings{seqgan,
 author = {Lantao Yu and
Weinan Zhang and
Jun Wang and
Yong Yu},
 booktitle = {Proceedings of the Thirty-First {AAAI} Conference on Artificial Intelligence,
February 4-9, 2017, San Francisco, California, {USA}},
 editor = {Satinder P. Singh and
Shaul Markovitch},
 pages = {2852--2858},
 title = {SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient},
 year = {2017}
}
@article{chen2019figcap,
  title={Figure captioning with reasoning and sequence-level training},
  author={Chen, Charles and Zhang, Ruiyi and Koh, Eunyee and Kim, Sungchul and Cohen, Scott and Yu, Tong and Rossi, Ryan and Bunescu, Razvan},
  journal={arXiv preprint arXiv:1906.02850},
  year={2019}
}
@inproceedings{chen2020figcap,
  title={Figure captioning with relation maps for reasoning},
  author={Chen, Charles and Zhang, Ruiyi and Koh, Eunyee and Kim, Sungchul and Cohen, Scott and Rossi, Ryan},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1537--1545},
  year={2020}
}

@inproceedings{masry2022chartqa,
  title={ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning},
  author={Masry, Ahmed and Do, Xuan Long and Tan, Jia Qing and Joty, Shafiq and Hoque, Enamul},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={2263--2279},
  year={2022}
}

@article{Yang2023SciCap+,
  title={SciCap+: A Knowledge Augmented Dataset to Study the Challenges of Scientific Figure Captioning},
  author={Zhishen Yang and Raj Dabre and Hideki Tanaka and Naoaki Okazaki},
  journal={ArXiv},
  year={2023},
  volume={abs/2306.03491},
  url={https://api.semanticscholar.org/CorpusID:259089153}
}
@inproceedings{methani2020plotqa,
  title={Plotqa: Reasoning over scientific plots},
  author={Methani, Nitesh and Ganguly, Pritha and Khapra, Mitesh M and Kumar, Pratyush},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1527--1536},
  year={2020}
}

@inproceedings{kafle2018dvqa,
  title={Dvqa: Understanding data visualizations via question answering},
  author={Kafle, Kushal and Price, Brian and Cohen, Scott and Kanan, Christopher},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5648--5656},
  year={2018}
}

@article{kahou2017figureqa,
  title={Figureqa: An annotated figure dataset for visual reasoning},
  author={Kahou, Samira Ebrahimi and Michalski, Vincent and Atkinson, Adam and K{\'a}d{\'a}r, {\'A}kos and Trischler, Adam and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.07300},
  year={2017}
}


@inproceedings{hsu-etal-2021-scicap-generating,
    title = "{S}ci{C}ap: Generating Captions for Scientific Figures",
    author = "Hsu, Ting-Yao  and
      Giles, C Lee  and
      Huang, Ting-Hao",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.277",
    doi = "10.18653/v1/2021.findings-emnlp.277",
    pages = "3258--3264",
}

@inproceedings{gan2014,
 author = {Ian J. Goodfellow and
Jean Pouget{-}Abadie and
Mehdi Mirza and
Bing Xu and
David Warde{-}Farley and
Sherjil Ozair and
Aaron C. Courville and
Yoshua Bengio},
 booktitle = {Advances in Neural Information Processing Systems 27: Annual Conference
on Neural Information Processing Systems 2014, December 8-13 2014,
Montreal, Quebec, Canada},
 editor = {Zoubin Ghahramani and
Max Welling and
Corinna Cortes and
Neil D. Lawrence and
Kilian Q. Weinberger},
 pages = {2672--2680},
 title = {Generative Adversarial Nets},
 year = {2014}
}

@inproceedings{wang2016chinese,
 author = {Wang, Zhe  and
He, Wei  and
Wu, Hua  and
Wu, Haiyang  and
Li, Wei  and
Wang, Haifeng  and
Chen, Enhong},
 booktitle = {Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers},
 pages = {1051--1060},
 title = {{C}hinese Poetry Generation with Planning based Neural Network},
 year = {2016}
}


@article{2023vlfeedback,
    author      = {Lei Li and Zhihui Xie and Mukai Li and Shunian Chen and Peiyi Wang and Liang Chen and  Yazheng Yang and  Benyou Wang and  Lingpeng Kong},
    title       = {Silkie: Preference Distillation for Large Visual Language Models},
    publisher   = {arXiv:2312.10665},
    year        = {2023}
  }
@inproceedings{drossos2020clotho,
  title={Clotho: An audio captioning dataset},
  author={Drossos, Konstantinos and Lipping, Samuel and Virtanen, Tuomas},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={736--740},
  year={2020},
  organization={IEEE}
}
@InProceedings{webvid,
  author       = "Max Bain and Arsha Nagrani and G{\"u}l Varol and Andrew Zisserman",
  title        = "Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval",
  booktitle    = "IEEE International Conference on Computer Vision",
  year         = "2021",
}
@article{zhao2023chatbridge,
  title={ChatBridge: Bridging Modalities with Large Language Model as a Language Catalyst},
  author={Zhao, Zijia and Guo, Longteng and Yue, Tongtian and Chen, Sihan and Shao, Shuai and Zhu, Xinxin and Yuan, Zehuan and Liu, Jing},
  journal={arXiv preprint arXiv:2305.16103},
  year={2023}
}
@article{chen2023sharegpt4v,
            title={ShareGPT4V: Improving Large Multi-Modal Models with Better Captions},
            author={Chen, Lin and Li, Jisong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
            journal={arXiv preprint arXiv:2311.12793},
            year={2023}
          }

@misc{flux,
        title = {Announcing Black Forest Labs},
        author = {
BlackForestLabs},
        url = {https://blackforestlabs.ai/announcing-black-forest-labs/},
        year = {2024}
    }
      
@misc{visionFlan2023,
        title = {Vision-Flan:Scaling Visual Instruction Tuning},
        url = {https://vision-flan.github.io/},
        author = {Zhiyang Xu and Trevor Ashby and Chao Feng and Rulin Shao and Ying Shen and Di Jin and Qifan Wang and Lifu Huang},
        month = {Sep},
        year = {2023}
    }

@article{Yu2023RLHFVTT,
  author      = {Tianyu Yu and Yuan Yao and Haoye Zhang and Taiwen He and Yifeng Han and Ganqu Cui and Jinyi Hu and Zhiyuan Liu and Hai-Tao Zheng and Maosong Sun and Tat-Seng Chua},
  title       = {RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from Fine-grained Correctional Human Feedback},
  journal      = {arxiv},
  year         = {2023},
}
@inproceedings{yao2018plan,
 author = {Lili Yao and
Nanyun Peng and
Ralph M. Weischedel and
Kevin Knight and
Dongyan Zhao and
Rui Yan},
 booktitle = {The Thirty-Third {AAAI} Conference on Artificial Intelligence, {AAAI}
2019, The Thirty-First Innovative Applications of Artificial Intelligence
Conference, {IAAI} 2019, The Ninth {AAAI} Symposium on Educational
Advances in Artificial Intelligence, {EAAI} 2019, Honolulu, Hawaii,
USA, January 27 - February 1, 2019},
 pages = {7378--7385},
 title = {Plan-and-Write: Towards Better Automatic Storytelling},
 year = {2019}
}
@article{lavit,
  title={Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization},
  author={Jin, Yang and Xu, Kun and Xu, Kun and Chen, Liwei and Liao, Chao and Tan, Jianchao and Mu, Yadong and others},
  journal={arXiv preprint arXiv:2309.04669},
  year={2023}
}

@article{video-lavit,
  title={Video-LaVIT: Unified Video-Language Pre-training with Decoupled Visual-Motional Tokenization},
  author={Jin, Yang and Sun, Zhicheng and Xu, Kun and Chen, Liwei and Jiang, Hao and Huang, Quzhe and Song, Chengru and Liu, Yuliang and Zhang, Di and Song, Yang and others},
  journal={arXiv preprint arXiv:2402.03161},
  year={2024}
}
@misc{amused,
      title={aMUSEd: An Open MUSE Reproduction}, 
      author={Suraj Patil and William Berman and Robin Rombach and Patrick von Platen},
      year={2024},
      eprint={2401.01808},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{vit,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@inproceedings{skeleton,
 author = {Xu, Jingjing  and
Ren, Xuancheng  and
Zhang, Yi  and
Zeng, Qi  and
Cai, Xiaoyan  and
Sun, Xu},
 booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
 pages = {4306--4315},
 title = {A Skeleton-Based Model for Promoting Coherence Among Sentences in Narrative Story Generation},
 year = {2018}
}

@inproceedings{bleu,
 author = {Papineni, Kishore  and
Roukos, Salim  and
Ward, Todd  and
Zhu, Wei-Jing},
 booktitle = {Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics},
 pages = {311--318},
 title = {{B}leu: a Method for Automatic Evaluation of Machine Translation},
 year = {2002}
}

@inproceedings{kim2014convolutional,
 author = {Kim, Yoon},
 booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})},
 pages = {1746--1751},
 title = {Convolutional Neural Networks for Sentence Classification},
 year = {2014}
}

@inproceedings{sutton2000policy,
 author = {Richard S. Sutton and
David A. McAllester and
Satinder P. Singh and
Yishay Mansour},
 booktitle = {{Advances in Neural Information Processing Systems 12: Annual Conference
on Neural Information Processing Systems 1999}},
 pages = {1057--1063},
 title = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
 year = {1999}
}

@article{williams1992simple,
 author = {Ronald J. Williams},
 journal = {Machine Learning},
 pages = {229--256},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 volume = {8},
 year = {1992}
}

@inproceedings{sukhbaatar2015end,
 author = {Sainbayar Sukhbaatar and
Arthur Szlam and
Jason Weston and
Rob Fergus},
 booktitle = {Advances in Neural Information Processing Systems 28: Annual Conference
on Neural Information Processing Systems 2015, December 7-12, 2015,
Montreal, Quebec, Canada},
 editor = {Corinna Cortes and
Neil D. Lawrence and
Daniel D. Lee and
Masashi Sugiyama and
Roman Garnett},
 pages = {2440--2448},
 title = {End-To-End Memory Networks},
 year = {2015}
}

@inproceedings{feng2018topic,
 author = {Xiaocheng Feng and
Ming Liu and
Jiahao Liu and
Bing Qin and
Yibo Sun and
Ting Liu},
 booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
Artificial Intelligence, {IJCAI} 2018, July 13-19, 2018, Stockholm,
Sweden},
 editor = {J{\'{e}}r{\^{o}}me Lang},
 pages = {4078--4084},
 title = {Topic-to-Essay Generation with Neural Networks},
 year = {2018}
}

@inproceedings{sutskever2014sequence,
 author = {Ilya Sutskever and
Oriol Vinyals and
Quoc V. Le},
 booktitle = {Advances in Neural Information Processing Systems 27: Annual Conference
on Neural Information Processing Systems 2014, December 8-13 2014,
Montreal, Quebec, Canada},
 editor = {Zoubin Ghahramani and
Max Welling and
Corinna Cortes and
Neil D. Lawrence and
Kilian Q. Weinberger},
 pages = {3104--3112},
 title = {Sequence to Sequence Learning with Neural Networks},
 year = {2014}
}

@inproceedings{song2018directional,
 author = {Song, Yan  and
Shi, Shuming  and
Li, Jing  and
Zhang, Haisong},
 booktitle = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},
 pages = {175--180},
 title = {Directional Skip-Gram: Explicitly Distinguishing Left and Right Context for Word Embeddings},
 year = {2018}
}

@inproceedings{bahdanau2014neural,
 author = {Dzmitry Bahdanau and
Kyunghyun Cho and
Yoshua Bengio},
 booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
 editor = {Yoshua Bengio and
Yann LeCun},
 title = {Neural Machine Translation by Jointly Learning to Align and Translate},
 year = {2015}
}

@inproceedings{rush2015neural,
 author = {Rush, Alexander M.  and
Chopra, Sumit  and
Weston, Jason},
 booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
 pages = {379--389},
 title = {A Neural Attention Model for Abstractive Sentence Summarization},
 year = {2015}
}

@inproceedings{tosa2008hitch,
 author = {Naoko Tosa and
Hideto Obara and
Michihiko Minoh},
 booktitle = {{Entertainment Computing - {ICEC} 2008, 7th International Conference}},
 pages = {209--216},
 title = {Hitch Haiku: An Interactive Supporting System for Composing Haiku
Poem},
 volume = {5309},
 year = {2008}
}

@inproceedings{yan2016poet,
 author = {Rui Yan},
 booktitle = {Proceedings of the Twenty-Fifth International Joint Conference on
Artificial Intelligence, {IJCAI} 2016, New York, NY, USA, 9-15 July
2016},
 editor = {Subbarao Kambhampati},
 pages = {2238--2244},
 title = {i, Poet: Automatic Poetry Composition through Recurrent Neural Networks
with Iterative Polishing Schema},
 year = {2016}
}

@inproceedings{zhang2017flexible,
 author = {Zhang, Jiyuan  and
Feng, Yang  and
Wang, Dong  and
Wang, Yang  and
Abel, Andrew  and
Zhang, Shiyue  and
Zhang, Andi},
 booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
 pages = {1364--1373},
 title = {Flexible and Creative {C}hinese Poetry Generation Using Neural Memory},
 year = {2017}
}

@inproceedings{yang2018generating,
 author = {Xiaopeng Yang and
Xiaowen Lin and
Shunda Suo and
Ming Li},
 booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
Artificial Intelligence, {IJCAI} 2018, July 13-19, 2018, Stockholm,
Sweden},
 editor = {J{\'{e}}r{\^{o}}me Lang},
 pages = {4539--4545},
 title = {Generating Thematic Chinese Poetry using Conditional Variational Autoencoders
with Hybrid Decoders},
 year = {2018}
}

@inproceedings{yi2018automatic,
 author = {Yi, Xiaoyuan  and
Sun, Maosong  and
Li, Ruoyu  and
Li, Wenhao},
 booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
 pages = {3143--3153},
 title = {Automatic Poetry Generation with Mutual Reinforcement Learning},
 year = {2018}
}

@inproceedings{li2018cvae,
 author = {Li, Juntao  and
Song, Yan  and
Zhang, Haisong  and
Chen, Dongmin  and
Shi, Shuming  and
Zhao, Dongyan  and
Yan, Rui},
 booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
 pages = {3890--3900},
 title = {Generating Classical {C}hinese Poems via Conditional Variational Autoencoder and Adversarial Training},
 year = {2018}
}

@inproceedings{lewis2018hierarchical,
 author = {Fan, Angela  and
Lewis, Mike  and
Dauphin, Yann},
 booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
 pages = {889--898},
 title = {Hierarchical Neural Story Generation},
 year = {2018}
}

@article{jain2017story,
 author = {Jain, Parag and Agrawal, Priyanka and Mishra, Abhijit and Sukhwani, Mohak and Laha, Anirban and Sankaranarayanan, Karthik},
 journal = {ArXiv preprint},
 title = {Story generation from sequence of independent short descriptions},
 volume = {abs/1707.05501},
 year = {2017}
}
@article{peng2022beit,
  title   = {BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers},
  author  = {Zhiliang Peng and Li Dong and Hangbo Bao and Qixiang Ye and Furu Wei},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2208.06366}
}

@inproceedings{yan2013poet,
 author = {Rui Yan and
Han Jiang and
Mirella Lapata and
Shou{-}De Lin and
Xueqiang Lv and
Xiaoming Li},
 booktitle = {{IJCAI} 2013, Proceedings of the 23rd International Joint Conference
on Artificial Intelligence, Beijing, China, August 3-9, 2013},
 editor = {Francesca Rossi},
 pages = {2197--2203},
 title = {i, Poet: Automatic Chinese Poetry Composition through a Generative
Summarization Framework under Constrained Optimization},
 year = {2013}
}

@inproceedings{speer2012representing,
 author = {Speer, Robyn  and
Havasi, Catherine},
 booktitle = {Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12)},
 pages = {3679--3686},
 title = {Representing General Relational Knowledge in {C}oncept{N}et 5},
 year = {2012}
}

@article{lstm,
 author = {Sepp Hochreiter and
J{\"{u}}rgen Schmidhuber},
 journal = {Neural Computation},
 number = {8},
 pages = {1735--1780},
 title = {Long Short-Term Memory},
 volume = {9},
 year = {1997}
}

@article{srivastava2015highway,
 author = {Srivastava, Rupesh Kumar and Greff, Klaus and Schmidhuber, J{\"u}rgen},
 journal = {ArXiv preprint},
 title = {Highway networks},
 volume = {abs/1505.00387},
 year = {2015}
}
@article{laion5b,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}

@misc{ldm,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.10752}, 
}

@inproceedings{li2015diversity,
 author = {Li, Jiwei  and
Galley, Michel  and
Brockett, Chris  and
Gao, Jianfeng  and
Dolan, Bill},
 booktitle = {Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
 pages = {110--119},
 title = {A Diversity-Promoting Objective Function for Neural Conversation Models},
 year = {2016}
}

@inproceedings{newswritting,
 author = {Lepp{\"a}nen, Leo  and
Munezero, Myriam  and
Granroth-Wilding, Mark  and
Toivonen, Hannu},
 booktitle = {Proceedings of the 10th International Conference on Natural Language Generation},
 pages = {188--197},
 title = {Data-Driven News Generation for Automated Journalism},
 year = {2017}
}

@inproceedings{wang2018sentigan,
 author = {Ke Wang and
Xiaojun Wan},
 booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
Artificial Intelligence, {IJCAI} 2018, July 13-19, 2018, Stockholm,
Sweden},
 editor = {J{\'{e}}r{\^{o}}me Lang},
 pages = {4446--4452},
 title = {SentiGAN: Generating Sentimental Texts via Mixture Adversarial Networks},
 year = {2018}
}

@article{dropout,
 author = {Nitish Srivastava and
Geoffrey E. Hinton and
Alex Krizhevsky and
Ilya Sutskever and
Ruslan Salakhutdinov},
 journal = {Journal of Machine Learning Research},
 number = {1},
 pages = {1929--1958},
 title = {Dropout: a simple way to prevent neural networks from overfitting},
 volume = {15},
 year = {2014}
}

@inproceedings{gradientclip,
 author = {Razvan Pascanu and
Tom{\'{a}}s Mikolov and
Yoshua Bengio},
 booktitle = {Proceedings of the 30th International Conference on Machine Learning,
{ICML} 2013, Atlanta, GA, USA, 16-21 June 2013},
 pages = {1310--1318},
 series = {{JMLR} Workshop and Conference Proceedings},
 title = {On the difficulty of training recurrent neural networks},
 volume = {28},
 year = {2013}
}

@inproceedings{yang2018sgm,
 author = {Yang, Pengcheng  and
Sun, Xu  and
Li, Wei  and
Ma, Shuming  and
Wu, Wei  and
Wang, Houfeng},
 booktitle = {Proceedings of the 27th International Conference on Computational Linguistics},
 pages = {3915--3926},
 title = {{SGM}: Sequence Generation Model for Multi-label Classification},
 year = {2018}
}

@article{clement2019use,
  title={On the use of arxiv as a dataset},
  author={Clement, Colin B and Bierbaum, Matthew and O'Keeffe, Kevin P and Alemi, Alexander A},
  journal={arXiv preprint arXiv:1905.00075},
  year={2019}
}

@misc{arxiv.org_submitters_2023,
    title={arXiv Dataset},
    url={https://www.kaggle.com/dsv/6947474},
    DOI={10.34740/KAGGLE/DSV/6947474},
    publisher={Kaggle},
    author={arXiv.org submitters},
    year={2023}
}

@misc{hu2023mplugpaperowl,
      title={mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large Language Model}, 
      author={Anwen Hu and Yaya Shi and Haiyang Xu and Jiabo Ye and Qinghao Ye and Ming Yan and Chenliang Li and Qi Qian and Ji Zhang and Fei Huang},
      year={2023},
      eprint={2311.18248},
      archivePrefix={arXiv},
      primaryClass={cs.MM}
}

@software{imagemagick,
  author = {{ImageMagick Studio LLC}},
  title = {ImageMagick},
  url = {https://imagemagick.org},
  version = {7.0.10},
  date = {2023-01-04},
}

@misc{zhang2024mathverse,
      title={MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?}, 
      author={Renrui Zhang and Dongzhi Jiang and Yichi Zhang and Haokun Lin and Ziyu Guo and Pengshuo Qiu and Aojun Zhou and Pan Lu and Kai-Wei Chang and Peng Gao and Hongsheng Li},
      year={2024},
      eprint={2403.14624},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{kinney2023semantic,
      title={The Semantic Scholar Open Data Platform}, 
      author={Rodney Kinney and Chloe Anastasiades and Russell Authur and Iz Beltagy and Jonathan Bragg and Alexandra Buraczynski and Isabel Cachola and Stefan Candra and Yoganand Chandrasekhar and Arman Cohan and Miles Crawford and Doug Downey and Jason Dunkelberger and Oren Etzioni and Rob Evans and Sergey Feldman and Joseph Gorney and David Graham and Fangzhou Hu and Regan Huff and Daniel King and Sebastian Kohlmeier and Bailey Kuehl and Michael Langan and Daniel Lin and Haokun Liu and Kyle Lo and Jaron Lochner and Kelsey MacMillan and Tyler Murray and Chris Newell and Smita Rao and Shaurya Rohatgi and Paul Sayre and Zejiang Shen and Amanpreet Singh and Luca Soldaini and Shivashankar Subramanian and Amber Tanaka and Alex D. Wade and Linda Wagner and Lucy Lu Wang and Chris Wilhelm and Caroline Wu and Jiangjiang Yang and Angele Zamarron and Madeleine Van Zuylen and Daniel S. Weld},
      year={2023},
      eprint={2301.10140},
      archivePrefix={arXiv},
      primaryClass={cs.DL}
}
@article{audioldm,
  title   = {AudioLDM: Text-to-Audio Generation with Latent Diffusion Models},
  author  = {Haohe Liu and Zehua Chen and Yi Yuan and Xinhao Mei and Xubo Liu and Danilo Mandic and Wenwu Wang and Mark D. Plumbley},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2301.12503}
}
@article{dreamllm,
  title   = {DreamLLM: Synergistic Multimodal Comprehension and Creation},
  author  = {Runpei Dong and Chunrui Han and Yuang Peng and Zekun Qi and Zheng Ge and Jinrong Yang and Liang Zhao and Jianjian Sun and Hongyu Zhou and Haoran Wei and Xiangwen Kong and Xiangyu Zhang and Kaisheng Ma and Li Yi},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2309.11499}
}
# MaskGIT
 @article{MaskGIT,  
 title={MaskGIT: Masked Generative Image Transformer}, 
 author={Chang, Huiwen and Zhang, Han and Jiang, Lu and Liu, Ce and Freeman, T and Research, Google}, 
 language={en-US} 
 }

 @inproceedings{Rombach_Blattmann_Lorenz_Esser_Ommer_2022,  
 title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
 url={http://dx.doi.org/10.1109/cvpr52688.2022.01042}, 
 DOI={10.1109/cvpr52688.2022.01042}, 
 booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
 author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bjorn}, 
 year={2022}, 
 month={Jun}, 
 language={en-US} 
 }
# LSQ
@misc{yu2023language,
      title={Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation}, 
      author={Lijun Yu and José Lezama and Nitesh B. Gundavarapu and Luca Versari and Kihyuk Sohn and David Minnen and Yong Cheng and Agrim Gupta and Xiuye Gu and Alexander G. Hauptmann and Boqing Gong and Ming-Hsuan Yang and Irfan Essa and David A. Ross and Lu Jiang},
      year={2023},
      eprint={2310.05737},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@incollection{imagetransfer,
  title={Image quilting for texture synthesis and transfer},
  author={Efros, Alexei A and Freeman, William T},
  booktitle={Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
  pages={571--576},
  year={2023}
}
#RQVAE
@misc{lee2022RQVAE,
      title={Autoregressive Image Generation using Residual Quantization}, 
      author={Doyup Lee and Chiheon Kim and Saehoon Kim and Minsu Cho and Wook-Shin Han},
      year={2022},
      eprint={2203.01941},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{imagetransfer2,
  title={Using deep transfer learning for image-based plant disease identification},
  author={Chen, Junde and Chen, Jinxiu and Zhang, Defu and Sun, Yuandong and Nanehkaran, Yaser Ahangari},
  journal={Computers and Electronics in Agriculture},
  volume={173},
  pages={105393},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{text2image1,
  title={Towards language-free training for text-to-image generation},
  author={Zhou, Yufan and Zhang, Ruiyi and Chen, Changyou and Li, Chunyuan and Tensmeyer, Chris and Yu, Tong and Gu, Jiuxiang and Xu, Jinhui and Sun, Tong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17907--17917},
  year={2022}
}

@article{parti,
  title={Scaling autoregressive models for content-rich text-to-image generation},
  author={Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and others},
  journal={arXiv preprint arXiv:2206.10789},
  volume={2},
  number={3},
  pages={5},
  year={2022},
  publisher={Jun}
}

@article{imagetrival,
  title={Deep graph-based multimodal feature embedding for endomicroscopy image retrieval},
  author={Gu, Yun and Vyas, Khushi and Shen, Mali and Yang, Jie and Yang, Guang-Zhong},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  volume={32},
  number={2},
  pages={481--492},
  year={2020},
  publisher={IEEE}
}

@article{imagecaption1,
  title={From show to tell: A survey on deep learning-based image captioning},
  author={Stefanini, Matteo and Cornia, Marcella and Baraldi, Lorenzo and Cascianelli, Silvia and Fiameni, Giuseppe and Cucchiara, Rita},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={45},
  number={1},
  pages={539--559},
  year={2022},
  publisher={IEEE}
}

@article{vqa1,
  title={Visual question answering: a state-of-the-art review},
  author={Manmadhan, Sruthy and Kovoor, Binsu C},
  journal={Artificial Intelligence Review},
  volume={53},
  pages={5705--5745},
  year={2020},
  publisher={Springer}
}

@article{speechre,
  title={Automatic speech recognition: a survey},
  author={Malik, Mishaim and Malik, Muhammad Kamran and Mehmood, Khawar and Makhdoom, Imran},
  journal={Multimedia Tools and Applications},
  volume={80},
  pages={9411--9457},
  year={2021},
  publisher={Springer}
}

@article{text2audio,
  title={Audioldm: Text-to-audio generation with latent diffusion models},
  author={Liu, Haohe and Chen, Zehua and Yuan, Yi and Mei, Xinhao and Liu, Xubo and Mandic, Danilo and Wang, Wenwu and Plumbley, Mark D},
  journal={arXiv preprint arXiv:2301.12503},
  year={2023}
}

@article{musicgeneration,
  title={A comprehensive survey on deep music generation: Multi-level representations, algorithms, evaluations, and future directions},
  author={Ji, Shulei and Luo, Jing and Yang, Xinyu},
  journal={arXiv preprint arXiv:2011.06801},
  year={2020}
}

@inproceedings{multimodalmusicre,
  title={Enhancing music recommendation with social media content: an attentive multimodal autoencoder approach},
  author={Shen, Tiancheng and Jia, Jia and Li, Yan and Wang, Hanjie and Chen, Bo},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2020},
  organization={IEEE}
}

@article{videogenerate,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}

@inproceedings{videocaption,
  title={Multi-modal dense video captioning},
  author={Iashin, Vladimir and Rahtu, Esa},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={958--959},
  year={2020}
}


@article{multimodal3Ddetect,
  title={Multimodal virtual point 3d detection},
  author={Yin, Tianwei and Zhou, Xingyi and Kr{\"a}henb{\"u}hl, Philipp},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={16494--16507},
  year={2021}
}
#cm3leon
@misc{cm3leon,
      title={Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning}, 
      author={Lili Yu and Bowen Shi and Ramakanth Pasunuru and Benjamin Muller and Olga Golovneva and Tianlu Wang and Arun Babu and Binh Tang and Brian Karrer and Shelly Sheynin and Candace Ross and Adam Polyak and Russell Howes and Vasu Sharma and Puxin Xu and Hovhannes Tamoyan and Oron Ashual and Uriel Singer and Shang-Wen Li and Susan Zhang and Richard James and Gargi Ghosh and Yaniv Taigman and Maryam Fazel-Zarandi and Asli Celikyilmaz and Luke Zettlemoyer and Armen Aghajanyan},
      year={2023},
      eprint={2309.02591},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
# cogview2
 @article{CogView2,  
 title={CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers}, 
 author={Ding, Ming and Zheng, Wendi and Hong, Wenyi and Tang, Jie}, 
 language={en-US} 
 }
# cogview
 @article{CogView,  
 title={CogView: Mastering Text-to-Image Generation via Transformers}, 
 journal={Neural Information Processing Systems,Neural Information Processing Systems}, 
 author={Ding, Ming and Yang, Zhuoyi and Hong, Wenyi and Zheng, Wendi and Zhou, Chang and Yin, Dong and Lin, Junyang and Zou, Xu and Shao, Zhou and Yang, Hongxia and Tang, Jie}, 
 year={2021}, 
 month={Dec}, 
 language={en-US} 
 }


@misc{fu2023mme,
  title         = {MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models},
  author        = {Chaoyou Fu and Peixian Chen and Yunhang Shen and Yulei Qin and Mengdan Zhang and Xu Lin and Jinrui Yang and Xiawu Zheng and Ke Li and Xing Sun and Yunsheng Wu and Rongrong Ji},
  year          = {2023},
  eprint        = {2306.13394},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{liu2023mmbench,
  title         = {MMBench: Is Your Multi-modal Model an All-around Player?},
  author        = {Yuan Liu and Haodong Duan and Yuanhan Zhang and Bo Li and Songyang Zhang and Wangbo Zhao and Yike Yuan and Jiaqi Wang and Conghui He and Ziwei Liu and Kai Chen and Dahua Lin},
  year          = {2023},
  eprint        = {2307.06281},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@article{seedllama,
  title={Making LLaMA SEE and Draw with SEED Tokenizer},
  author={Ge, Yuying and Zhao, Sijie and Zeng, Ziyun and Ge, Yixiao and Li, Chen and Wang, Xintao and Shan, Ying},
  journal={arXiv preprint arXiv:2310.01218},
  year={2023}
}

@article{seed-tokenizer,
  title={Planting a seed of vision in large language model},
  author={Ge, Yuying and Ge, Yixiao and Zeng, Ziyun and Wang, Xintao and Shan, Ying},
  journal={arXiv preprint arXiv:2307.08041},
  year={2023}
}

@misc{li2023seedbench,
  title         = {SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension},
  author        = {Bohao Li and Rui Wang and Guangzhi Wang and Yuying Ge and Yixiao Ge and Ying Shan},
  year          = {2023},
  eprint        = {2307.16125},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{li2023seedbench2,
  title         = {SEED-Bench-2: Benchmarking Multimodal Large Language Models},
  author        = {Bohao Li and Yuying Ge and Yixiao Ge and Guangzhi Wang and Rui Wang and Ruimao Zhang and Ying Shan},
  year          = {2023},
  eprint        = {2311.17092},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{yue2023mmmu,
  title         = {MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI},
  author        = {Xiang Yue and Yuansheng Ni and Kai Zhang and Tianyu Zheng and Ruoqi Liu and Ge Zhang and Samuel Stevens and Dongfu Jiang and Weiming Ren and Yuxuan Sun and Cong Wei and Botao Yu and Ruibin Yuan and Renliang Sun and Ming Yin and Boyuan Zheng and Zhenzhu Yang and Yibo Liu and Wenhao Huang and Huan Sun and Yu Su and Wenhu Chen},
  year          = {2023},
  eprint        = {2311.16502},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{ge2023mllmbench,
  title         = {MLLM-Bench, Evaluating Multi-modal LLMs using GPT-4V},
  author        = {Wentao Ge and Shunian Chen and Guiming Chen and Junying Chen and Zhihong Chen and Shuo Yan and Chenghao Zhu and Ziyue Lin and Wenya Xie and Xidong Wang and Anningzhe Gao and Zhiyi Zhang and Jianquan Li and Xiang Wan and Benyou Wang},
  year          = {2023},
  eprint        = {2311.13951},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{li2024mvbench,
  title         = {MVBench: A Comprehensive Multi-modal Video Understanding Benchmark},
  author        = {Kunchang Li and Yali Wang and Yinan He and Yizhuo Li and Yi Wang and Yi Liu and Zun Wang and Jilan Xu and Guo Chen and Ping Luo and Limin Wang and Yu Qiao},
  year          = {2024},
  eprint        = {2311.17005},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{huang2023vbench,
  title         = {VBench: Comprehensive Benchmark Suite for Video Generative Models},
  author        = {Ziqi Huang and Yinan He and Jiashuo Yu and Fan Zhang and Chenyang Si and Yuming Jiang and Yuanhan Zhang and Tianxing Wu and Qingyang Jin and Nattapol Chanpaisit and Yaohui Wang and Xinyuan Chen and Limin Wang and Dahua Lin and Yu Qiao and Ziwei Liu},
  year          = {2023},
  eprint        = {2311.17982},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{huang2023sparkles,
  title         = {Sparkles: Unlocking Chats Across Multiple Images for Multimodal Instruction-Following Models},
  author        = {Yupan Huang and Zaiqiao Meng and Fangyu Liu and Yixuan Su and Nigel Collier and Yutong Lu},
  year          = {2023},
  eprint        = {2308.16463},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{lu2024mathvista,
  title         = {MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts},
  author        = {Pan Lu and Hritik Bansal and Tony Xia and Jiacheng Liu and Chunyuan Li and Hannaneh Hajishirzi and Hao Cheng and Kai-Wei Chang and Michel Galley and Jianfeng Gao},
  year          = {2024},
  eprint        = {2310.02255},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{guan2024hallusionbench,
  title         = {HallusionBench: An Advanced Diagnostic Suite for Entangled Language Hallucination and Visual Illusion in Large Vision-Language Models},
  author        = {Tianrui Guan and Fuxiao Liu and Xiyang Wu and Ruiqi Xian and Zongxia Li and Xiaoyu Liu and Xijun Wang and Lichang Chen and Furong Huang and Yaser Yacoob and Dinesh Manocha and Tianyi Zhou},
  year          = {2024},
  eprint        = {2310.14566},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@misc{cui2023holistic,
  title         = {Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges},
  author        = {Chenhang Cui and Yiyang Zhou and Xinyu Yang and Shirley Wu and Linjun Zhang and James Zou and Huaxiu Yao},
  year          = {2023},
  eprint        = {2311.03287},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{liu2023mmc,
  title         = {MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning},
  author        = {Fuxiao Liu and Xiaoyang Wang and Wenlin Yao and Jianshu Chen and Kaiqiang Song and Sangwoo Cho and Yaser Yacoob and Dong Yu},
  year          = {2023},
  eprint        = {2311.10774},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{cai2023benchlmm,
  title         = {BenchLMM: Benchmarking Cross-style Visual Capability of Large Multimodal Models},
  author        = {Rizhao Cai and Zirui Song and Dayan Guan and Zhenhao Chen and Xing Luo and Chenyu Yi and Alex Kot},
  year          = {2023},
  eprint        = {2312.02896},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{wu2024better,
  title         = {Towards A Better Metric for Text-to-Video Generation},
  author        = {Jay Zhangjie Wu and Guian Fang and Haoning Wu and Xintao Wang and Yixiao Ge and Xiaodong Cun and David Junhao Zhang and Jia-Wei Liu and Yuchao Gu and Rui Zhao and Weisi Lin and Wynne Hsu and Ying Shan and Mike Zheng Shou},
  year          = {2024},
  eprint        = {2401.07781},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}


@inproceedings{lvpm3,
    title = "{LVP}-{M}3: Language-aware Visual Prompt for Multilingual Multimodal Machine Translation",
    author = "Guo, Hongcheng  and
      Liu, Jiaheng  and
      Huang, Haoyang  and
      Yang, Jian  and
      Li, Zhoujun  and
      Zhang, Dongdong  and
      Cui, Zheng",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    year = "2022",
    publisher = "Association for Computational Linguistics",
    pages = "2862--2872",
}

@misc{zhang2024benchmarking,
  title         = {Benchmarking Large Multimodal Models against Common Corruptions},
  author        = {Jiawei Zhang and Tianyu Pang and Chao Du and Yi Ren and Bo Li and Min Lin},
  year          = {2024},
  eprint        = {2401.11943},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{zhang2024cmmmu,
  title         = {CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark},
  author        = {Ge Zhang and Xinrun Du and Bei Chen and Yiming Liang and Tongxu Luo and Tianyu Zheng and Kang Zhu and Yuyang Cheng and Chunpu Xu and Shuyue Guo and Haoran Zhang and Xingwei Qu and Junjie Wang and Ruibin Yuan and Yizhi Li and Zekun Wang and Yudong Liu and Yu-Hsuan Tsai and Fengji Zhang and Chenghua Lin and Wenhao Huang and Wenhu Chen and Jie Fu},
  year          = {2024},
  eprint        = {2401.11944},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
@article{coca,
  author    = {Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu},
  title     = {CoCa: Contrastive Captioners are Image-Text Foundation Models},
  journal   = {Trans. Mach. Learn. Res.},
  volume    = {2022},
  year      = {2022},
  url       = {https://openreview.net/forum?id=Ee277P3AYC},
  timestamp = {Fri, 19 May 2023 11:20:41 +0200},
  biburl    = {https://dblp.org/rec/journals/tmlr/YuWVYSW22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{wang2024measuring,
  title         = {Measuring Multimodal Mathematical Reasoning with MATH-Vision Dataset},
  author        = {Ke Wang and Junting Pan and Weikang Shi and Zimu Lu and Mingjie Zhan and Hongsheng Li},
  year          = {2024},
  eprint        = {2402.14804},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@article{imu2clip,
  title   = {IMU2CLIP: Multimodal Contrastive Learning for IMU Motion Sensors from Egocentric Videos and Text},
  author  = {Seungwhan Moon and Andrea Madotto and Zhaojiang Lin and Alireza Dirafzoon and Aparajita Saraf and Amy Bearman and Babak Damavandi},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2210.14395}
}
@misc{cha2024visually,
  title         = {Visually Dehallucinative Instruction Generation: Know What You Don't Know},
  author        = {Sungguk Cha and Jusung Lee and Younghyun Lee and Cheoljong Yang},
  year          = {2024},
  eprint        = {2402.09717},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{liu2024tempcompass,
  title         = {TempCompass: Do Video LLMs Really Understand Videos?},
  author        = {Yuanxin Liu and Shicheng Li and Yi Liu and Yuxiang Wang and Shuhuai Ren and Lei Li and Sishuo Chen and Xu Sun and Lu Hou},
  year          = {2024},
  eprint        = {2403.00476},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{musicgeneration,
  title={Efficient neural music generation},
  author={Lam, Max WY and Tian, Qiao and Li, Tang and Yin, Zongyu and Feng, Siyuan and Tu, Ming and Ji, Yuliang and Xia, Rui and Ma, Mingbo and Song, Xuchen and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{videounderstand,
  title={Internvid: A large-scale video-text dataset for multimodal understanding and generation},
  author={Wang, Yi and He, Yinan and Li, Yizhuo and Li, Kunchang and Yu, Jiashuo and Ma, Xin and Li, Xinhao and Chen, Guo and Chen, Xinyuan and Wang, Yaohui and others},
  journal={arXiv preprint arXiv:2307.06942},
  year={2023}
}

@article{audiotovideo,
  title={PADVG: A Simple Baseline of Active Protection for Audio-driven Video Generation},
  author={Liu, Huan and Liu, Xiaolong and Tan, Zichang and Li, Xiaolong and Zhao, Yao},
  journal={ACM Transactions on Multimedia Computing, Communications and Applications},
  year={2024},
  publisher={ACM New York, NY}
}

@article{3dgenera1,
  title={3D point cloud generation with millimeter-wave radar},
  author={Qian, Kun and He, Zhaoyuan and Zhang, Xinyu},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={4},
  number={4},
  pages={1--23},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{embodiedgpt,
  title={Embodiedgpt: Vision-language pre-training via embodied chain of thought},
  author={Mu, Yao and Zhang, Qinglong and Hu, Mengkang and Wang, Wenhai and Ding, Mingyu and Jin, Jun and Wang, Bin and Dai, Jifeng and Qiao, Yu and Luo, Ping},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{agentai,
  title={Agent ai: Surveying the horizons of multimodal interaction},
  author={Durante, Zane and Huang, Qiuyuan and Wake, Naoki and Gong, Ran and Park, Jae Sung and Sarkar, Bidipta and Taori, Rohan and Noda, Yusuke and Terzopoulos, Demetri and Choi, Yejin and others},
  journal={arXiv preprint arXiv:2401.03568},
  year={2024}
}

@article{emboieddecision,
  title={Towards end-to-end embodied decision making via multi-modal large language model: Explorations with gpt4-vision and beyond},
  author={Chen, Liang and Zhang, Yichi and Ren, Shuhuai and Zhao, Haozhe and Cai, Zefan and Wang, Yuchi and Wang, Peiyi and Liu, Tianyu and Chang, Baobao},
  journal={arXiv preprint arXiv:2310.02071},
  year={2023}
}
@misc{rolfe2017discrete,
      title={Discrete Variational Autoencoders}, 
      author={Jason Tyler Rolfe},
      year={2017},
      eprint={1609.02200},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@article{humanoid,
  title={Humanoid Locomotion as Next Token Prediction},
  author={Radosavovic, Ilija and Zhang, Bike and Shi, Baifeng and Rajasegaran, Jathushan and Kamat, Sarthak and Darrell, Trevor and Sreenath, Koushil and Malik, Jitendra},
  journal={arXiv preprint arXiv:2402.19469},
  year={2024}
}
@article{lucas2019don,
  title={Don't blame the elbo! a linear vae perspective on posterior collapse},
  author={Lucas, James and Tucker, George and Grosse, Roger B and Norouzi, Mohammad},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


Chain-of-Thought Prompting
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}
@article{zhang2023multimodal,
  title={Multimodal chain-of-thought reasoning in language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Zhao, Hai and Karypis, George and Smola, Alex},
  journal={arXiv preprint arXiv:2302.00923},
  year={2023}
}
@article{shao2024visual,
  title={Visual CoT: Unleashing Chain-of-Thought Reasoning in Multi-Modal Language Models},
  author={Shao, Hao and Qian, Shengju and Xiao, Han and Song, Guanglu and Zong, Zhuofan and Wang, Letian and Liu, Yu and Li, Hongsheng},
  journal={arXiv preprint arXiv:2403.16999},
  year={2024}
}
@article{mitra2023compositional,
  title={Compositional chain-of-thought prompting for large multimodal models},
  author={Mitra, Chancharik and Huang, Brandon and Darrell, Trevor and Herzig, Roei},
  journal={arXiv preprint arXiv:2311.17076},
  year={2023}
}


@misc{lu2023chameleon,
      title={Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models}, 
      author={Pan Lu and Baolin Peng and Hao Cheng and Michel Galley and Kai-Wei Chang and Ying Nian Wu and Song-Chun Zhu and Jianfeng Gao},
      year={2023},
      eprint={2304.09842},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{yu2023efficient,
      title={Efficient In-Context Learning in Vision-Language Models for Egocentric Videos}, 
      author={Keunwoo Peter Yu and Zheyuan Zhang and Fengyuan Hu and Joyce Chai},
      year={2023},
      eprint={2311.17041},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zeng2024mllms,
      title={Can MLLMs Perform Text-to-Image In-Context Learning?}, 
      author={Yuchen Zeng and Wonjun Kang and Yicong Chen and Hyung Il Koo and Kangwook Lee},
      year={2024},
      eprint={2402.01293},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{zhou2024visual,
      title={Visual In-Context Learning for Large Vision-Language Models}, 
      author={Yucheng Zhou and Xiang Li and Qianning Wang and Jianbing Shen},
      year={2024},
      eprint={2402.11574},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{sun2024generative,
      title={Generative Multimodal Models are In-Context Learners}, 
      author={Quan Sun and Yufeng Cui and Xiaosong Zhang and Fan Zhang and Qiying Yu and Zhengxiong Luo and Yueze Wang and Yongming Rao and Jingjing Liu and Tiejun Huang and Xinlong Wang},
      year={2024},
      eprint={2312.13286},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{jeong2024hijacking,
      title={Hijacking Context in Large Multi-modal Models}, 
      author={Joonhyun Jeong},
      year={2024},
      eprint={2312.07553},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{sheng2024unified,
      title={Towards More Unified In-context Visual Understanding}, 
      author={Dianmo Sheng and Dongdong Chen and Zhentao Tan and Qiankun Liu and Qi Chu and Jianmin Bao and Tao Gong and Bin Liu and Shengwei Xu and Nenghai Yu},
      year={2024},
      eprint={2312.02520},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{tai2023linkcontext,
      title={Link-Context Learning for Multimodal LLMs}, 
      author={Yan Tai and Weichen Fan and Zhao Zhang and Feng Zhu and Rui Zhao and Ziwei Liu},
      year={2023},
      eprint={2308.07891},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{awadalla2023openflamingo,
      title={OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models}, 
      author={Anas Awadalla and Irena Gao and Josh Gardner and Jack Hessel and Yusuf Hanafy and Wanrong Zhu and Kalyani Marathe and Yonatan Bitton and Samir Gadre and Shiori Sagawa and Jenia Jitsev and Simon Kornblith and Pang Wei Koh and Gabriel Ilharco and Mitchell Wortsman and Ludwig Schmidt},
      year={2023},
      eprint={2308.01390},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{moor2023medflamingo,
      title={Med-Flamingo: a Multimodal Medical Few-shot Learner}, 
      author={Michael Moor and Qian Huang and Shirley Wu and Michihiro Yasunaga and Cyril Zakka and Yash Dalmia and Eduardo Pontes Reis and Pranav Rajpurkar and Jure Leskovec},
      year={2023},
      eprint={2307.15189},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{sun2024emu,
      title={Emu: Generative Pretraining in Multimodality}, 
      author={Quan Sun and Qiying Yu and Yufeng Cui and Fan Zhang and Xiaosong Zhang and Yueze Wang and Hongcheng Gao and Jingjing Liu and Tiejun Huang and Xinlong Wang},
      year={2024},
      eprint={2307.05222},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{li2023mimicit,
      title={MIMIC-IT: Multi-Modal In-Context Instruction Tuning}, 
      author={Bo Li and Yuanhan Zhang and Liangyu Chen and Jinghao Wang and Fanyi Pu and Jingkang Yang and Chunyuan Li and Ziwei Liu},
      year={2023},
      eprint={2306.05425},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{yang2024exploring,
      title={Exploring Diverse In-Context Configurations for Image Captioning}, 
      author={Xu Yang and Yongliang Wu and Mingzhuo Yang and Haokun Chen and Xin Geng},
      year={2024},
      eprint={2305.14800},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{alayrac2022flamingo,
      title={Flamingo: a Visual Language Model for Few-Shot Learning}, 
      author={Jean-Baptiste Alayrac and Jeff Donahue and Pauline Luc and Antoine Miech and Iain Barr and Yana Hasson and Karel Lenc and Arthur Mensch and Katie Millican and Malcolm Reynolds and Roman Ring and Eliza Rutherford and Serkan Cabi and Tengda Han and Zhitao Gong and Sina Samangooei and Marianne Monteiro and Jacob Menick and Sebastian Borgeaud and Andrew Brock and Aida Nematzadeh and Sahand Sharifzadeh and Mikolaj Binkowski and Ricardo Barreira and Oriol Vinyals and Andrew Zisserman and Karen Simonyan},
      year={2022},
      eprint={2204.14198},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{tsimpoukelli2021multimodal,
      title={Multimodal Few-Shot Learning with Frozen Language Models}, 
      author={Maria Tsimpoukelli and Jacob Menick and Serkan Cabi and S. M. Ali Eslami and Oriol Vinyals and Felix Hill},
      year={2021},
      eprint={2106.13884},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{gao2024cantor,
      title={Cantor: Inspiring Multimodal Chain-of-Thought of MLLM}, 
      author={Timin Gao and Peixian Chen and Mengdan Zhang and Chaoyou Fu and Yunhang Shen and Yan Zhang and Shengchuan Zhang and Xiawu Zheng and Xing Sun and Liujuan Cao and Rongrong Ji},
      year={2024},
      eprint={2404.16033},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{shao2024visual,
      title={Visual CoT: Unleashing Chain-of-Thought Reasoning in Multi-Modal Language Models}, 
      author={Hao Shao and Shengju Qian and Han Xiao and Guanglu Song and Zhuofan Zong and Letian Wang and Yu Liu and Hongsheng Li},
      year={2024},
      eprint={2403.16999},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zheng2023ddcot,
      title={DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models}, 
      author={Ge Zheng and Bin Yang and Jiajin Tang and Hong-Yu Zhou and Sibei Yang},
      year={2023},
      eprint={2310.16436},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{chen2023shikra,
      title={Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic}, 
      author={Keqin Chen and Zhao Zhang and Weili Zeng and Richong Zhang and Feng Zhu and Rui Zhao},
      year={2023},
      eprint={2306.15195},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{lian2024explainable,
      title={Explainable Multimodal Emotion Recognition}, 
      author={Zheng Lian and Haiyang Sun and Licai Sun and Hao Gu and Zhuofan Wen and Siyuan Zhang and Shun Chen and Mingyu Xu and Ke Xu and Kang Chen and Lan Chen and Shan Liang and Ya Li and Jiangyan Yi and Bin Liu and Jianhua Tao},
      year={2024},
      eprint={2306.15401},
      archivePrefix={arXiv},
      primaryClass={cs.MM}
}

@misc{mu2023embodiedgpt,
      title={EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought}, 
      author={Yao Mu and Qinglong Zhang and Mengkang Hu and Wenhai Wang and Mingyu Ding and Jun Jin and Bin Wang and Jifeng Dai and Yu Qiao and Ping Luo},
      year={2023},
      eprint={2305.15021},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@misc{himakunthala2023lets,
      title={Let's Think Frame by Frame with VIP: A Video Infilling and Prediction Dataset for Evaluating Video Chain-of-Thought}, 
      author={Vaishnavi Himakunthala and Andy Ouyang and Daniel Rose and Ryan He and Alex Mei and Yujie Lu and Chinmay Sonar and Michael Saxon and William Yang Wang},
      year={2023},
      eprint={2305.13903},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wang2023tsciq,
      title={T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Mixed Large Language Model Signals for Science Question Answering}, 
      author={Lei Wang and Yi Hu and Jiabang He and Xing Xu and Ning Liu and Hui Liu and Heng Tao Shen},
      year={2023},
      eprint={2305.03453},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wang2023caption,
      title={Caption Anything: Interactive Image Description with Diverse Multimodal Controls}, 
      author={Teng Wang and Jinrui Zhang and Junjie Fei and Hao Zheng and Yunlong Tang and Zhe Li and Mingqi Gao and Shanshan Zhao},
      year={2023},
      eprint={2305.02677},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{rose2024visual,
      title={Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings}, 
      author={Daniel Rose and Vaishnavi Himakunthala and Andy Ouyang and Ryan He and Alex Mei and Yujie Lu and Michael Saxon and Chinmay Sonar and Diba Mirza and William Yang Wang},
      year={2024},
      eprint={2305.02317},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lu2023chameleon,
      title={Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models}, 
      author={Pan Lu and Baolin Peng and Hao Cheng and Michel Galley and Kai-Wei Chang and Ying Nian Wu and Song-Chun Zhu and Jianfeng Gao},
      year={2023},
      eprint={2304.09842},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ge2023chain,
      title={Chain of Thought Prompt Tuning in Vision Language Models}, 
      author={Jiaxin Ge and Hongyin Luo and Siyuan Qian and Yulu Gan and Jie Fu and Shanghang Zhang},
      year={2023},
      eprint={2304.07919},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{yang2023mmreact,
      title={MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action}, 
      author={Zhengyuan Yang and Linjie Li and Jianfeng Wang and Kevin Lin and Ehsan Azarnasab and Faisal Ahmed and Zicheng Liu and Ce Liu and Michael Zeng and Lijuan Wang},
      year={2023},
      eprint={2303.11381},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{wu2023visual,
      title={Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models}, 
      author={Chenfei Wu and Shengming Yin and Weizhen Qi and Xiaodong Wang and Zecheng Tang and Nan Duan},
      year={2023},
      eprint={2303.04671},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zhang2024multimodal,
      title={Multimodal Chain-of-Thought Reasoning in Language Models}, 
      author={Zhuosheng Zhang and Aston Zhang and Mu Li and Hai Zhao and George Karypis and Alex Smola},
      year={2024},
      eprint={2302.00923},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{gupta2022visual,
      title={Visual Programming: Compositional visual reasoning without training}, 
      author={Tanmay Gupta and Aniruddha Kembhavi},
      year={2022},
      eprint={2211.11559},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{lu2022learn,
      title={Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering}, 
      author={Pan Lu and Swaroop Mishra and Tony Xia and Liang Qiu and Kai-Wei Chang and Song-Chun Zhu and Oyvind Tafjord and Peter Clark and Ashwin Kalyan},
      year={2022},
      eprint={2209.09513},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{yin2024surveymultimodallargelanguage,
      title={A Survey on Multimodal Large Language Models}, 
      author={Shukang Yin and Chaoyou Fu and Sirui Zhao and Ke Li and Xing Sun and Tong Xu and Enhong Chen},
      year={2024},
      eprint={2306.13549},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2306.13549}, 
}
@misc{bordes2024introductionvisionlanguagemodeling,
      title={An Introduction to Vision-Language Modeling}, 
      author={Florian Bordes and Richard Yuanzhe Pang and Anurag Ajay and Alexander C. Li and Adrien Bardes and Suzanne Petryk and Oscar Mañas and Zhiqiu Lin and Anas Mahmoud and Bargav Jayaraman and Mark Ibrahim and Melissa Hall and Yunyang Xiong and Jonathan Lebensold and Candace Ross and Srihari Jayakumar and Chuan Guo and Diane Bouchacourt and Haider Al-Tahan and Karthik Padthe and Vasu Sharma and Hu Xu and Xiaoqing Ellen Tan and Megan Richards and Samuel Lavoie and Pietro Astolfi and Reyhane Askari Hemmat and Jun Chen and Kushal Tirumala and Rim Assouel and Mazda Moayeri and Arjang Talattof and Kamalika Chaudhuri and Zechun Liu and Xilun Chen and Quentin Garrido and Karen Ullrich and Aishwarya Agrawal and Kate Saenko and Asli Celikyilmaz and Vikas Chandra},
      year={2024},
      eprint={2405.17247},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.17247}, 
}
@misc{awais2023foundationalmodelsdefiningnew,
      title={Foundational Models Defining a New Era in Vision: A Survey and Outlook}, 
      author={Muhammad Awais and Muzammal Naseer and Salman Khan and Rao Muhammad Anwer and Hisham Cholakkal and Mubarak Shah and Ming-Hsuan Yang and Fahad Shahbaz Khan},
      year={2023},
      eprint={2307.13721},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.13721}, 
}
@misc{ghosh2024exploringfrontiervisionlanguagemodels,
      title={Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions}, 
      author={Akash Ghosh and Arkadeep Acharya and Sriparna Saha and Vinija Jain and Aman Chadha},
      year={2024},
      eprint={2404.07214},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2404.07214}, 
}
@misc{caffagni2024revolutionmultimodallargelanguage,
      title={The Revolution of Multimodal Large Language Models: A Survey}, 
      author={Davide Caffagni and Federico Cocchi and Luca Barsellotti and Nicholas Moratelli and Sara Sarto and Lorenzo Baraldi and Lorenzo Baraldi and Marcella Cornia and Rita Cucchiara},
      year={2024},
      eprint={2402.12451},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2402.12451}, 
}
@misc{zhang2024mmllmsrecentadvancesmultimodal,
      title={MM-LLMs: Recent Advances in MultiModal Large Language Models}, 
      author={Duzhen Zhang and Yahan Yu and Jiahua Dong and Chenxing Li and Dan Su and Chenhui Chu and Dong Yu},
      year={2024},
      eprint={2401.13601},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.13601}, 
}
@misc{zhang2024visionlanguagemodelsvisiontasks,
      title={Vision-Language Models for Vision Tasks: A Survey}, 
      author={Jingyi Zhang and Jiaxing Huang and Sheng Jin and Shijian Lu},
      year={2024},
      eprint={2304.00685},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2304.00685}, 
}
@misc{wang2024exploringreasoningabilitiesmultimodal,
      title={Exploring the Reasoning Abilities of Multimodal Large Language Models (MLLMs): A Comprehensive Survey on Emerging Trends in Multimodal Reasoning}, 
      author={Yiqi Wang and Wentao Chen and Xiaotian Han and Xudong Lin and Haiteng Zhao and Yongfei Liu and Bohan Zhai and Jianbo Yuan and Quanzeng You and Hongxia Yang},
      year={2024},
      eprint={2401.06805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.06805}, 
}
@misc{jin2024efficientmultimodallargelanguage,
      title={Efficient Multimodal Large Language Models: A Survey}, 
      author={Yizhang Jin and Jian Li and Yexin Liu and Tianjun Gu and Kai Wu and Zhengkai Jiang and Muyang He and Bo Zhao and Xin Tan and Zhenye Gan and Yabiao Wang and Chengjie Wang and Lizhuang Ma},
      year={2024},
      eprint={2405.10739},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.10739}, 
}
@misc{liu2024surveyhallucinationlargevisionlanguage,
      title={A Survey on Hallucination in Large Vision-Language Models}, 
      author={Hanchao Liu and Wenyuan Xue and Yifei Chen and Dapeng Chen and Xiutian Zhao and Ke Wang and Liping Hou and Rongjun Li and Wei Peng},
      year={2024},
      eprint={2402.00253},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2402.00253}, 
}
@misc{rohleder2024variationalapproachhotspots,
      title={A variational approach to the hot spots conjecture}, 
      author={Jonathan Rohleder},
      year={2024},
      eprint={2404.01890},
      archivePrefix={arXiv},
      primaryClass={math.SP},
      url={https://arxiv.org/abs/2404.01890}, 
}
@misc{xu2024surveyresourceefficientllmmultimodal,
      title={A Survey of Resource-efficient LLM and Multimodal Foundation Models}, 
      author={Mengwei Xu and Wangsong Yin and Dongqi Cai and Rongjie Yi and Daliang Xu and Qipeng Wang and Bingyang Wu and Yihao Zhao and Chen Yang and Shihe Wang and Qiyang Zhang and Zhenyan Lu and Li Zhang and Shangguang Wang and Yuanchun Li and Yunxin Liu and Xin Jin and Xuanzhe Liu},
      year={2024},
      eprint={2401.08092},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.08092}, 
}
@misc{xie2024largemultimodalagentssurvey,
      title={Large Multimodal Agents: A Survey}, 
      author={Junlin Xie and Zhihong Chen and Ruifei Zhang and Xiang Wan and Guanbin Li},
      year={2024},
      eprint={2402.15116},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2402.15116}, 
}
@misc{cui2023surveymultimodallargelanguage,
      title={A Survey on Multimodal Large Language Models for Autonomous Driving}, 
      author={Can Cui and Yunsheng Ma and Xu Cao and Wenqian Ye and Yang Zhou and Kaizhao Liang and Jintai Chen and Juanwu Lu and Zichong Yang and Kuei-Da Liao and Tianren Gao and Erlong Li and Kun Tang and Zhipeng Cao and Tong Zhou and Ao Liu and Xinrui Yan and Shuqi Mei and Jianguo Cao and Ziran Wang and Chao Zheng},
      year={2023},
      eprint={2311.12320},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2311.12320}, 
}
@misc{li2023multimodalfoundationmodelsspecialists,
      title={Multimodal Foundation Models: From Specialists to General-Purpose Assistants}, 
      author={Chunyuan Li and Zhe Gan and Zhengyuan Yang and Jianwei Yang and Linjie Li and Lijuan Wang and Jianfeng Gao},
      year={2023},
      eprint={2309.10020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2309.10020}, 
}


@article{van2016wavenet,
  title={Wavenet: A generative model for raw audio},
  author={Van Den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray and others},
  journal={arXiv preprint arXiv:1609.03499},
  volume={12},
  year={2016}
}

@article{chen2024valle2,
  title={VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers},
  author={Chen, Sanyuan and Liu, Shujie and Zhou, Long and Liu, Yanqing and Tan, Xu and Li, Jinyu and Zhao, Sheng and Qian, Yao and Wei, Furu},
  journal={arXiv preprint arXiv:2406.05370},
  year={2024}
}

@article{han2024valler,
  title={VALL-E R: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via Monotonic Alignment},
  author={Han, Bing and Zhou, Long and Liu, Shujie and Chen, Sanyuan and Meng, Lingwei and Qian, Yanming and Liu, Yanqing and Zhao, Sheng and Li, Jinyu and Wei, Furu},
  journal={arXiv preprint arXiv:2406.07855},
  year={2024}
}

@article{meng2024llm,
  title={Large Language Model Can Transcribe Speech in Multi-Talker Scenarios with Versatile Instructions},
  author={Meng, Lingwei and Hu, Shujie and Kang, Jiawen and Li, Zhaoqing and Wang, Yuejiao and Wu, Wenxuan and Wu, Xixin and Liu, Xunying and Meng, Helen},
  journal={arXiv preprint arXiv:2409.08596},
  year={2024}
}

@article{song2024ellav,
  title={ELLA-V: Stable neural codec language modeling with alignment-guided sequence reordering},
  author={Song, Yakun and Chen, Zhuo and Wang, Xiaofei and Ma, Ziyang and Chen, Xie},
  journal={arXiv preprint arXiv:2401.07333},
  year={2024}
}

@article{du2022vqtts,
  title={VQTTS: High-fidelity text-to-speech synthesis with self-supervised VQ acoustic feature},
  author={Du, Chenpeng and Guo, Yiwei and Chen, Xie and Yu, Kai},
  journal={arXiv preprint arXiv:2204.00768},
  year={2022}
}

@article{lakhotia2021gslm,
  title={On generative spoken language modeling from raw audio},
  author={Lakhotia, Kushal and Kharitonov, Eugene and Hsu, Wei-Ning and Adi, Yossi and Polyak, Adam and Bolte, Benjamin and Nguyen, Tu-Anh and Copet, Jade and Baevski, Alexei and Mohamed, Abdelrahman and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={1336--1354},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{ji2024wavtokenizer,
  title={WavTokenizer: an efficient acoustic discrete codec tokenizer for audio language modeling},
  author={Ji, Shengpeng and Jiang, Ziyue and Cheng, Xize and Chen, Yifu and Fang, Minghui and Zuo, Jialong and Yang, Qian and Li, Ruiqi and Zhang, Ziang and Yang, Xiaoda and others},
  journal={arXiv preprint arXiv:2408.16532},
  year={2024}
}

@inproceedings{wu2022wav2clip,
  title={Wav2CLIP: Learning robust audio representations from clip},
  author={Wu, Ho-Hsiang and Seetharaman, Prem and Kumar, Kundan and Bello, Juan Pablo},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4563--4567},
  year={2022},
  organization={IEEE}
}

@inproceedings{guzhov2022audioclip,
  title={AudioCLIP: Extending clip to image, text and audio},
  author={Guzhov, Andrey and Raue, Federico and Hees, J{\"o}rn and Dengel, Andreas},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={976--980},
  year={2022},
  organization={IEEE}
}
@article{huang2022masked,
  title={Masked autoencoders that listen},
  author={Huang, Po-Yao and Xu, Hu and Li, Juncheng and Baevski, Alexei and Auli, Michael and Galuba, Wojciech and Metze, Florian and Feichtenhofer, Christoph},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={28708--28720},
  year={2022}
}

@inproceedings{meng24c_interspeech,
  title     = {Empowering Whisper as a Joint Multi-Talker and Target-Talker Speech Recognition System},
  author    = {Lingwei Meng and Jiawen Kang and Yuejiao Wang and Zengrui Jin and Xixin Wu and Xunying Liu and Helen Meng},
  year      = {2024},
  booktitle = {Interspeech 2024},
  pages     = {4653--4657},
  doi       = {10.21437/Interspeech.2024-971},
  issn      = {2958-1796},
}
@misc{ultraEdit,
      title={UltraEdit: Instruction-based Fine-Grained Image Editing at Scale}, 
      author={Haozhe Zhao and Xiaojian Ma and Liang Chen and Shuzheng Si and Rujie Wu and Kaikai An and Peiyu Yu and Minjia Zhang and Qing Li and Baobao Chang},
      year={2024},
      eprint={2407.05282},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.05282}, 
}
@misc{eve,
      title={Unveiling Encoder-Free Vision-Language Models}, 
      author={Haiwen Diao and Yufeng Cui and Xiaotong Li and Yueze Wang and Huchuan Lu and Xinlong Wang},
      year={2024},
      eprint={2406.11832},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.11832}, 
}
@misc{monointernvl,
      title={Mono-InternVL: Pushing the Boundaries of Monolithic Multimodal Large Language Models with Endogenous Visual Pre-training}, 
      author={Gen Luo and Xue Yang and Wenhan Dou and Zhaokai Wang and Jifeng Dai and Yu Qiao and Xizhou Zhu},
      year={2024},
      eprint={2410.08202},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.08202}, 
}
@misc{Kosmos-G,
      title={Kosmos-G: Generating Images in Context with Multimodal Large Language Models}, 
      author={Xichen Pan and Li Dong and Shaohan Huang and Zhiliang Peng and Wenhu Chen and Furu Wei},
      year={2024},
      eprint={2310.02992},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2310.02992}, 
}
@misc{dnd-transformer,
      title={A Spark of Vision-Language Intelligence: 2-Dimensional Autoregressive Transformer for Efficient Finegrained Image Generation}, 
      author={Liang Chen and Sinan Tan and Zefan Cai and Weichu Xie and Haozhe Zhao and Yichi Zhang and Junyang Lin and Jinze Bai and Tianyu Liu and Baobao Chang},
      year={2024},
      eprint={2410.01912},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.01912}, 
}
@misc{llamagen,
      title={Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation}, 
      author={Peize Sun and Yi Jiang and Shoufa Chen and Shilong Zhang and Bingyue Peng and Ping Luo and Zehuan Yuan},
      year={2024},
      eprint={2406.06525},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.06525}, 
}
@misc{VAR,
      title={Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction}, 
      author={Keyu Tian and Yi Jiang and Zehuan Yuan and Bingyue Peng and Liwei Wang},
      year={2024},
      eprint={2404.02905},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2404.02905}, 
}
@misc{MAR,
      title={Autoregressive Image Generation without Vector Quantization}, 
      author={Tianhong Li and Yonglong Tian and He Li and Mingyang Deng and Kaiming He},
      year={2024},
      eprint={2406.11838},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.11838}, 
}
@misc{Transfusion,
      title={Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model}, 
      author={Chunting Zhou and Lili Yu and Arun Babu and Kushal Tirumala and Michihiro Yasunaga and Leonid Shamis and Jacob Kahn and Xuezhe Ma and Luke Zettlemoyer and Omer Levy},
      year={2024},
      eprint={2408.11039},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2408.11039}, 
}
@misc{DALLE,
      title={Zero-Shot Text-to-Image Generation}, 
      author={Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
      year={2021},
      eprint={2102.12092},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2102.12092}, 
}
@misc{Emu3,
      title={Emu3: Next-Token Prediction is All You Need}, 
      author={Xinlong Wang and Xiaosong Zhang and Zhengxiong Luo and Quan Sun and Yufeng Cui and Jinsheng Wang and Fan Zhang and Yueze Wang and Zhen Li and Qiying Yu and Yingli Zhao and Yulong Ao and Xuebin Min and Tao Li and Boya Wu and Bo Zhao and Bowen Zhang and Liangdong Wang and Guang Liu and Zheqi He and Xi Yang and Jingjing Liu and Yonghua Lin and Tiejun Huang and Zhongyuan Wang},
      year={2024},
      eprint={2409.18869},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.18869}, 
}
@misc{Show-o,
      title={Show-o: One Single Transformer to Unify Multimodal Understanding and Generation}, 
      author={Jinheng Xie and Weijia Mao and Zechen Bai and David Junhao Zhang and Weihao Wang and Kevin Qinghong Lin and Yuchao Gu and Zhijie Chen and Zhenheng Yang and Mike Zheng Shou},
      year={2024},
      eprint={2408.12528},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.12528}, 
}
@misc{OmniGen,
      title={OmniGen: Unified Image Generation}, 
      author={Shitao Xiao and Yueze Wang and Junjie Zhou and Huaying Yuan and Xingrun Xing and Ruiran Yan and Shuting Wang and Tiejun Huang and Zheng Liu},
      year={2024},
      eprint={2409.11340},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.11340}, 
}
@misc{Moshi,
      title={Moshi: a speech-text foundation model for real-time dialogue}, 
      author={Alexandre Défossez and Laurent Mazaré and Manu Orsini and Amélie Royer and Patrick Pérez and Herv\'{e} J\'{e}gou and Edouard Grave and Neil Zeghidour},
      year={2024},
      eprint={2410.00037},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2410.00037}, 
}
@misc{li2023blipdiffusionpretrainedsubjectrepresentation,
      title={BLIP-Diffusion: Pre-trained Subject Representation for Controllable Text-to-Image Generation and Editing}, 
      author={Dongxu Li and Junnan Li and Steven C. H. Hoi},
      year={2023},
      eprint={2305.14720},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2305.14720}, 
}
@misc{FLUID,
      title={Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens}, 
      author={Lijie Fan and Tianhong Li and Siyang Qin and Yuanzhen Li and Chen Sun and Michael Rubinstein and Deqing Sun and Kaiming He and Yonglong Tian},
      year={2024},
      eprint={2410.13863},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.13863}, 
}


@misc{LWM,
      title={World Model on Million-Length Video And Language With Blockwise RingAttention}, 
      author={Hao Liu and Wilson Yan and Matei Zaharia and Pieter Abbeel},
      year={2024},
      eprint={2402.08268},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.08268}, 
}
@misc{Janus,
      title={Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation}, 
      author={Chengyue Wu and Xiaokang Chen and Zhiyu Wu and Yiyang Ma and Xingchao Liu and Zizheng Pan and Wen Liu and Zhenda Xie and Xingkai Yu and Chong Ruan and Ping Luo},
      year={2024},
      eprint={2410.13848},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.13848}, 
}
@misc{Qwen2vl,
      title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution}, 
      author={Peng Wang and Shuai Bai and Sinan Tan and Shijie Wang and Zhihao Fan and Jinze Bai and Keqin Chen and Xuejing Liu and Jialin Wang and Wenbin Ge and Yang Fan and Kai Dang and Mengfei Du and Xuancheng Ren and Rui Men and Dayiheng Liu and Chang Zhou and Jingren Zhou and Junyang Lin},
      year={2024},
      eprint={2409.12191},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.12191}, 
}
@misc{solo,
      title={A Single Transformer for Scalable Vision-Language Modeling}, 
      author={Yangyi Chen and Xingyao Wang and Hao Peng and Heng Ji},
      year={2024},
      eprint={2407.06438},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.06438}, 
}
@misc{Cambrian-1,
      title={Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs}, 
      author={Shengbang Tong and Ellis Brown and Penghao Wu and Sanghyun Woo and Manoj Middepogu and Sai Charitha Akula and Jihan Yang and Shusheng Yang and Adithya Iyer and Xichen Pan and Austin Wang and Rob Fergus and Yann LeCun and Saining Xie},
      year={2024},
      eprint={2406.16860},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.16860}, 
}
@misc{LLaVA-OneVision,
      title={LLaVA-OneVision: Easy Visual Task Transfer}, 
      author={Bo Li and Yuanhan Zhang and Dong Guo and Renrui Zhang and Feng Li and Hao Zhang and Kaichen Zhang and Peiyuan Zhang and Yanwei Li and Ziwei Liu and Chunyuan Li},
      year={2024},
      eprint={2408.03326},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.03326}, 
}
@misc{DeepSeek-VL,
      title={DeepSeek-VL: Towards Real-World Vision-Language Understanding}, 
      author={Haoyu Lu and Wen Liu and Bo Zhang and Bingxuan Wang and Kai Dong and Bo Liu and Jingxiang Sun and Tongzheng Ren and Zhuoshu Li and Hao Yang and Yaofeng Sun and Chengqi Deng and Hanwei Xu and Zhenda Xie and Chong Ruan},
      year={2024},
      eprint={2403.05525},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2403.05525}, 
}
@misc{InternVL,
      title={InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks}, 
      author={Zhe Chen and Jiannan Wu and Wenhai Wang and Weijie Su and Guo Chen and Sen Xing and Muyan Zhong and Qinglong Zhang and Xizhou Zhu and Lewei Lu and Bin Li and Ping Luo and Tong Lu and Yu Qiao and Jifeng Dai},
      year={2024},
      eprint={2312.14238},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.14238}, 
}
@misc{xue2024xgenmmblip3familyopen,
      title={xGen-MM (BLIP-3): A Family of Open Large Multimodal Models}, 
      author={Le Xue and Manli Shu and Anas Awadalla and Jun Wang and An Yan and Senthil Purushwalkam and Honglu Zhou and Viraj Prabhu and Yutong Dai and Michael S Ryoo and Shrikant Kendre and Jieyu Zhang and Can Qin and Shu Zhang and Chia-Chih Chen and Ning Yu and Juntao Tan and Tulika Manoj Awalgaonkar and Shelby Heinecke and Huan Wang and Yejin Choi and Ludwig Schmidt and Zeyuan Chen and Silvio Savarese and Juan Carlos Niebles and Caiming Xiong and Ran Xu},
      year={2024},
      eprint={2408.08872},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.08872}, 
}
@misc{Molmo,
      title={Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models}, 
      author={Matt Deitke and Christopher Clark and Sangho Lee and Rohun Tripathi and Yue Yang and Jae Sung Park and Mohammadreza Salehi and Niklas Muennighoff and Kyle Lo and Luca Soldaini and Jiasen Lu and Taira Anderson and Erin Bransom and Kiana Ehsani and Huong Ngo and YenSung Chen and Ajay Patel and Mark Yatskar and Chris Callison-Burch and Andrew Head and Rose Hendrix and Favyen Bastani and Eli VanderBilt and Nathan Lambert and Yvonne Chou and Arnavi Chheda and Jenna Sparks and Sam Skjonsberg and Michael Schmitz and Aaron Sarnat and Byron Bischoff and Pete Walsh and Chris Newell and Piper Wolters and Tanmay Gupta and Kuo-Hao Zeng and Jon Borchardt and Dirk Groeneveld and Jen Dumas and Crystal Nam and Sophie Lebrecht and Caitlin Wittlif and Carissa Schoenick and Oscar Michel and Ranjay Krishna and Luca Weihs and Noah A. Smith and Hannaneh Hajishirzi and Ross Girshick and Ali Farhadi and Aniruddha Kembhavi},
      year={2024},
      eprint={2409.17146},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.17146}, 
}
@misc{internvl15,
      title={How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites}, 
      author={Zhe Chen and Weiyun Wang and Hao Tian and Shenglong Ye and Zhangwei Gao and Erfei Cui and Wenwen Tong and Kongzhi Hu and Jiapeng Luo and Zheng Ma and Ji Ma and Jiaqi Wang and Xiaoyi Dong and Hang Yan and Hewei Guo and Conghui He and Botian Shi and Zhenjiang Jin and Chao Xu and Bin Wang and Xingjian Wei and Wei Li and Wenjian Zhang and Bo Zhang and Pinlong Cai and Licheng Wen and Xiangchao Yan and Min Dou and Lewei Lu and Xizhou Zhu and Tong Lu and Dahua Lin and Yu Qiao and Jifeng Dai and Wenhai Wang},
      year={2024},
      eprint={2404.16821},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2404.16821}, 
}
@misc{yao2024minicpmvgpt4vlevelmllm,
      title={MiniCPM-V: A GPT-4V Level MLLM on Your Phone}, 
      author={Yuan Yao and Tianyu Yu and Ao Zhang and Chongyi Wang and Junbo Cui and Hongji Zhu and Tianchi Cai and Haoyu Li and Weilin Zhao and Zhihui He and Qianyu Chen and Huarong Zhou and Zhensheng Zou and Haoye Zhang and Shengding Hu and Zhi Zheng and Jie Zhou and Jie Cai and Xu Han and Guoyang Zeng and Dahai Li and Zhiyuan Liu and Maosong Sun},
      year={2024},
      eprint={2408.01800},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.01800}, 
}
@misc{Mini-Gemini,
      title={Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models}, 
      author={Yanwei Li and Yuechen Zhang and Chengyao Wang and Zhisheng Zhong and Yixin Chen and Ruihang Chu and Shaoteng Liu and Jiaya Jia},
      year={2024},
      eprint={2403.18814},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2403.18814}, 
}
@misc{VILA,
      title={VILA: On Pre-training for Visual Language Models}, 
      author={Ji Lin and Hongxu Yin and Wei Ping and Yao Lu and Pavlo Molchanov and Andrew Tao and Huizi Mao and Jan Kautz and Mohammad Shoeybi and Song Han},
      year={2024},
      eprint={2312.07533},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.07533}, 
}
@misc{VILA-U,
      title={VILA-U: a Unified Foundation Model Integrating Visual Understanding and Generation}, 
      author={Yecheng Wu and Zhuoyang Zhang and Junyu Chen and Haotian Tang and Dacheng Li and Yunhao Fang and Ligeng Zhu and Enze Xie and Hongxu Yin and Li Yi and Song Han and Yao Lu},
      year={2024},
      eprint={2409.04429},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.04429}, 
}

@misc{maskbit,
      title={MaskBit: Embedding-free Image Generation via Bit Tokens}, 
      author={Mark Weber and Lijun Yu and Qihang Yu and Xueqing Deng and Xiaohui Shen and Daniel Cremers and Liang-Chieh Chen},
      year={2024},
      eprint={2409.16211},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.16211}, 
}
@misc{brock2021highperformancelargescaleimagerecognition,
      title={High-Performance Large-Scale Image Recognition Without Normalization}, 
      author={Andrew Brock and Soham De and Samuel L. Smith and Karen Simonyan},
      year={2021},
      eprint={2102.06171},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2102.06171}, 
}
@software{OpenCLIP,
  author       = {Ilharco, Gabriel and
                  Wortsman, Mitchell and
                  Wightman, Ross and
                  Gordon, Cade and
                  Carlini, Nicholas and
                  Taori, Rohan and
                  Dave, Achal and
                  Shankar, Vaishaal and
                  Namkoong, Hongseok and
                  Miller, John and
                  Hajishirzi, Hannaneh and
                  Farhadi, Ali and
                  Schmidt, Ludwig},
  title        = {OpenCLIP},
  month        = jul,
  year         = 2021,
  note         = {If you use this software, please cite it as below.},
  publisher    = {Zenodo},
  version      = {0.1},
  doi          = {10.5281/zenodo.5143773},
  url          = {https://doi.org/10.5281/zenodo.5143773}
}
@misc{sd,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.10752}, 
}
@misc{SDXL,
      title={SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis}, 
      author={Dustin Podell and Zion English and Kyle Lacey and Andreas Blattmann and Tim Dockhorn and Jonas Müller and Joe Penna and Robin Rombach},
      year={2023},
      eprint={2307.01952},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.01952}, 
}@misc{liu2022convnet2020s,
      title={A ConvNet for the 2020s}, 
      author={Zhuang Liu and Hanzi Mao and Chao-Yuan Wu and Christoph Feichtenhofer and Trevor Darrell and Saining Xie},
      year={2022},
      eprint={2201.03545},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2201.03545}, 
}
@misc{AudioLDM2,
      title={AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining}, 
      author={Haohe Liu and Yi Yuan and Xubo Liu and Xinhao Mei and Qiuqiang Kong and Qiao Tian and Yuping Wang and Wenwu Wang and Yuxuan Wang and Mark D. Plumbley},
      year={2024},
      eprint={2308.05734},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2308.05734}, 
}


# XYZ
@article{zhu2021vision,
  author       = {Mingjian Zhu and
                  Kai Han and
                  Yehui Tang and
                  Yunhe Wang},
  title        = {Visual Transformer Pruning},
  journal      = {CoRR},
  volume       = {abs/2104.08500},
  year         = {2021},
  url          = {https://arxiv.org/abs/2104.08500},
  eprinttype    = {arXiv},
  eprint       = {2104.08500},
  timestamp    = {Mon, 17 May 2021 08:15:54 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2104-08500.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{Lin_2024_CVPR,
    author    = {Lin, Haokun and Bai, Haoli and Liu, Zhili and Hou, Lu and Sun, Muyi and Song, Linqi and Wei, Ying and Sun, Zhenan},
    title     = {MoPE-CLIP: Structured Pruning for Efficient Vision-Language Models with Module-wise Pruning Error Metric},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2024},
    pages     = {27370-27380}
}

@inproceedings{yuan2021tokens,
  title={Tokens-to-token vit: Training vision transformers from scratch on imagenet},
  author={Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zi-Hang and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={558--567},
  year={2021}
}

@inproceedings{wu2023tinyclip,
  title={Tinyclip: Clip distillation via affinity mimicking and weight inheritance},
  author={Wu, Kan and Peng, Houwen and Zhou, Zhenghong and Xiao, Bin and Liu, Mengchen and Yuan, Lu and Xuan, Hong and Valenzuela, Michael and Chen, Xi Stephen and Wang, Xinggang and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={21970--21980},
  year={2023}
}

@inproceedings{yu2022unified,
  author       = {Shixing Yu and
                  Tianlong Chen and
                  Jiayi Shen and
                  Huan Yuan and
                  Jianchao Tan and
                  Sen Yang and
                  Ji Liu and
                  Zhangyang Wang},
  title        = {Unified Visual Transformer Compression},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022},
  url          = {https://openreview.net/forum?id=9jsZiUgkCZP},
  timestamp    = {Sat, 26 Aug 2023 22:01:08 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/YuCSYTY0W22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{liu2021post,
  title={Post-training quantization for vision transformer},
  author={Liu, Zhenhua and Wang, Yunhe and Han, Kai and Zhang, Wei and Ma, Siwei and Gao, Wen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={28092--28103},
  year={2021}
}

@article{chen2024spark,
  author       = {Liang Chen and
                  Sinan Tan and
                  Zefan Cai and
                  Weichu Xie and
                  Haozhe Zhao and
                  Yichi Zhang and
                  Junyang Lin and
                  Jinze Bai and
                  Tianyu Liu and
                  Baobao Chang},
  title        = {A Spark of Vision-Language Intelligence: 2-Dimensional Autoregressive
                  Transformer for Efficient Finegrained Image Generation},
  journal      = {CoRR},
  volume       = {abs/2410.01912},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2410.01912},
  doi          = {10.48550/ARXIV.2410.01912},
  eprinttype    = {arXiv},
  eprint       = {2410.01912},
  timestamp    = {Fri, 08 Nov 2024 14:43:54 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2410-01912.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{marin2021token,
  author       = {Dmitrii Marin and
                  Jen{-}Hao Rick Chang and
                  Anurag Ranjan and
                  Anish Prabhu and
                  Mohammad Rastegari and
                  Oncel Tuzel},
  title        = {Token Pooling in Vision Transformers for Image Classification},
  booktitle    = {{IEEE/CVF} Winter Conference on Applications of Computer Vision, {WACV}
                  2023, Waikoloa, HI, USA, January 2-7, 2023},
  pages        = {12--21},
  publisher    = {{IEEE}},
  year         = {2023},
  url          = {https://doi.org/10.1109/WACV56688.2023.00010},
  doi          = {10.1109/WACV56688.2023.00010},
  timestamp    = {Tue, 14 Feb 2023 22:26:55 +0100},
  biburl       = {https://dblp.org/rec/conf/wacv/MarinCRPRT23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{xiong2024pyra,
  author       = {Yizhe Xiong and
                  Hui Chen and
                  Tianxiang Hao and
                  Zijia Lin and
                  Jungong Han and
                  Yuesong Zhang and
                  Guoxin Wang and
                  Yongjun Bao and
                  Guiguang Ding},
  editor       = {Ales Leonardis and
                  Elisa Ricci and
                  Stefan Roth and
                  Olga Russakovsky and
                  Torsten Sattler and
                  G{\"{u}}l Varol},
  title        = {{PYRA:} Parallel Yielding Re-activation for Training-Inference Efficient
                  Task Adaptation},
  booktitle    = {Computer Vision - {ECCV} 2024 - 18th European Conference, Milan, Italy,
                  September 29-October 4, 2024, Proceedings, Part {IX}},
  series       = {Lecture Notes in Computer Science},
  volume       = {15067},
  pages        = {455--473},
  publisher    = {Springer},
  year         = {2024},
  url          = {https://doi.org/10.1007/978-3-031-72673-6\_25},
  doi          = {10.1007/978-3-031-72673-6\_25},
  timestamp    = {Wed, 06 Nov 2024 22:17:13 +0100},
  biburl       = {https://dblp.org/rec/conf/eccv/XiongCHLHZWBD24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bolya2022token,
  author       = {Daniel Bolya and
                  Cheng{-}Yang Fu and
                  Xiaoliang Dai and
                  Peizhao Zhang and
                  Christoph Feichtenhofer and
                  Judy Hoffman},
  title        = {Token Merging: Your ViT But Faster},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/forum?id=JroZRaRw7Eu},
  timestamp    = {Wed, 24 Jul 2024 16:50:34 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/BolyaFDZFH23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@misc{yu2024imageworth32tokens,
      title={An Image is Worth 32 Tokens for Reconstruction and Generation}, 
      author={Qihang Yu and Mark Weber and Xueqing Deng and Xiaohui Shen and Daniel Cremers and Liang-Chieh Chen},
      year={2024},
      eprint={2406.07550},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.07550}, 
}
@misc{MoVQ,
      title={MoVQ: Modulating Quantized Vectors for High-Fidelity Image Generation}, 
      author={Chuanxia Zheng and Long Tung Vuong and Jianfei Cai and Dinh Phung},
      year={2022},
      eprint={2209.09002},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2209.09002}, 
}

@inproceedings{todd2024function,
  title={Function Vectors in Large Language Models},
  author={Todd, Eric and Li, Millicent and Sharma, Arnab and Mueller, Aaron and Wallace, Byron C and Bau, David},
  booktitle={International Conference on Learning Representations},
  year={2024},
  organization={ICLR}
}


@inproceedings{baldassini2024makes,
  title={What Makes Multimodal In-Context Learning Work?},
  author={Baldassini, Folco Bertini and Shukor, Mustafa and Cord, Matthieu and Soulier, Laure and Piwowarski, Benjamin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1539--1550},
  year={2024}
}

@article{qi2024cogcom,
  title={Cogcom: Train large vision-language models diving into details through chain of manipulations},
  author={Qi, Ji and Ding, Ming and Wang, Weihan and Bai, Yushi and Lv, Qingsong and Hong, Wenyi and Xu, Bin and Hou, Lei and Li, Juanzi and Dong, Yuxiao and others},
  journal={arXiv preprint arXiv:2402.04236},
  year={2024}
}
@inproceedings{wu2024v,
  title={V*: Guided Visual Search as a Core Mechanism in Multimodal LLMs},
  author={Wu, Penghao and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13084--13094},
  year={2024}
}

@InProceedings{Mitra_2024_CVPR,
    author    = {Mitra, Chancharik and Huang, Brandon and Darrell, Trevor and Herzig, Roei},
    title     = {Compositional Chain-of-Thought Prompting for Large Multimodal Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2024},
    pages     = {14420-14431}
}

@article{zheng2023ddcot,
  title={Ddcot: Duty-distinct chain-of-thought prompting for multimodal reasoning in language models},
  author={Zheng, Ge and Yang, Bin and Tang, Jiajin and Zhou, Hong-Yu and Yang, Sibei},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={5168--5191},
  year={2023}
}



@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{wang2022language,
  title={Language models with image descriptors are strong few-shot video-language learners},
  author={Wang, Zhenhailong and Li, Manling and Xu, Ruochen and Zhou, Luowei and Lei, Jie and Lin, Xudong and Wang, Shuohang and Yang, Ziyi and Zhu, Chenguang and Hoiem, Derek and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={8483--8497},
  year={2022}
}

@article{wang2024videocot,
  title={Videocot: A video chain-of-thought dataset with active annotation tool},
  author={Wang, Yan and Zeng, Yawen and Zheng, Jingsheng and Xing, Xiaofen and Xu, Jin and Xu, Xiangmin},
  journal={arXiv preprint arXiv:2407.05355},
  year={2024}
}

@article{du2024cot,
  title={CoT-ST: Enhancing LLM-based Speech Translation with Multimodal Chain-of-Thought},
  author={Du, Yexing and Ma, Ziyang and Yang, Yifan and Deng, Keqi and Chen, Xie and Yang, Bo and Xiang, Yang and Liu, Ming and Qin, Bing},
  journal={arXiv preprint arXiv:2409.19510},
  year={2024}
}

@article{harvey2023visual,
  title={Visual chain-of-thought diffusion models},
  author={Harvey, William and Wood, Frank},
  journal={arXiv preprint arXiv:2303.16187},
  year={2023}
}


@inproceedings{
fei2024videoofthought,
title={Video-of-Thought: Step-by-Step Video Reasoning from Perception to Cognition},
author={Hao Fei and Shengqiong Wu and Wei Ji and Hanwang Zhang and Meishan Zhang and Mong-Li Lee and Wynne Hsu},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=fO31YAyNbI}
}

@article{gpt2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{team2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}
@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}

@article{maynez2020faithfulness,
  title={On faithfulness and factuality in abstractive summarization},
  author={Maynez, Joshua and Narayan, Shashi and Bohnet, Bernd and McDonald, Ryan},
  journal={arXiv preprint arXiv:2005.00661},
  year={2020}
}

@article{rawte2023survey,
  title={A survey of hallucination in large foundation models},
  author={Rawte, Vipula and Sheth, Amit and Das, Amitava},
  journal={arXiv preprint arXiv:2309.05922},
  year={2023}
}

@article{shukor2023beyond,
  title={Beyond task performance: Evaluating and reducing the flaws of large multimodal models with in-context learning},
  author={Shukor, Mustafa and Rame, Alexandre and Dancette, Corentin and Cord, Matthieu},
  journal={arXiv preprint arXiv:2310.00647},
  year={2023}
}

@article{iyer2022opt,
  title={{OPT-IML}: Scaling language model instruction meta learning through the lens of generalization},
  author={Iyer, Srinivasan and Lin, Xi Victoria and Pasunuru, Ramakanth and Mihaylov, Todor and Simig, Daniel and Yu, Ping and Shuster, Kurt and Wang, Tianlu and Liu, Qing and Koura, Punit Singh and others},
  journal={arXiv preprint arXiv:2212.12017},
  year={2022}
}

@inproceedings{emu2,
  title={Generative multimodal models are in-context learners},
  author={Sun, Quan and Cui, Yufeng and Zhang, Xiaosong and Zhang, Fan and Yu, Qiying and Wang, Yueze and Rao, Yongming and Liu, Jingjing and Huang, Tiejun and Wang, Xinlong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14398--14409},
  year={2024}
}

@article{laurenccon2024obelics,
  title={Obelics: An open web-scale filtered dataset of interleaved image-text documents},
  author={Lauren{\c{c}}on, Hugo and Saulnier, Lucile and Tronchon, L{\'e}o and Bekman, Stas and Singh, Amanpreet and Lozhkov, Anton and Wang, Thomas and Karamcheti, Siddharth and Rush, Alexander and Kiela, Douwe and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{shukor2023beyond,
  title={Beyond task performance: Evaluating and reducing the flaws of large multimodal models with in-context learning},
  author={Shukor, Mustafa and Rame, Alexandre and Dancette, Corentin and Cord, Matthieu},
  journal={arXiv preprint arXiv:2310.00647},
  year={2023}
}
@misc{croCo,
    title={CroCo: Self-Supervised Pre-training for 3D Vision Tasks by Cross-View Completion},
    author={Philippe Weinzaepfel and Vincent Leroy and Thomas Lucas and Romain Brégier and Yohann Cabon and Vaibhav Arora and Leonid Antsfeld and Boris Chidlovskii and Gabriela Csurka and Jérôme Revaud},
    year={2022},
    eprint={2210.10716},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
@misc{habitat,
      title={Habitat: A Platform for Embodied AI Research}, 
      author={Manolis Savva and Abhishek Kadian and Oleksandr Maksymets and Yili Zhao and Erik Wijmans and Bhavana Jain and Julian Straub and Jia Liu and Vladlen Koltun and Jitendra Malik and Devi Parikh and Dhruv Batra},
      year={2019},
      eprint={1904.01201},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1904.01201}, 
}
@misc{DPO,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2024},
      eprint={2305.18290},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.18290}, 
}
@article{RLHF,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@misc{DIT,
      title={Scalable Diffusion Models with Transformers}, 
      author={William Peebles and Saining Xie},
      year={2023},
      eprint={2212.09748},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.09748}, 
}
@misc{scale1,
      title={Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM}, 
      author={Deepak Narayanan and Mohammad Shoeybi and Jared Casper and Patrick LeGresley and Mostofa Patwary and Vijay Anand Korthikanti and Dmitri Vainbrand and Prethvi Kashinkunti and Julie Bernauer and Bryan Catanzaro and Amar Phanishayee and Matei Zaharia},
      year={2021},
      eprint={2104.04473},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2104.04473}, 
}
@misc{scale2,
      title={Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble Exploitation}, 
      author={Weiqi Feng and Yangrui Chen and Shaoyu Wang and Yanghua Peng and Haibin Lin and Minlan Yu},
      year={2024},
      eprint={2408.03505},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.03505}, 
}
@misc{scale3,
      title={DistTrain: Addressing Model and Data Heterogeneity with Disaggregated Training for Multimodal Large Language Models}, 
      author={Zili Zhang and Yinmin Zhong and Ranchen Ming and Hanpeng Hu and Jianjian Sun and Zheng Ge and Yibo Zhu and Xin Jin},
      year={2024},
      eprint={2408.04275},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/2408.04275}, 
}
@misc{scale4,
      title={DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models}, 
      author={Sam Ade Jacobs and Masahiro Tanaka and Chengming Zhang and Minjia Zhang and Shuaiwen Leon Song and Samyam Rajbhandari and Yuxiong He},
      year={2023},
      eprint={2309.14509},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2309.14509}, 
}
@misc{scale5,
      title={Ring Attention with Blockwise Transformers for Near-Infinite Context}, 
      author={Hao Liu and Matei Zaharia and Pieter Abbeel},
      year={2023},
      eprint={2310.01889},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.01889}, 
}
@misc{scale6,
      title={USP: A Unified Sequence Parallelism Approach for Long Context Generative AI}, 
      author={Jiarui Fang and Shangchun Zhao},
      year={2024},
      eprint={2405.07719},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.07719}, 
}
@misc{zhao2024lookingtextreducinglanguage,
      title={Looking Beyond Text: Reducing Language bias in Large Vision-Language Models via Multimodal Dual-Attention and Soft-Image Guidance}, 
      author={Haozhe Zhao and Shuzheng Si and Liang Chen and Yichi Zhang and Maosong Sun and Mingjia Zhang and Baobao Chang},
      year={2024},
      eprint={2411.14279},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.14279}, 
}
# 基础引用

@inproceedings{2023Convnext,
  title={{ConvNeXt v2}: Co-designing and scaling {ConvNets} with masked autoencoders},
  author={Woo, Sanghyun and Debnath, Shoubhik and Hu, Ronghang and Chen, Xinlei and Liu, Zhuang and Kweon, In So and Xie, Saining},
  booktitle=cvpr,
  year={2023}
}

@inproceedings{2023UViT,
  title={All are worth words: A {ViT} backbone for diffusion models},
  author={Bao, Fan and Nie, Shen and Xue, Kaiwen and Cao, Yue and Li, Chongxuan and Su, Hang and Zhu, Jun},
  booktitle=cvpr,
  year={2023}
}

@inproceedings{2023SigLIP,
  title={Sigmoid loss for language image pre-training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle=iccv,
  year={2023}
}

@article{2017TTUR&FID,
  title={{GANs} trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal=nips,
  year={2017}
}

@inproceedings{2021CLIP,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle=icml,
  year={2021},
}

# Benchmark

@inproceedings{2019GQA,
  title={{GQA}: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle=cvpr,
  year={2019}
}

@article{2023SeedBench,
  title={{SEED-Bench}: Benchmarking multimodal llms with generative comprehension},
  author={Li, Bohao and Wang, Rui and Wang, Guangzhi and Ge, Yuying and Ge, Yixiao and Shan, Ying},
  journal={arXiv preprint arXiv:2307.16125},
  year={2023}
}

@inproceedings{2023POPE,
  title={Evaluating Object Hallucination in Large Vision-Language Models},
  author={Li, Yifan and Du, Yifan and Zhou, Kun and Wang, Jinpeng and Zhao, Xin and Wen, Ji-Rong},
  booktitle=emnlp,
  year={2023}
}

@inproceedings{2024MMBench,
  title={{MMBench}: Is your multi-modal model an all-around player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  booktitle=eccv,
  year={2024},
}
@misc{GLIDE,
      title={GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models}, 
      author={Alex Nichol and Prafulla Dhariwal and Aditya Ramesh and Pranav Shyam and Pamela Mishkin and Bob McGrew and Ilya Sutskever and Mark Chen},
      year={2022},
      eprint={2112.10741},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.10741}, 
}
@inproceedings{2024Geneval,
  title={{GenEval}: An object-focused framework for evaluating text-to-image alignment},
  author={Ghosh, Dhruba and Hajishirzi, Hannaneh and Schmidt, Ludwig},
  booktitle=nips,
  year={2024}
}

@article{2024DPGBench,
  title={{ELLA}: Equip diffusion models with llm for enhanced semantic alignment},
  author={Hu, Xiwei and Wang, Rui and Fang, Yixiao and Fu, Bin and Cheng, Pei and Yu, Gang},
  journal={arXiv preprint arXiv:2403.05135},
  year={2024}
}

@article{2023MME,
  title={{MME}: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models}, 
  author={Chaoyou Fu and Peixian Chen and Yunhang Shen and Yulei Qin and Mengdan Zhang and Xu Lin and Jinrui Yang and Xiawu Zheng and Ke Li and Xing Sun and Yunsheng Wu and Rongrong Ji},
  journal={arXiv preprint arXiv:2306.13394}, 
  year={2024},
}

@inproceedings{2024mmvet,
  title={{MM-Vet}: Evaluating Large Multimodal Models for Integrated Capabilities},
  author={Yu, Weihao and Yang, Zhengyuan and Li, Linjie and Wang, Jianfeng and Lin, Kevin and Liu, Zicheng and Wang, Xinchao and Wang, Lijuan},
  booktitle=icml,
  year={2024}
}

@inproceedings{2024mmmu,
  title={{MMMU}: A massive multi-discipline multimodal understanding and reasoning benchmark for expert AGI},
  author={Yue, Xiang and Ni, Yuansheng and Zhang, Kai and Zheng, Tianyu and Liu, Ruoqi and Zhang, Ge and Stevens, Samuel and Jiang, Dongfu and Ren, Weiming and Sun, Yuxuan and others},
  booktitle=cvpr,
  year={2024}
}

# 语言模型

@article{2024DeepSeekLLM,
  title={{DeepSeek LLM}: Scaling open-source language models with longtermism},
  author={Bi, Xiao and Chen, Deli and Chen, Guanting and Chen, Shanhuang and Dai, Damai and Deng, Chengqi and Ding, Honghui and Dong, Kai and Du, Qiushi and Fu, Zhe and others},
  journal={arXiv preprint arXiv:2401.02954},
  year={2024}
}

# 生成模型

@inproceedings{2020DDPM,
  title={Denoising Diffusion Probabilistic Models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  booktitle=nips,
  year={2020}
}

@inproceedings{2021ADM,
  title={Diffusion Models Beat {GANs} on Image Synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  booktitle=nips,
  year={2021}
}

@inproceedings{2021ScoreModel,
  title={Score-based Generative Modeling through Stochastic Differential Equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  booktitle=iclr,
  year={2021}
}

@inproceedings{2021CFG,
  title={Classifier-Free Diffusion Guidance},
  author={Ho, Jonathan and Salimans, Tim},
  booktitle=nipsw,
  year={2021}
}

@article{2022DALLE2,
  title={Hierarchical text-conditional image generation with {CLIP} latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@inproceedings{2022Imagen,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  booktitle=nips,
  year={2022}
}

@inproceedings{2022LDM,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle=cvpr,
  year={2022}
}

@inproceedings{2022MMDiffusion,
  title={{MM-Diffusion}: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation},
  author={Ruan, Ludan and Ma, Yiyang and Yang, Huan and He, Huiguo and Liu, Bei and Fu, Jianlong and Yuan, Nicholas Jing and Jin, Qin and Guo, Baining},
  booktitle=cvpr,
  year={2022}
}

@inproceedings{2022RF,
  title={Flow straight and fast: Learning to generate and transfer data with rectified flow},
  author={Liu, Xingchao and Gong, Chengyue and Liu, Qiang},
  booktitle=iclr,
  year={2023}
}

@inproceedings{2022FlowMatching,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  booktitle=iclr,
  year={2023}
}

@article{2023ummdiffusion,
  title={Unified multi-modal latent diffusion for joint subject and text conditional image generation},
  author={Ma, Yiyang and Yang, Huan and Wang, Wenjing and Fu, Jianlong and Liu, Jiaying},
  journal={arXiv preprint arXiv:2303.09319},
  year={2023}
}

@inproceedings{2023DiT,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle=iccv,
  year={2023}
}

@inproceedings{2023SDXL,
  title={{SDXL}: Improving latent diffusion models for high-resolution image synthesis},
  author={Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and M{\"u}ller, Jonas and Penna, Joe and Rombach, Robin},
  booktitle=iclr,
  year={2024}
}

@inproceedings{2024HDiT,
  title={Scalable high-resolution pixel-space image synthesis with hourglass diffusion transformers},
  author={Crowson, Katherine and Baumann, Stefan Andreas and Birch, Alex and Abraham, Tanishq Mathew and Kaplan, Daniel Z and Shippole, Enrico},
  booktitle=icml,
  year={2024}
}

@article{2024Vermeer,
  title={Greedy Growing Enables High-Resolution Pixel-Based Diffusion Models},
  author={Vasconcelos, Cristina Nader and Rashwan, Abdullah and Waters, Austin and Walker, Trevor and Xu, Keyang and Yan, Jimmy and Qian, Rui and Li, Yeqing and LUO, SHIXIN and Onoe, Yasumasa and others},
  journal={Transactions on Machine Learning Research},
  year={2024}
}

@article{2024PG2.5,
  title={Playground v2.5: Three insights towards enhancing aesthetic quality in text-to-image generation},
  author={Li, Daiqing and Kamko, Aleks and Akhgari, Ehsan and Sabet, Ali and Xu, Linmiao and Doshi, Suhail},
  journal={arXiv preprint arXiv:2402.17245},
  year={2024}
}

@article{2024llamagen,
  title={Autoregressive Model Beats Diffusion: {LLaMA} for Scalable Image Generation},
  author={Sun, Peize and Jiang, Yi and Chen, Shoufa and Zhang, Shilong and Peng, Bingyue and Luo, Ping and Yuan, Zehuan},
  journal={arXiv preprint arXiv:2406.06525},
  year={2024}
}

@inproceedings{2024SD3,
  title={Scaling rectified flow transformers for high-resolution image synthesis},
  author={Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others},
  booktitle=icml,
  year={2024}
}

@misc{2024PGv2,
  url={https://huggingface.co/playgroundai/playground-v2-1024px-aesthetic},
  title={Playground v2},
  author={Li, Daiqing and Kamko, Aleks and Sabet, Ali and Akhgari, Ehsan and Xu, Linmiao and Doshi, Suhail},
  year=2024
}

@article{2023Pixelartalpha,
  title={{PixArt-alpha}: Fast training of diffusion transformer for photorealistic text-to-image synthesis},
  author={Chen, Junsong and Yu, Jincheng and Ge, Chongjian and Yao, Lewei and Xie, Enze and Wu, Yue and Wang, Zhongdao and Kwok, James and Luo, Ping and Lu, Huchuan and others},
  journal={arXiv preprint arXiv:2310.00426},
  year={2023}
}

@article{2024sit,
  title={{SiT}: Exploring flow and diffusion-based generative models with scalable interpolant transformers},
  author={Ma, Nanye and Goldstein, Mark and Albergo, Michael S and Boffi, Nicholas M and Vanden-Eijnden, Eric and Xie, Saining},
  journal={arXiv preprint arXiv:2401.08740},
  year={2024}
}

@inproceedings{2023gigagan,
  title={Scaling up {GAN}s for text-to-image synthesis},
  author={Kang, Minguk and Zhu, Jun-Yan and Zhang, Richard and Park, Jaesik and Shechtman, Eli and Paris, Sylvain and Park, Taesung},
  booktitle=cvpr,
  year={2023}
}

@article{2024lumina,
  title={{Lumina-Next}: Making {Lumina-T2X} stronger and faster with {Next-DiT}},
  author={Zhuo, Le and Du, Ruoyi and Xiao, Han and Li, Yangguang and Liu, Dongyang and Huang, Rongjie and Liu, Wenze and Zhao, Lirui and Wang, Fu-Yun and Ma, Zhanyu and others},
  journal={arXiv preprint arXiv:2406.18583},
  year={2024}
}

@article{2024hunyuandit,
  title={{Hunyuan-DiT}: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding},
  author={Li, Zhimin and Zhang, Jianwei and Lin, Qin and Xiong, Jiangfeng and Long, Yanxin and Deng, Xinchi and Zhang, Yingfang and Liu, Xingchao and Huang, Minbin and Xiao, Zedong and others},
  journal={arXiv preprint arXiv:2405.08748},
  year={2024}
}

@article{2024pixartsigma,
  title={{PixArt-Sigma}: Weak-to-strong training of diffusion transformer for {4K} text-to-image generation},
  author={Chen, Junsong and Ge, Chongjian and Xie, Enze and Wu, Yue and Yao, Lewei and Ren, Xiaozhe and Wang, Zhongdao and Luo, Ping and Lu, Huchuan and Li, Zhenguo},
  journal={arXiv preprint arXiv:2403.04692},
  year={2024}
}

# 理解模型

@article{2023Qwen,
  title={{Qwen-VL}: A frontier large vision-language model with versatile abilities},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}

@inproceedings{2024LLaVA,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  booktitle=nips,
  year={2024}
}

@inproceedings{2024LLaVA1.5,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle=cvpr,
  year={2024}
}

@article{2024DeepSeekVL,
  title={{DeepSeek-VL}: towards real-world vision-language understanding},
  author={Lu, Haoyu and Liu, Wen and Zhang, Bo and Wang, Bingxuan and Dong, Kai and Liu, Bo and Sun, Jingxiang and Ren, Tongzheng and Li, Zhuoshu and Yang, Hao and others},
  journal={arXiv preprint arXiv:2403.05525},
  year={2024}
}

@article{2023Sharegpt4v,
  title={{ShareGPT4V}: Improving large multi-modal models with better captions},
  author={Chen, Lin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
  journal={arXiv preprint arXiv:2311.12793},
  year={2023}
}

@article{2023mobilevlm,
  title={{MobileVLM}: A fast, reproducible and strong vision language assistant for mobile devices},
  author={Chu, Xiangxiang and Qiao, Limeng and Lin, Xinyang and Xu, Shuang and Yang, Yang and Hu, Yiming and Wei, Fei and Zhang, Xinyu and Zhang, Bo and Wei, Xiaolin and others},
  journal={arXiv preprint arXiv:2312.16886},
  year={2023}
}

@inproceedings{2023instructblip,
    title={{InstructBLIP}: Towards General-purpose Vision-Language Models with Instruction Tuning},
    author={Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale and Hoi, Steven},
    booktitle=nips,
    year={2023}
}

@misc{2023idefics,
  title={Introducing {IDEFICS}: An open reproduction of state-of-the-art visual language model, 2023},
  author={Lauren{\c{c}}on, H and van Strien, Daniel and Bekman, Stas and Tronchon, Leo and Saulnier, Lucile and Wang, Thomas and Karamcheti, Siddharth and Singh, Amanpreet and Pistilli, Giada and Jernite, Yacine and others},
  url={https://huggingface.co/blog/idefics},
  year={2023}
}

@article{2024mobilevlmv2,
  title={{MobileVLM V2}: Faster and stronger baseline for vision language model},
  author={Chu, Xiangxiang and Qiao, Limeng and Zhang, Xinyu and Xu, Shuang and Wei, Fei and Yang, Yang and Sun, Xiaofei and Hu, Yiming and Lin, Xinyang and Zhang, Bo and others},
  journal={arXiv preprint arXiv:2402.03766},
  year={2024}
}

@article{2024LLaVAOV,
  title={{LLaVA-OneVision}: Easy visual task transfer},
  author={Li, Bo and Zhang, Yuanhan and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Hao and Zhang, Kaichen and Li, Yanwei and Liu, Ziwei and Li, Chunyuan},
  journal={arXiv preprint arXiv:2408.03326},
  year={2024}
}

@article{2024llavaphi,
  title={{LLaVA-Phi}: Efficient Multi-Modal Assistant with Small Language Model},
  author={Zhu, Yichen and Zhu, Minjie and Liu, Ning and Ou, Zhicai and Mou, Xiaofeng and Tang, Jian},
  journal={arXiv preprint arXiv:2401.02330},
  year={2024}
}

# 联合模型

@article{2023Seed,
  title={Planting a {SEED} of vision in large language model},
  author={Ge, Yuying and Ge, Yixiao and Zeng, Ziyun and Wang, Xintao and Shan, Ying},
  journal={arXiv preprint arXiv:2307.08041},
  year={2023}
}

@article{2023SeedLLaMa,
  title={Making {LLaMA} {SEE} and draw with {SEED} tokenizer},
  author={Ge, Yuying and Zhao, Sijie and Zeng, Ziyun and Ge, Yixiao and Li, Chen and Wang, Xintao and Shan, Ying},
  journal={arXiv preprint arXiv:2310.01218},
  year={2023}
}

@inproceedings{2023nextgpt,
  title={{NExT-GPT}: Any-to-any multimodal {LLM}},
  author={Wu, Shengqiong and Fei, Hao and Qu, Leigang and Ji, Wei and Chua, Tat-Seng},
  booktitle=icml,
  year={2024}
}

@inproceedings{2024Emu,
  title={Generative pretraining in multimodality},
  author={Sun, Quan and Yu, Qiying and Cui, Yufeng and Zhang, Fan and Zhang, Xiaosong and Wang, Yueze and Gao, Hongcheng and Liu, Jingjing and Huang, Tiejun and Wang, Xinlong},
  booktitle=iclr,
  year={2024}
}

@article{2024SeedX,
  title={{SEED-X}: Multimodal models with unified multi-granularity comprehension and generation},
  author={Ge, Yuying and Zhao, Sijie and Zhu, Jinguo and Ge, Yixiao and Yi, Kun and Song, Lin and Li, Chen and Ding, Xiaohan and Shan, Ying},
  journal={arXiv preprint arXiv:2404.14396},
  year={2024}
}

@article{2024Chameleon,
  title={Chameleon: Mixed-modal early-fusion foundation models},
  author={Team, Chameleon},
  journal={arXiv preprint arXiv:2405.09818},
  year={2024}
}

@article{2024Showo,
  title={Show-o: One single transformer to unify multimodal understanding and generation},
  author={Xie, Jinheng and Mao, Weijia and Bai, Zechen and Zhang, David Junhao and Wang, Weihao and Lin, Kevin Qinghong and Gu, Yuchao and Chen, Zhijie and Yang, Zhenheng and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2408.12528},
  year={2024}
}

@article{2024Transfusion,
  title={Transfusion: Predict the next token and diffuse images with one multi-modal model},
  author={Zhou, Chunting and Yu, Lili and Babu, Arun and Tirumala, Kushal and Yasunaga, Michihiro and Shamis, Leonid and Kahn, Jacob and Ma, Xuezhe and Zettlemoyer, Luke and Levy, Omer},
  journal={arXiv preprint arXiv:2408.11039},
  year={2024}
}

@article{2024VILAU,
  title={{VILA-U}: A unified foundation model integrating visual understanding and generation},
  author={Wu, Yecheng and Zhang, Zhuoyang and Chen, Junyu and Tang, Haotian and Li, Dacheng and Fang, Yunhao and Zhu, Ligeng and Xie, Enze and Yin, Hongxu and Yi, Li and others},
  journal={arXiv preprint arXiv:2409.04429},
  year={2024}
}

@article{2024Janus,
  title={Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation},
  author={Wu, Chengyue and Chen, Xiaokang and Wu, Zhiyu and Ma, Yiyang and Liu, Xingchao and Pan, Zizheng and Liu, Wen and Xie, Zhenda and Yu, Xingkai and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2410.13848},
  year={2024}
}

@article{2024emu3,
  title={Emu3: Next-token prediction is all you need},
  author={Wang, Xinlong and Zhang, Xiaosong and Luo, Zhengxiong and Sun, Quan and Cui, Yufeng and Wang, Jinsheng and Zhang, Fan and Wang, Yueze and Li, Zhen and Yu, Qiying and others},
  journal={arXiv preprint arXiv:2409.18869},
  year={2024}
}

@inproceedings{2024dreamllm,
  title={{DreamLLM}: Synergistic Multimodal Comprehension and Creation},
  author={Dong, Runpei and Han, Chunrui and Peng, Yuang and Qi, Zekun and Ge, Zheng and Yang, Jinrong and Zhao, Liang and Sun, Jianjian and Zhou, Hongyu and Wei, Haoran and others},
  booktitle=iclr,
  year={2024}
}

@inproceedings{2024lavit,
  title={Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization},
  author={Jin, Yang and Xu, Kun and Chen, Liwei and Liao, Chao and Tan, Jianchao and Huang, Quzhe and Bin, CHEN and Song, Chengru and ZHANG, Di and Ou, Wenwu and others},
  booktitle=iclr,
  year={2024}
}

@article{2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{2024LWM,
  title={World model on million-length video and language with ringattention},
  author={Liu, Hao and Yan, Wilson and Zaharia, Matei and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2402.08268},
  year={2024}
}

# 其他引用

@inproceedings{2009Imagenet,
  title={{ImageNet}: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle=cvpr,
  year={2009},
}

@inproceedings{2017VQAv2,
  title={Making the v in {VQA} matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle=cvpr,
  year={2017}
}

@inproceedings{2019kvqa,
  title={{KVQA}: Knowledge-aware visual question answering},
  author={Shah, Sanket and Mishra, Anand and Yadati, Naganand and Talukdar, Partha Pratim},
  booktitle=aaai,
  year={2019}
}

@article{2020OpenImgsv4,
  title={The {Open Images Dataset V4}: Unified image classification, object detection, and visual relationship detection at scale},
  author={Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Kolesnikov, Alexander and others},
  journal=ijcv,
  year={2020},
}

@inproceedings{2021iconqa,
  title={{IconQA}: A new benchmark for abstract diagram understanding and visual language reasoning},
  author={Lu, Pan and Qiu, Liang and Chen, Jiaqi and Xia, Tony and Zhao, Yizhou and Zhang, Wei and Yu, Zhou and Liang, Xiaodan and Zhu, Song-Chun},
  booktitle=nips,
  year={2021}
}

@article{2022screenqa,
  title={{ScreenQA}: Large-scale question-answer pairs over mobile app screenshots},
  author={Hsiao, Yu-Chung and Zubach, Fedir and Baechler, Gilles and Carbune, Victor and Lin, Jason and Wang, Maria and Sunkara, Srinivas and Zhu, Yun and Chen, Jindong},
  journal={arXiv preprint arXiv:2209.08199},
  year={2022}
}

@Misc{2023PyTorch,
    title = {{PyTorch}},
    author = {PyTorch-Contributors},
    url = {https://pytorch.org},
    year = {2024}
}

@misc{2023HAI-LLM,
    title = {{HAI-LLM}: Efficient and lightweight training tool for large models} ,
    author = {High-flyer},
    url = {https://www.high-flyer.cn/en/blog/hai-llm},
    year = {2023}
}

@inproceedings{2023DPS,
  title={Diffusion posterior sampling for general noisy inverse problems},
  author={Chung, Hyungjin and Kim, Jeongsol and Mccann, Michael T and Klasky, Marc L and Ye, Jong Chul},
  booktitle=iclr,
  year={2023}
}

@article{2024REPA,
  title={Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think},
  author={Yu, Sihyun and Kwak, Sangkyung and Jang, Huiwon and Jeong, Jongheon and Huang, Jonathan and Shin, Jinwoo and Xie, Saining},
  journal={arXiv preprint arXiv:2410.06940},
  year={2024}
}

@misc{2022LA,
    title={{LAION-Aesthetics-UMAP}},
    author={dclure},
    url={https://huggingface.co/datasets/dclure/laion-aesthetics-12m-umap},
    year={2022}
}

@misc{2023DetailedCaption,
    title={Detailed Caption},
    author={echo840},
    url={https://huggingface.co/datasets/echo840/Detailed_Caption},
    year={2023}
}

@inproceedings{2023SAM,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle=iccv,
  year={2023}
}

@inproceedings{2024ArxivQA,
  title={Multimodal {arXiv}: A dataset for improving scientific comprehension of large vision-language models},
  author={Li, Lei and Wang, Yuqi and Xu, Runxin and Wang, Peiyi and Feng, Xiachong and Kong, Lingpeng and Liu, Qi},
  booktitle=acl,
  year={2024}
}

@inproceedings{2024DenseFusion,
  title={{DenseFusion-1M}: Merging vision experts for comprehensive multimodal perception},
  author={Li, Xiaotong and Zhang, Fan and Diao, Haiwen and Wang, Yueze and Wang, Xinlong and Duan, Ling-Yu},
  booktitle=nips,
  year={2024}
}

@inproceedings{2024MMSci,
  title={{MMSci}: A Multimodal Multi-Discipline Dataset for PhD-Level Scientific Comprehension},
  author={Li, Zekun and Yang, Xianjun and Choi, Kyuri and Zhu, Wanrong and Hsieh, Ryan and Kim, HyeonJung and Lim, Jin Hyuk and Ji, Sungyoung and Lee, Byungju and Yan, Xifeng and others},
  booktitle={AI for Accelerated Materials Design},
  year={2024}
}

@article{2024PixelProse,
  title={From Pixels to Prose: A Large Dataset of Dense Image Captions},
  author={Singla, Vasu and Yue, Kaiyu and Paul, Sukriti and Shirkavand, Reza and Jayawardhana, Mayuka and Ganjdanesh, Alireza and Huang, Heng and Bhatele, Abhinav and Somepalli, Gowthami and Goldstein, Tom},
  journal={arXiv preprint arXiv:2406.10328},
  year={2024}
}

@article{2018wikihow,
  title={{WikiHow}: A large scale text summarization dataset},
  author={Koupaee, Mahnaz and Wang, William Yang},
  journal={arXiv preprint arXiv:1810.09305},
  year={2018}
}

@inproceedings{2021wit,
  title={{WIT}: Wikipedia-based image text dataset for multimodal multilingual machine learning},
  author={Srinivasan, Krishna and Raman, Karthik and Chen, Jiecao and Bendersky, Michael and Najork, Marc},
  booktitle={Proc.~ACM SIGIR Conf. Research and Develop. in Info. Retrieval},
  year={2021}
}

@inproceedings{2024JDB,
  title={{JourneyDB}: A benchmark for generative image understanding},
  author={Sun, Keqiang and Pan, Junting and Ge, Yuying and Li, Hao and Duan, Haodong and Wu, Xiaoshi and Zhang, Renrui and Zhou, Aojun and Qin, Zipeng and Wang, Yi and others},
  booktitle=nips,
  year={2024}
}

@misc{2024Megalith,
    title={{Megelith-10M}},
    author={madebyollin},
    url={https://huggingface.co/datasets/madebyollin/megalith-10m},
    year={2024}
}

@misc{2024Yfcc,
    title={{YFCC-15M}},
    author={mehdidc},
    url={https://huggingface.co/datasets/mehdidc/yfcc15m},
    year={2024}
}

@misc{2024DALLE3-Img,
    author = {Egan, Ben and Redden, Alex and {XWAVE} and {SilentAntagonist}},
    title = {{DALLE-3} 1 Million+ High Quality Captions},
    url = {https://huggingface.co/datasets/ProGamerGov/synthetic-dataset-1m-dalle3-high-quality-captions},
    year = {2024}
}

@article{touvron2023llama,
  title={{LLaMA}: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{mann2020language,
  title={Language models are few-shot learners},
  author={Mann, Ben and Ryder, N and Subbiah, M and Kaplan, J and Dhariwal, P and Neelakantan, A and Shyam, P and Sastry, G and Askell, A and Agarwal, S and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{achiam2023gpt,
  title={{GPT-4} technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with {GPT-4}},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

@inproceedings{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  booktitle=nips,
  year={2022}
}

@inproceedings{li2023blip,
  title={{BLIP-2}: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle=icml,
  year={2023},
}

@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle=cvpr,
  year={2021}
}

@inproceedings{chen2020generative,
  title={Generative pretraining from pixels},
  author={Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
  booktitle=icml,
  year={2020},
}

@inproceedings{liu2023instaflow,
  title={{InstaFlow}: One step is enough for high-quality diffusion-based text-to-image generation},
  author={Liu, Xingchao and Zhang, Xiwen and Ma, Jianzhu and Peng, Jian and others},
  booktitle=iclr,
  year={2024}
}

@inproceedings{albergo2023building,
  title={Building Normalizing Flows with Stochastic Interpolants},
  author={Albergo, Michael and Vanden-Eijnden, Eric},
  booktitle=iclr,
  year={2023}
}

@inproceedings{le2024voicebox,
  title={{VoiceBox}: Text-guided multilingual universal speech generation at scale},
  author={Le, Matthew and Vyas, Apoorv and Shi, Bowen and Karrer, Brian and Sari, Leda and Moritz, Rashel and Williamson, Mary and Manohar, Vimal and Adi, Yossi and Mahadeokar, Jay and others},
  booktitle=nips,
  year={2024}
}

@article{jin2024pyramidal,
  title={Pyramidal flow matching for efficient video generative modeling},
  author={Jin, Yang and Sun, Zhicheng and Li, Ningyuan and Xu, Kun and Jiang, Hao and Zhuang, Nan and Huang, Quzhe and Song, Yang and Mu, Yadong and Lin, Zhouchen},
  journal={arXiv preprint arXiv:2410.05954},
  year={2024}
}

@inproceedings{kim2024p,
  title={{P-Flow}: a fast and data-efficient zero-shot TTS through speech prompting},
  author={Kim, Sungwon and Shih, Kevin and Santos, Joao Felipe and Bakhturina, Evelina and Desta, Mikyas and Valle, Rafael and Yoon, Sungroh and Catanzaro, Bryan and others},
  booktitle=nips,
  year={2024}
}

@inproceedings{jingalphafold,
  title={{AlphaFold} Meets Flow Matching for Generating Protein Ensembles},
  author={Jing, Bowen and Berger, Bonnie and Jaakkola, Tommi},
  booktitle=icml,
  year={2024}
}

@inproceedings{yulanguage,
  title={Language Model Beats Diffusion-Tokenizer is key to visual generation},
  author={Yu, Lijun and Lezama, Jose and Gundavarapu, Nitesh Bharadwaj and Versari, Luca and Sohn, Kihyuk and Minnen, David and Cheng, Yong and Gupta, Agrim and Gu, Xiuye and Hauptmann, Alexander G and others},
  booktitle=iclr,
  year={2024}
}

@article{tong2024cambrian,
  title={Cambrian-1: A fully open, vision-centric exploration of multimodal llms},
  author={Tong, Shengbang and Brown, Ellis and Wu, Penghao and Woo, Sanghyun and Middepogu, Manoj and Akula, Sai Charitha and Yang, Jihan and Yang, Shusheng and Iyer, Adithya and Pan, Xichen and others},
  journal={arXiv preprint arXiv:2406.16860},
  year={2024}
}

@article{liu2022rectified,
  title={Rectified flow: A marginal preserving approach to optimal transport},
  author={Liu, Qiang},
  journal={arXiv preprint arXiv:2209.14577},
  year={2022}
}

@article{touvron2023llama2,
  title={{LLaMA 2}: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{liu2024deepseek,
  title={{DeepSeek-v2}: A strong, economical, and efficient mixture-of-experts language model},
  author={Liu, Aixin and Feng, Bei and Wang, Bin and Wang, Bingxuan and Liu, Bo and Zhao, Chenggang and Dengr, Chengqi and Ruan, Chong and Dai, Damai and Guo, Daya and others},
  journal={arXiv preprint arXiv:2405.04434},
  year={2024}
}

@article{ye2024x,
  title={{X-VILA}: Cross-Modality Alignment for Large Language Model},
  author={Ye, Hanrong and Huang, De-An and Lu, Yao and Yu, Zhiding and Ping, Wei and Tao, Andrew and Kautz, Jan and Han, Song and Xu, Dan and Molchanov, Pavlo and others},
  journal={arXiv preprint arXiv:2405.19335},
  year={2024}
}

@misc{2023IF,
    title={{DeepFloyd IF}},
    author={DeepFloyd},
    url={https://huggingface.co/DeepFloyd/IF-I-XL-v1.0},
    year={2023}
}

@article{2023dalle3,
  title={Improving image generation with better captions},
  author={Betker, James and Goh, Gabriel and Jing, Li and Brooks, Tim and Wang, Jianfeng and Li, Linjie and Ouyang, Long and Zhuang, Juntang and Lee, Joyce and Guo, Yufei and others},
  journal={Computer Science},
  year={2023}
}




@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}
@inproceedings{EGGen,
author = {Sun, Zhenhong and Wang, Junyan and Tan, Zhiyu and Dong, Daoyi and Ma, Hailan and Li, Hao and Gong, Dong},
title = {EGGen: Image Generation with Multi-entity Prior Learning through Entity Guidance},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680898},
doi = {10.1145/3664647.3680898},
abstract = {Diffusion models have shown remarkable prowess in text-to-image synthesis and editing, yet they often stumble when tasked with interpreting complex prompts that describe multiple entities with specific attributes and interrelations. The generated images often contain inconsistent multi-entity representation (IMR), reflected as inaccurate presentations of the multiple entities and their attributes. Although providing spatial layout guidance improves the multi-entity generation quality in existing works, it is still challenging to handle the leakage attributes and avoid unnatural characteristics. To address the IMR challenge, we first conduct in-depth analyses of the diffusion process and attention operation, revealing that the IMR challenges largely stem from the process of cross-attention mechanisms. According to the analyses, we introduce the entity guidance generation mechanism, which maintains the integrity of the original diffusion model parameters by integrating plug-in networks. Our work advances the stable diffusion model by segmenting comprehensive prompts into distinct entity-specific prompts with bounding boxes, enabling a transition from multi-entity to single-entity generation in cross-attention layers. More importantly, we introduce entity-centric cross-attention layers that focus on individual entities to preserve their uniqueness and accuracy, alongside global entity alignment layers that refine cross-attention maps using multi-entity priors for precise positioning and attribute accuracy. Additionally, a linear attenuation module is integrated to progressively reduce the influence of these layers during inference, preventing oversaturation and preserving generation fidelity. Our comprehensive experiments demonstrate that this entity guidance generation enhances existing text-to-image models in generating detailed, multi-entity images.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {6637–6645},
numpages = {9},
keywords = {diffusion model, multi-entity prior, text-to-image generation},
location = {Melbourne VIC, Australia},
series = {MM '24}
}
@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}
@misc{han2024emmatexttoimagediffusionmodel,
      title={EMMA: Your Text-to-Image Diffusion Model Can Secretly Accept Multi-Modal Prompts}, 
      author={Yucheng Han and Rui Wang and Chi Zhang and Juntao Hu and Pei Cheng and Bin Fu and Hanwang Zhang},
      year={2024},
      eprint={2406.09162},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.09162}, 
}
